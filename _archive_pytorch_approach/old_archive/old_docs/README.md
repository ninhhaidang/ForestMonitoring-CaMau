# Ca Mau Forest Change Detection - Multi-Model Comparison

**Author:** Ninh Háº£i ÄÄƒng (21021411)
**Institution:** VNU University of Engineering and Technology
**Year:** 2025-2026

Automatic mangrove forest change detection using Deep Learning with comparison of 3 state-of-the-art models and multi-sensor satellite imagery (Sentinel-2 + Sentinel-1).

---

## ğŸ“‹ OVERVIEW

This thesis compares **3 deep learning models** for forest change detection:

| Model | Type | Params | Batch | Time | Test mIoU | Status |
|-------|------|--------|-------|------|-----------|--------|
| **SNUNet-CD** | CNN | 4-8M | 16 | 1h 43min | **79.50%** | âœ… Complete |
| **Changer** | Transformer | 8-10M | 12 | ~45 min | - | â³ Pending |
| **BAN** | Transformer | 90M | 8 | ~60 min | - | â³ Pending |

**Dataset:** 1,285 samples (1,028 train / 128 val / 129 test) from Ca Mau, Vietnam
**Input:** 9 channels per time step (Sentinel-2: B4,B8,B11,B12,NDVI,NBR,NDMI + Sentinel-1: VH,Ratio)

---

## ğŸ“ PROJECT STRUCTURE

```
25-26_HKI_DATN_21021411_DangNH/
â”‚
â”œâ”€â”€ configs/                    # Model configs
â”‚   â”œâ”€â”€ snunet_camau.py
â”‚   â”œâ”€â”€ changer_camau.py
â”‚   â””â”€â”€ ban_camau.py
â”‚
â”œâ”€â”€ data/processed/             # Preprocessed dataset
â”‚   â”œâ”€â”€ train/                 # 1,028 samples
â”‚   â”‚   â”œâ”€â”€ A/                # Time 1 (9-ch TIFFs)
â”‚   â”‚   â”œâ”€â”€ B/                # Time 2 (9-ch TIFFs)
â”‚   â”‚   â””â”€â”€ label/            # Change masks (PNGs)
â”‚   â”œâ”€â”€ val/                  # 128 samples
â”‚   â””â”€â”€ test/                 # 129 samples
â”‚
â”œâ”€â”€ experiments/               # Training outputs
â”‚   â”œâ”€â”€ snunet/
â”‚   â”œâ”€â”€ changer/
â”‚   â””â”€â”€ ban/
â”‚
â”œâ”€â”€ notebooks/                 # ğŸ¯ TRAINING NOTEBOOKS
â”‚   â”œâ”€â”€ train_snunet.ipynb    # â­ Train SNUNet-CD
â”‚   â”œâ”€â”€ train_changer.ipynb   # â­ Train Changer
â”‚   â”œâ”€â”€ train_ban.ipynb       # â­ Train BAN
â”‚   â””â”€â”€ compare_models.ipynb  # â­ Compare results
â”‚
â”œâ”€â”€ results/                   # Final results
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ custom_transforms.py  # 9-channel TIFF loader
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ evaluation_utils.py
â”‚   â””â”€â”€ training_utils.py
â”‚
â”œâ”€â”€ open-cd/                   # Open-CD framework
â”‚
â”œâ”€â”€ train_camau.py             # CLI training script
â”œâ”€â”€ MODEL_ANALYSIS.md          # Model selection analysis
â”œâ”€â”€ environment.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ QUICK START

### 1. Environment Setup

```bash
# Create environment
conda env create -f environment.yml
conda activate dang

# Verify GPU
nvidia-smi
```

### 2. Training (Choose One Method)

#### â­ Method A: Jupyter Notebook (Recommended - Easy!)

```bash
# Start Jupyter
jupyter notebook

# Open one of these notebooks:
# - notebooks/train_snunet.ipynb   (Fastest, ~35 min)
# - notebooks/train_changer.ipynb  (Balanced, ~45 min)
# - notebooks/train_ban.ipynb      (Best accuracy, ~60 min)
```

**Notebook Features:**
- âœ… Start training with 1 click
- âœ… **Auto-refreshing progress bar** (updates every 5s)
- âœ… Real-time metrics (Loss, Accuracy, ETA)
- âœ… Easy stop/resume
- âœ… No terminal needed!

**How to use:**
1. Run cells 1-4 (Setup + Start Training)
2. Run cell 5 (Progress Bar) - **Just once, it auto-refreshes!**
3. Watch the progress bar update automatically:
   ```
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     ğŸš€ SNUNet-CD TRAINING
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 42.5%

     Progress: 1,827 / 4,300 iterations
     ETA: 0:18:30
     Loss: 0.3245 | Acc: 92.35%

     ğŸ• Last update: 2025-10-17 15:05:30

   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   ```
4. Press "Kernel â†’ Interrupt" to stop monitoring

#### Method B: Command Line

```bash
python train_camau.py configs/snunet_camau.py
python train_camau.py configs/changer_camau.py
python train_camau.py configs/ban_camau.py
```

### 3. Compare Results

After training all 3 models:

```bash
# Open comparison notebook
jupyter notebook notebooks/compare_models.ipynb
```

This generates:
- Training curves comparison
- Performance summary table
- Bar charts (Loss, Accuracy, Speed, Memory)
- CSV export

---

## ğŸ“ WHY THESE 3 MODELS?

After analyzing Open-CD models for **9-channel compatibility**:

### âœ… SNUNet-CD (Lightweight CNN)
- **Architecture:** Dense Siamese UNet + ECAM attention
- **Why:** Conv2d natively supports any number of channels
- **Advantage:** Fastest, no pretrained needed, good for production

### âœ… Changer (Medium Transformer)
- **Architecture:** MixVisionTransformer with Interaction modules
- **Why:** Patch embedding (Conv2d-based) is flexible
- **Advantage:** Balanced accuracy/speed, explicit bi-temporal interaction

### âœ… BAN (Heavy Transformer)
- **Architecture:** CLIP ViT-B/16 + MiT-B0 with adapters
- **Why:** ViT patch embedding supports any channels
- **Advantage:** Best accuracy, strong pretrained features

### âŒ TinyCDv2 (Rejected)
- **Problem:** Hardcoded for 3 channels in MixingMaskAttentionBlock
- **Cannot use** for 9-channel input without major rewrite

---

## ğŸ’» SYSTEM REQUIREMENTS

### Hardware
- **GPU:** NVIDIA RTX A4000 (16GB) or equivalent
- **RAM:** 32GB recommended
- **Storage:** ~10GB for data + experiments

### Software
- **Python:** 3.8+
- **PyTorch:** 1.13+ with CUDA 11.7+
- **OS:** Windows 11 / Linux

---

## ğŸ“Š TRAINING CONFIGS

### SNUNet-CD (Fastest)
```python
batch_size = 24        # Largest batch (lightweight model)
max_iters = 4,300      # ~100 epochs
optimizer = AdamW(lr=0.001, weight_decay=0.01)
GPU memory: ~14-15GB
Training time: ~35-40 minutes
```

### Changer (Balanced)
```python
batch_size = 12        # Medium batch
max_iters = 8,600      # ~100 epochs
optimizer = AdamW(lr=0.0001, weight_decay=0.01)
GPU memory: ~10-12GB
Training time: ~45-50 minutes
```

### BAN (Most Accurate)
```python
batch_size = 8         # Smallest batch (heavy model)
max_iters = 12,800     # ~100 epochs
optimizer = AdamW(lr=0.0001, weight_decay=0.0001)
GPU memory: ~12-14GB
Training time: ~60-65 minutes
```

---

## ğŸ”¬ KEY FEATURES

### Multi-Spectral 9-Channel Input
- **Sentinel-2 Optical:** B4 (Red), B8 (NIR), B11 (SWIR1), B12 (SWIR2)
- **Vegetation Indices:** NDVI, NBR, NDMI
- **Sentinel-1 SAR:** VH polarization, VH/VV Ratio

### Custom Data Pipeline
- **Rasterio-based TIFF loader** for >4 channel images
- Multi-temporal pairing (Time 1 vs Time 2)
- Data augmentation: Random rotation, flip (no PhotoMetric for 9-ch)
- Normalization: Min-max to [0, 1]

### Model Diversity
- **Architecture:** CNN vs Transformer (Medium vs Heavy)
- **Size:** 4M â†’ 10M â†’ 90M parameters
- **Pretrained:** None / ImageNet / CLIP + ImageNet

---

## ğŸ› ï¸ TROUBLESHOOTING

### GPU Out of Memory
Reduce batch size in config:
```python
train_dataloader = dict(batch_size=16, ...)  # Lower
```

### Training Too Slow
Increase if GPU has memory:
```python
train_dataloader = dict(batch_size=32, num_workers=8, ...)
```

### Stop Training
**In Jupyter:** Press "Kernel â†’ Interrupt" in monitoring cell
**In CLI:** Press `Ctrl+C`
**In Task Manager:** End `python.exe` process

---

## ğŸ“– DOCUMENTATION

- **MODEL_ANALYSIS.md:** Why these 3 models? Detailed analysis
- **configs/*.py:** Model configs with inline comments
- **notebooks/*.ipynb:** Interactive training with auto-refresh progress
- **src/*.py:** Source code with docstrings

---

## ğŸ“ˆ ACTUAL RESULTS

### SNUNet-CD (Completed âœ…)

**Training:** 1h 43min (6,400 iterations / 100 epochs)

| Metric | Validation | Test Set |
|--------|------------|----------|
| **mIoU** | 74.99% | **79.50%** |
| **F1-Score** | 85.67% | **88.56%** |
| **Precision** | 85.79% | **88.86%** |
| **Recall** | 86.57% | **88.39%** |
| **Overall Accuracy** | 86.11% | **88.71%** |

**Per-Class Performance (Test Set):**
| Class | IoU | F1-Score | Precision | Recall |
|-------|-----|----------|-----------|--------|
| Unchanged | 81.56% | 89.84% | 87.75% | 92.04% |
| Changed | 77.44% | 87.28% | 89.97% | 84.75% |

**Details:** See `SNUNET_RESULTS.md`

---

### Changer (Pending)
*To be trained*

### BAN (Pending)
*To be trained*

---

## ğŸ“ˆ EXPECTED RESULTS (Reference)

| Model | Loss | Accuracy | Precision | Recall | F1-Score |
|-------|------|----------|-----------|--------|----------|
| SNUNet-CD | 0.15-0.20 | 94-95% | 0.85 | 0.87 | 0.86-0.88 |
| Changer | 0.12-0.18 | 95-96% | 0.87 | 0.89 | 0.88-0.90 |
| BAN | 0.10-0.15 | 96-97% | 0.89 | 0.90 | 0.89-0.91 |

**Trade-offs:**
- **SNUNet-CD:** âœ… Fastest (35-40 min), good for real-time applications, **79.50% mIoU achieved**
- **Changer:** Best balance between accuracy and speed
- **BAN:** Highest accuracy, best for research

---

## ğŸ“ CITATION

```bibtex
@mastersthesis{dang2025camau,
  title={Multi-Model Comparison for Forest Change Detection in Ca Mau Using Deep Learning},
  author={Ninh Háº£i ÄÄƒng},
  school={VNU University of Engineering and Technology},
  year={2025}
}
```

---

## ğŸ“§ CONTACT

**Student:** Ninh Háº£i ÄÄƒng (21021411)
**Email:** ninhhaidangg@gmail.com

---

## ğŸ™ ACKNOWLEDGMENTS

- **Open-CD Framework:** https://github.com/likyoo/open-cd
- **MMSegmentation:** https://github.com/open-mmlab/mmsegmentation
- **Sentinel Hub:** Satellite imagery access

---

## ğŸ”„ VERSION HISTORY

### 2025-10-17 (Current)
- âœ… Finalized 3-model comparison (SNUNet-CD, Changer, BAN)
- âœ… Optimized configs for RTX A4000 16GB
- âœ… Created interactive notebooks with **auto-refresh progress bars**
- âœ… Implemented custom 9-channel TIFF data loader
- âœ… Clean project structure
- âœ… **Completed SNUNet-CD training** (1h 43min, 79.50% test mIoU)
- âœ… **Evaluated SNUNet-CD on test set** (88.56% F1-score)
- âœ… Created comprehensive results report (`SNUNET_RESULTS.md`)

---

**Status:** âœ… SNUNet-CD completed | Changer & BAN pending
**Framework:** Open-CD (MMSegmentation)
**GPU:** NVIDIA RTX A4000 16GB
**Last Updated:** 2025-10-17
