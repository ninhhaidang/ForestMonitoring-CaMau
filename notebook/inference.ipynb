{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "107954b2",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896914af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce GTX 1060 6GB\n",
      "\n",
      "‚úì Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Geospatial\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = 'cpu'\n",
    "\n",
    "print(\"\\n‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecffa0e",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8e0d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  patch_size               : 3\n",
      "  n_features               : 27\n",
      "  n_classes                : 4\n",
      "  device                   : cuda\n",
      "  pred_batch_size          : 8000\n",
      "  pred_stride              : 1\n",
      "\n",
      "üìÅ Input data directory: ..\\data\\inference\n",
      "üìÅ Output directory: ..\\results\\inference\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "INFERENCE_DATA_DIR = Path('../data/inference')\n",
    "MODEL_PATH = Path('../results/models/cnn_final_model.pth')\n",
    "NORMALIZATION_STATS_PATH = Path('../results/data/normalization_stats.json')\n",
    "OUTPUT_DIR = Path('../results/inference')\n",
    "\n",
    "# Model configuration (MUST match training config)\n",
    "CONFIG = {\n",
    "    'patch_size': 3,\n",
    "    'n_features': 27,\n",
    "    'n_classes': 4,\n",
    "    'device': device,\n",
    "    'pred_batch_size': 8000,\n",
    "    'pred_stride': 1,\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(OUTPUT_DIR / 'rasters').mkdir(exist_ok=True)\n",
    "(OUTPUT_DIR / 'plots').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:25s}: {value}\")\n",
    "\n",
    "print(f\"\\nüìÅ Input data directory: {INFERENCE_DATA_DIR}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3de57",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Trained Model & Normalization Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8d5fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING TRAINED MODEL\n",
      "======================================================================\n",
      "\n",
      "Loading model from: ..\\results\\models\\cnn_final_model.pth\n",
      "  Loading from checkpoint dictionary...\n",
      "‚úì Model loaded successfully!\n",
      "\n",
      "Model parameters:\n",
      "  Total: 36,676\n",
      "  Trainable: 36,676\n",
      "\n",
      "Loading normalization stats from: ..\\results\\data\\normalization_stats.json\n",
      "‚ö†Ô∏è  Warning: Normalization stats not found!\n",
      "   Will compute normalization from inference data (not recommended)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from models.cnn.architecture import create_model\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING TRAINED MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if model exists\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\\nPlease train the model first using cnn_deforestation_detection.ipynb\")\n",
    "\n",
    "# Load model checkpoint\n",
    "print(f\"\\nLoading model from: {MODEL_PATH}\")\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "\n",
    "# Check if checkpoint is a dict (with state_dict) or the model itself\n",
    "if isinstance(checkpoint, dict):\n",
    "    print(\"  Loading from checkpoint dictionary...\")\n",
    "    # Create model architecture first\n",
    "    model = create_model(\n",
    "        model_type='standard',\n",
    "        patch_size=CONFIG['patch_size'],\n",
    "        n_features=CONFIG['n_features'],\n",
    "        n_classes=CONFIG['n_classes'],\n",
    "        dropout_rate=0.7  # Same as training\n",
    "    )\n",
    "    # Load state dict\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "else:\n",
    "    # If it's already a model object\n",
    "    model = checkpoint\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(\"‚úì Model loaded successfully!\")\n",
    "\n",
    "# Print model summary\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")\n",
    "\n",
    "# Load normalization stats from training\n",
    "print(f\"\\nLoading normalization stats from: {NORMALIZATION_STATS_PATH}\")\n",
    "if not NORMALIZATION_STATS_PATH.exists():\n",
    "    print(\"‚ö†Ô∏è  Warning: Normalization stats not found!\")\n",
    "    print(\"   Will compute normalization from inference data (not recommended)\")\n",
    "    normalization_stats = None\n",
    "else:\n",
    "    with open(NORMALIZATION_STATS_PATH, 'r') as f:\n",
    "        normalization_stats = json.load(f)\n",
    "    print(\"‚úì Normalization stats loaded successfully!\")\n",
    "    print(f\"  Mean shape: {np.array(normalization_stats['mean']).shape}\")\n",
    "    print(f\"  Std shape: {np.array(normalization_stats['std']).shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7241b7",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Load New Data for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22cbdab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING NEW DATA FOR INFERENCE\n",
      "======================================================================\n",
      "\n",
      "Searching for Sentinel-2 data in: ..\\data\\inference\\sentinel-2\n",
      "Searching for Sentinel-1 data in: ..\\data\\inference\\sentinel-1\n",
      "\n",
      "‚úì Found 2 Sentinel-2 files:\n",
      "  - S2_2024_04_04.tif\n",
      "  - S2_2025_04_04.tif\n",
      "\n",
      "‚úì Found 2 Sentinel-1 files:\n",
      "  - S1_2024_04_04_matched_S2_2024_04_04.tif\n",
      "  - S1_2025_04_05_matched_S2_2025_04_04.tif\n",
      "\n",
      "üìÖ Time period:\n",
      "  Before: S2_2024_04_04, S1_2024_04_04_matched_S2_2024_04_04\n",
      "  After:  S2_2025_04_04, S1_2025_04_05_matched_S2_2025_04_04\n",
      "\n",
      "Loading rasters...\n",
      "  Sentinel-2 before: (7, 10919, 12549)\n",
      "  Sentinel-2 after:  (7, 10919, 12549)\n",
      "  Sentinel-1 before: (2, 10919, 12549)\n",
      "  Sentinel-1 after:  (2, 10919, 12549)\n",
      "\n",
      "‚úì Data loaded successfully!\n",
      "  Image dimensions: 10919 x 12549\n",
      "  CRS: EPSG:32648\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOADING NEW DATA FOR INFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define expected file paths\n",
    "s2_dir = INFERENCE_DATA_DIR / 'sentinel-2'\n",
    "s1_dir = INFERENCE_DATA_DIR / 'sentinel-1'\n",
    "\n",
    "print(f\"\\nSearching for Sentinel-2 data in: {s2_dir}\")\n",
    "print(f\"Searching for Sentinel-1 data in: {s1_dir}\")\n",
    "\n",
    "# Find Sentinel-2 files (before and after)\n",
    "s2_files = sorted(list(s2_dir.glob('*.tif')))\n",
    "if len(s2_files) < 2:\n",
    "    raise FileNotFoundError(f\"Expected at least 2 Sentinel-2 files (before & after) in {s2_dir}\\nFound: {len(s2_files)} files\")\n",
    "\n",
    "print(f\"\\n‚úì Found {len(s2_files)} Sentinel-2 files:\")\n",
    "for f in s2_files:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Find Sentinel-1 files (before and after)\n",
    "s1_files = sorted(list(s1_dir.glob('*.tif')))\n",
    "if len(s1_files) < 2:\n",
    "    raise FileNotFoundError(f\"Expected at least 2 Sentinel-1 files (before & after) in {s1_dir}\\nFound: {len(s1_files)} files\")\n",
    "\n",
    "print(f\"\\n‚úì Found {len(s1_files)} Sentinel-1 files:\")\n",
    "for f in s1_files:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Assume first file is 'before', second is 'after'\n",
    "s2_before_path = s2_files[0]\n",
    "s2_after_path = s2_files[1]\n",
    "s1_before_path = s1_files[0]\n",
    "s1_after_path = s1_files[1]\n",
    "\n",
    "print(f\"\\nüìÖ Time period:\")\n",
    "print(f\"  Before: {s2_before_path.stem}, {s1_before_path.stem}\")\n",
    "print(f\"  After:  {s2_after_path.stem}, {s1_after_path.stem}\")\n",
    "\n",
    "# Load rasters\n",
    "print(f\"\\nLoading rasters...\")\n",
    "with rasterio.open(s2_before_path) as src:\n",
    "    s2_before = src.read()\n",
    "    s2_metadata = {\n",
    "        'transform': src.transform,\n",
    "        'crs': src.crs,\n",
    "        'bounds': src.bounds,\n",
    "        'shape': (src.height, src.width)\n",
    "    }\n",
    "    print(f\"  Sentinel-2 before: {s2_before.shape}\")\n",
    "\n",
    "with rasterio.open(s2_after_path) as src:\n",
    "    s2_after = src.read()\n",
    "    print(f\"  Sentinel-2 after:  {s2_after.shape}\")\n",
    "\n",
    "with rasterio.open(s1_before_path) as src:\n",
    "    s1_before = src.read()\n",
    "    print(f\"  Sentinel-1 before: {s1_before.shape}\")\n",
    "\n",
    "with rasterio.open(s1_after_path) as src:\n",
    "    s1_after = src.read()\n",
    "    print(f\"  Sentinel-1 after:  {s1_after.shape}\")\n",
    "\n",
    "print(f\"\\n‚úì Data loaded successfully!\")\n",
    "print(f\"  Image dimensions: {s2_metadata['shape'][0]} x {s2_metadata['shape'][1]}\")\n",
    "print(f\"  CRS: {s2_metadata['crs']}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51411915",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Extract Features (Same as Training)\n",
    "\n",
    "**CRITICAL**: Must use the same 27 features as training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f013efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:39:38 - core.feature_extraction - INFO - \n",
      "======================================================================\n",
      "2025-11-21 18:39:38 - core.feature_extraction - INFO - STEP 3: FEATURE EXTRACTION\n",
      "2025-11-21 18:39:38 - core.feature_extraction - INFO - ======================================================================\n",
      "2025-11-21 18:39:38 - core.feature_extraction - INFO - \n",
      "Input dimensions: 10919 x 12549\n",
      "2025-11-21 18:39:38 - core.feature_extraction - INFO - \n",
      "Creating valid pixel mask (relaxed for cloud coverage)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE EXTRACTION\n",
      "======================================================================\n",
      "\n",
      "Extracting features (must match training features)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:39:45 - core.feature_extraction - INFO -   ‚úì Total valid pixels: 16,246,850 / 137,022,531 (11.86%)\n",
      "2025-11-21 18:39:45 - core.feature_extraction - INFO -   ‚úì Pixels with S2 data: 13,736,943 (10.03%)\n",
      "2025-11-21 18:39:45 - core.feature_extraction - INFO -   ‚úì S1-only pixels (cloudy): 2,509,907 (1.83%)\n",
      "2025-11-21 18:39:45 - core.feature_extraction - INFO - \n",
      "Extracting Sentinel-2 features...\n",
      "2025-11-21 18:39:47 - core.feature_extraction - INFO -   - Imputing S2 values for cloudy pixels using median...\n",
      "2025-11-21 18:39:54 - core.feature_extraction - INFO -   - Adding S2 Before bands (7 features)\n",
      "2025-11-21 18:39:54 - core.feature_extraction - INFO -   - Adding S2 After bands (7 features)\n",
      "2025-11-21 18:39:54 - core.feature_extraction - INFO -   - Calculating S2 Delta (7 features)\n",
      "2025-11-21 18:39:56 - core.feature_extraction - INFO -   ‚úì Total S2 features: 21\n",
      "2025-11-21 18:39:56 - core.feature_extraction - INFO - \n",
      "Extracting Sentinel-1 features...\n",
      "2025-11-21 18:39:56 - core.feature_extraction - INFO -   - Adding S1 Before bands (2 features)\n",
      "2025-11-21 18:39:56 - core.feature_extraction - INFO -   - Adding S1 After bands (2 features)\n",
      "2025-11-21 18:39:56 - core.feature_extraction - INFO -   - Calculating S1 Delta (2 features)\n",
      "2025-11-21 18:39:57 - core.feature_extraction - INFO -   ‚úì Total S1 features: 6\n",
      "2025-11-21 18:39:57 - core.feature_extraction - INFO - \n",
      "Stacking all features...\n",
      "2025-11-21 18:40:11 - core.feature_extraction - INFO -   ‚úì Feature stack shape: (27, 10919, 12549)\n",
      "2025-11-21 18:40:11 - core.feature_extraction - INFO -   ‚úì Total features: 27\n",
      "2025-11-21 18:40:11 - core.feature_extraction - INFO - \n",
      "Feature statistics:\n",
      "2025-11-21 18:40:12 - core.feature_extraction - INFO -   S2_before_B4                  : min=   0.000, max=   1.067, mean=   0.059, std=   0.036\n",
      "2025-11-21 18:40:12 - core.feature_extraction - INFO -   S2_before_B8                  : min=   0.000, max=   1.074, mean=   0.202, std=   0.085\n",
      "2025-11-21 18:40:12 - core.feature_extraction - INFO -   S2_before_B11                 : min=   0.000, max=   1.477, mean=   0.116, std=   0.056\n",
      "2025-11-21 18:40:13 - core.feature_extraction - INFO -   S2_before_B12                 : min=   0.001, max=   1.544, mean=   0.066, std=   0.044\n",
      "2025-11-21 18:40:13 - core.feature_extraction - INFO -   S2_before_NDVI                : min=  -0.997, max=   0.999, mean=   0.485, std=   0.302\n",
      "2025-11-21 18:40:14 - core.feature_extraction - INFO -   S2_before_NBR                 : min=  -0.998, max=   0.958, mean=   0.474, std=   0.232\n",
      "2025-11-21 18:40:14 - core.feature_extraction - INFO -   S2_before_NDMI                : min=  -0.998, max=   0.984, mean=   0.242, std=   0.202\n",
      "2025-11-21 18:40:14 - core.feature_extraction - INFO -   S2_after_B4                   : min=   0.007, max=   0.935, mean=   0.074, std=   0.041\n",
      "2025-11-21 18:40:15 - core.feature_extraction - INFO -   S2_after_B8                   : min=   0.002, max=   0.835, mean=   0.215, std=   0.088\n",
      "2025-11-21 18:40:15 - core.feature_extraction - INFO -   S2_after_B11                  : min=   0.012, max=   0.763, mean=   0.121, std=   0.051\n",
      "2025-11-21 18:40:15 - core.feature_extraction - INFO -   S2_after_B12                  : min=   0.012, max=   0.818, mean=   0.075, std=   0.042\n",
      "2025-11-21 18:40:16 - core.feature_extraction - INFO -   S2_after_NDVI                 : min=  -0.948, max=   0.930, mean=   0.443, std=   0.273\n",
      "2025-11-21 18:40:16 - core.feature_extraction - INFO -   S2_after_NBR                  : min=  -0.959, max=   0.895, mean=   0.448, std=   0.210\n",
      "2025-11-21 18:40:17 - core.feature_extraction - INFO -   S2_after_NDMI                 : min=  -0.969, max=   0.816, mean=   0.253, std=   0.182\n",
      "2025-11-21 18:40:17 - core.feature_extraction - INFO -   S2_delta_B4                   : min=  -0.834, max=   0.802, mean=   0.015, std=   0.038\n",
      "2025-11-21 18:40:17 - core.feature_extraction - INFO -   S2_delta_B8                   : min=  -0.705, max=   0.566, mean=   0.013, std=   0.059\n",
      "2025-11-21 18:40:18 - core.feature_extraction - INFO -   S2_delta_B11                  : min=  -1.099, max=   0.503, mean=   0.005, std=   0.046\n",
      "2025-11-21 18:40:18 - core.feature_extraction - INFO -   S2_delta_B12                  : min=  -1.312, max=   0.508, mean=   0.009, std=   0.039\n",
      "2025-11-21 18:40:19 - core.feature_extraction - INFO -   S2_delta_NDVI                 : min=  -1.156, max=   1.382, mean=  -0.042, std=   0.161\n",
      "2025-11-21 18:40:19 - core.feature_extraction - INFO -   S2_delta_NBR                  : min=  -1.214, max=   1.491, mean=  -0.026, std=   0.165\n",
      "2025-11-21 18:40:19 - core.feature_extraction - INFO -   S2_delta_NDMI                 : min=  -0.999, max=   1.368, mean=   0.011, std=   0.146\n",
      "2025-11-21 18:40:20 - core.feature_extraction - INFO -   S1_before_VV                  : min=     nan, max=     nan, mean=     nan, std=     nan\n",
      "2025-11-21 18:40:20 - core.feature_extraction - INFO -   S1_before_VH                  : min=     nan, max=     nan, mean=     nan, std=     nan\n",
      "2025-11-21 18:40:21 - core.feature_extraction - INFO -   S1_after_VV                   : min=     nan, max=     nan, mean=     nan, std=     nan\n",
      "2025-11-21 18:40:21 - core.feature_extraction - INFO -   S1_after_VH                   : min=     nan, max=     nan, mean=     nan, std=     nan\n",
      "2025-11-21 18:40:21 - core.feature_extraction - INFO -   S1_delta_VV                   : min=     nan, max=     nan, mean=     nan, std=     nan\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO -   S1_delta_VH                   : min=     nan, max=     nan, mean=     nan, std=     nan\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO - \n",
      "======================================================================\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO - ‚úì FEATURE EXTRACTION COMPLETED\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO - ======================================================================\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO -   - Total features: 27\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO -   - Feature shape: (27, 10919, 12549)\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO -   - Valid pixels: 16,246,850 (11.86%)\n",
      "2025-11-21 18:40:22 - core.feature_extraction - INFO - ======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Feature extraction completed!\n",
      "  Feature stack shape: (27, 10919, 12549)\n",
      "  Expected features: 27\n",
      "  Valid pixels: 16,246,850 / 137,022,531 (11.86%)\n",
      "\n",
      "‚úì Feature count verified!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from core.feature_extraction import FeatureExtraction\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE EXTRACTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nExtracting features (must match training features)...\")\n",
    "extractor = FeatureExtraction()\n",
    "\n",
    "feature_stack, valid_mask = extractor.extract_features(\n",
    "    s2_before, s2_after,\n",
    "    s1_before, s1_after\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Feature extraction completed!\")\n",
    "print(f\"  Feature stack shape: {feature_stack.shape}\")\n",
    "print(f\"  Expected features: {CONFIG['n_features']}\")\n",
    "print(f\"  Valid pixels: {valid_mask.sum():,} / {valid_mask.size:,} ({valid_mask.sum()/valid_mask.size*100:.2f}%)\")\n",
    "\n",
    "# Verify feature count\n",
    "if feature_stack.shape[0] != CONFIG['n_features']:\n",
    "    raise ValueError(f\"Feature mismatch! Expected {CONFIG['n_features']}, got {feature_stack.shape[0]}\")\n",
    "\n",
    "print(\"\\n‚úì Feature count verified!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd4028",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Predict Full Raster\n",
    "\n",
    "**Apply trained model to entire study area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097bebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - RasterPredictor initialized on device: cuda\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - \n",
      "======================================================================\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - PREDICTING FULL RASTER WITH CNN\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - ======================================================================\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - Raster shape: 10919 x 12549\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - Patch size: 3x3\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - Stride: 1\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - Batch size: 8000\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - Temperature: 1.0 (normal)\n",
      "2025-11-21 18:40:23 - models.cnn.predictor - INFO - \n",
      "Extracting patches...\n",
      "2025-11-21 18:40:23 - models.cnn.patch_extractor - INFO - \n",
      "Extracting patches for full raster prediction...\n",
      "2025-11-21 18:40:23 - models.cnn.patch_extractor - INFO - Raster shape: 10919 x 12549\n",
      "2025-11-21 18:40:23 - models.cnn.patch_extractor - INFO - Patch size: 3x3, stride: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREDICTING FULL RASTER\n",
      "======================================================================\n",
      "\n",
      "Initializing RasterPredictor...\n",
      "  Device: cuda\n",
      "  Patch size: 3x3\n",
      "  Batch size: 8,000\n",
      "  Stride: 1\n",
      "\n",
      "üîÆ Starting prediction...\n",
      "   (This may take several minutes depending on image size)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:40:24 - models.cnn.patch_extractor - INFO - Total potential patches: 136,975,599\n",
      "2025-11-21 18:40:25 - models.cnn.patch_extractor - INFO - After center mask filter: 16,246,850\n",
      "2025-11-21 18:40:25 - models.cnn.patch_extractor - INFO - Processing 325 chunks of 50,000 patches...\n",
      "2025-11-21 18:40:45 - models.cnn.patch_extractor - INFO -   Processed 10/325 chunks...\n",
      "2025-11-21 18:41:05 - models.cnn.patch_extractor - INFO -   Processed 20/325 chunks...\n",
      "2025-11-21 18:41:24 - models.cnn.patch_extractor - INFO -   Processed 30/325 chunks...\n",
      "2025-11-21 18:41:44 - models.cnn.patch_extractor - INFO -   Processed 40/325 chunks...\n",
      "2025-11-21 18:42:03 - models.cnn.patch_extractor - INFO -   Processed 50/325 chunks...\n",
      "2025-11-21 18:42:23 - models.cnn.patch_extractor - INFO -   Processed 60/325 chunks...\n",
      "2025-11-21 18:42:43 - models.cnn.patch_extractor - INFO -   Processed 70/325 chunks...\n",
      "2025-11-21 18:43:03 - models.cnn.patch_extractor - INFO -   Processed 80/325 chunks...\n",
      "2025-11-21 18:43:23 - models.cnn.patch_extractor - INFO -   Processed 90/325 chunks...\n",
      "2025-11-21 18:43:42 - models.cnn.patch_extractor - INFO -   Processed 100/325 chunks...\n",
      "2025-11-21 18:44:02 - models.cnn.patch_extractor - INFO -   Processed 110/325 chunks...\n",
      "2025-11-21 18:44:21 - models.cnn.patch_extractor - INFO -   Processed 120/325 chunks...\n",
      "2025-11-21 18:44:40 - models.cnn.patch_extractor - INFO -   Processed 130/325 chunks...\n",
      "2025-11-21 18:45:00 - models.cnn.patch_extractor - INFO -   Processed 140/325 chunks...\n",
      "2025-11-21 18:45:19 - models.cnn.patch_extractor - INFO -   Processed 150/325 chunks...\n",
      "2025-11-21 18:45:39 - models.cnn.patch_extractor - INFO -   Processed 160/325 chunks...\n",
      "2025-11-21 18:45:58 - models.cnn.patch_extractor - INFO -   Processed 170/325 chunks...\n",
      "2025-11-21 18:46:18 - models.cnn.patch_extractor - INFO -   Processed 180/325 chunks...\n",
      "2025-11-21 18:46:37 - models.cnn.patch_extractor - INFO -   Processed 190/325 chunks...\n",
      "2025-11-21 18:46:56 - models.cnn.patch_extractor - INFO -   Processed 200/325 chunks...\n",
      "2025-11-21 18:47:16 - models.cnn.patch_extractor - INFO -   Processed 210/325 chunks...\n",
      "2025-11-21 18:47:35 - models.cnn.patch_extractor - INFO -   Processed 220/325 chunks...\n",
      "2025-11-21 18:47:55 - models.cnn.patch_extractor - INFO -   Processed 230/325 chunks...\n",
      "2025-11-21 18:48:14 - models.cnn.patch_extractor - INFO -   Processed 240/325 chunks...\n",
      "2025-11-21 18:48:33 - models.cnn.patch_extractor - INFO -   Processed 250/325 chunks...\n",
      "2025-11-21 18:48:53 - models.cnn.patch_extractor - INFO -   Processed 260/325 chunks...\n",
      "2025-11-21 18:49:12 - models.cnn.patch_extractor - INFO -   Processed 270/325 chunks...\n",
      "2025-11-21 18:49:31 - models.cnn.patch_extractor - INFO -   Processed 280/325 chunks...\n",
      "2025-11-21 18:49:51 - models.cnn.patch_extractor - INFO -   Processed 290/325 chunks...\n",
      "2025-11-21 18:50:10 - models.cnn.patch_extractor - INFO -   Processed 300/325 chunks...\n",
      "2025-11-21 18:50:30 - models.cnn.patch_extractor - INFO -   Processed 310/325 chunks...\n",
      "2025-11-21 18:50:49 - models.cnn.patch_extractor - INFO -   Processed 320/325 chunks...\n",
      "2025-11-21 18:51:27 - models.cnn.patch_extractor - INFO - Extracted 15,794,143 valid patches\n",
      "2025-11-21 18:51:28 - models.cnn.predictor - INFO - Normalizing patches...\n",
      "2025-11-21 18:52:10 - models.cnn.predictor - INFO - Computing normalization from prediction patches\n",
      "2025-11-21 18:53:38 - models.cnn.predictor - INFO - \n",
      "Predicting 15,794,143 patches...\n",
      "2025-11-21 18:54:01 - models.cnn.predictor - INFO -   Progress: 197/1975 batches (10.0%)\n",
      "2025-11-21 18:54:08 - models.cnn.predictor - INFO -   Progress: 394/1975 batches (19.9%)\n",
      "2025-11-21 18:54:16 - models.cnn.predictor - INFO -   Progress: 591/1975 batches (29.9%)\n",
      "2025-11-21 18:54:23 - models.cnn.predictor - INFO -   Progress: 788/1975 batches (39.9%)\n",
      "2025-11-21 18:54:30 - models.cnn.predictor - INFO -   Progress: 985/1975 batches (49.9%)\n",
      "2025-11-21 18:54:38 - models.cnn.predictor - INFO -   Progress: 1182/1975 batches (59.8%)\n",
      "2025-11-21 18:54:45 - models.cnn.predictor - INFO -   Progress: 1379/1975 batches (69.8%)\n",
      "2025-11-21 18:54:53 - models.cnn.predictor - INFO -   Progress: 1576/1975 batches (79.8%)\n",
      "2025-11-21 18:55:00 - models.cnn.predictor - INFO -   Progress: 1773/1975 batches (89.8%)\n",
      "2025-11-21 18:55:07 - models.cnn.predictor - INFO -   Progress: 1970/1975 batches (99.7%)\n",
      "2025-11-21 18:55:07 - models.cnn.predictor - INFO - Filling output map...\n",
      "2025-11-21 18:55:16 - models.cnn.predictor - INFO - Applying valid mask...\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO - \n",
      "======================================================================\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO - PREDICTION SUMMARY\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO - ======================================================================\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO - Total valid pixels: 16,246,850\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO - \n",
      "4-Class Predictions:\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO -   Class 0 (Forest Stable): 12,071,691 (74.30%)\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO -   Class 1 (Deforestation): 728,215 (4.48%)\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO -   Class 2 (Non-forest): 2,952,854 (18.17%)\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO -   Class 3 (Reforestation): 494,090 (3.04%)\n",
      "2025-11-21 18:55:18 - models.cnn.predictor - INFO - ======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Prediction completed in 902.07 seconds (15.03 minutes)\n",
      "  Output shape: (10919, 12549)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from models.cnn.predictor import RasterPredictor\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PREDICTING FULL RASTER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create predictor\n",
    "print(\"\\nInitializing RasterPredictor...\")\n",
    "predictor = RasterPredictor(\n",
    "    model=model,\n",
    "    device=CONFIG['device'],\n",
    "    patch_size=CONFIG['patch_size'],\n",
    "    batch_size=CONFIG['pred_batch_size']\n",
    ")\n",
    "\n",
    "print(f\"  Device: {CONFIG['device']}\")\n",
    "print(f\"  Patch size: {CONFIG['patch_size']}x{CONFIG['patch_size']}\")\n",
    "print(f\"  Batch size: {CONFIG['pred_batch_size']:,}\")\n",
    "print(f\"  Stride: {CONFIG['pred_stride']}\")\n",
    "\n",
    "# Predict\n",
    "print(f\"\\nüîÆ Starting prediction...\")\n",
    "print(\"   (This may take several minutes depending on image size)\\n\")\n",
    "\n",
    "prediction_start = time.time()\n",
    "\n",
    "multiclass_map = predictor.predict_raster(\n",
    "    feature_stack=feature_stack,\n",
    "    valid_mask=valid_mask,\n",
    "    stride=CONFIG['pred_stride'],\n",
    "    normalize=True,\n",
    "    normalization_stats=normalization_stats,  # Use training stats\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "prediction_time = time.time() - prediction_start\n",
    "\n",
    "print(f\"\\n‚úì Prediction completed in {prediction_time:.2f} seconds ({prediction_time/60:.2f} minutes)\")\n",
    "print(f\"  Output shape: {multiclass_map.shape}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5d21ca",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b317ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:55:25 - models.cnn.predictor - INFO - \n",
      "Saving output rasters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "Saving prediction raster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:55:26 - models.cnn.predictor - INFO -   Multiclass raster saved: ..\\results\\inference\\rasters\\prediction_multiclass_20251121_185525.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Raster saved successfully!\n",
      "  Multiclass map: prediction_multiclass_20251121_185525.tif\n",
      "  Metadata: metadata_20251121_185525.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Generate output filename with timestamp\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "multiclass_output_path = OUTPUT_DIR / 'rasters' / f'prediction_multiclass_{timestamp}.tif'\n",
    "\n",
    "print(f\"\\nSaving prediction raster...\")\n",
    "\n",
    "# Save multiclass map\n",
    "predictor.save_rasters(\n",
    "    reference_metadata=s2_metadata,\n",
    "    multiclass_path=multiclass_output_path\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Raster saved successfully!\")\n",
    "print(f\"  Multiclass map: {multiclass_output_path.name}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata_output = {\n",
    "    'timestamp': timestamp,\n",
    "    'input_files': {\n",
    "        's2_before': s2_before_path.name,\n",
    "        's2_after': s2_after_path.name,\n",
    "        's1_before': s1_before_path.name,\n",
    "        's1_after': s1_after_path.name\n",
    "    },\n",
    "    'model_path': str(MODEL_PATH),\n",
    "    'image_shape': s2_metadata['shape'],\n",
    "    'crs': str(s2_metadata['crs']),\n",
    "    'prediction_time_seconds': prediction_time,\n",
    "    'config': CONFIG\n",
    "}\n",
    "\n",
    "metadata_path = OUTPUT_DIR / f'metadata_{timestamp}.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata_output, f, indent=2)\n",
    "\n",
    "print(f\"  Metadata: {metadata_path.name}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301fffd",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Classification Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e39f8e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLASSIFICATION STATISTICS (4-Class)\n",
      "======================================================================\n",
      "\n",
      "Total pixels:\n",
      "  Valid pixels:          16,246,850\n",
      "  Invalid pixels:        120,775,681\n",
      "\n",
      "4-Class breakdown:\n",
      "  Class 0 - Forest Stable:    12,071,691 (74.30%)\n",
      "  Class 1 - Deforestation:    728,215 (4.48%)\n",
      "  Class 2 - Non-forest:       2,952,854 (18.17%)\n",
      "  Class 3 - Reforestation:    494,090 (3.04%)\n",
      "\n",
      "Area estimates (10m resolution):\n",
      "  Forest Stable area:    120716.91 ha\n",
      "  Deforestation area:    7282.15 ha\n",
      "  Non-forest area:       29528.54 ha\n",
      "  Reforestation area:    4940.90 ha\n",
      "  Total valid area:      162468.50 ha\n",
      "\n",
      "‚úì Statistics saved to: statistics_20251121_185525.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CLASSIFICATION STATISTICS (4-Class)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count pixels for each class\n",
    "class_0_pixels = np.sum(multiclass_map[valid_mask] == 0)  # Forest Stable\n",
    "class_1_pixels = np.sum(multiclass_map[valid_mask] == 1)  # Deforestation\n",
    "class_2_pixels = np.sum(multiclass_map[valid_mask] == 2)  # Non-forest\n",
    "class_3_pixels = np.sum(multiclass_map[valid_mask] == 3)  # Reforestation\n",
    "total_valid = np.sum(valid_mask)\n",
    "\n",
    "print(f\"\\nTotal pixels:\")\n",
    "print(f\"  Valid pixels:          {total_valid:,}\")\n",
    "print(f\"  Invalid pixels:        {np.sum(~valid_mask):,}\")\n",
    "\n",
    "print(f\"\\n4-Class breakdown:\")\n",
    "print(f\"  Class 0 - Forest Stable:    {class_0_pixels:,} ({class_0_pixels/total_valid*100:.2f}%)\")\n",
    "print(f\"  Class 1 - Deforestation:    {class_1_pixels:,} ({class_1_pixels/total_valid*100:.2f}%)\")\n",
    "print(f\"  Class 2 - Non-forest:       {class_2_pixels:,} ({class_2_pixels/total_valid*100:.2f}%)\")\n",
    "print(f\"  Class 3 - Reforestation:    {class_3_pixels:,} ({class_3_pixels/total_valid*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nArea estimates (10m resolution):\")\n",
    "print(f\"  Forest Stable area:    {class_0_pixels * 100 / 10000:.2f} ha\")\n",
    "print(f\"  Deforestation area:    {class_1_pixels * 100 / 10000:.2f} ha\")\n",
    "print(f\"  Non-forest area:       {class_2_pixels * 100 / 10000:.2f} ha\")\n",
    "print(f\"  Reforestation area:    {class_3_pixels * 100 / 10000:.2f} ha\")\n",
    "print(f\"  Total valid area:      {total_valid * 100 / 10000:.2f} ha\")\n",
    "\n",
    "# Save statistics\n",
    "stats_output = {\n",
    "    'timestamp': timestamp,\n",
    "    'total_pixels': int(total_valid),\n",
    "    'classes': {\n",
    "        'forest_stable': {'pixels': int(class_0_pixels), 'percent': float(class_0_pixels/total_valid*100), 'area_ha': float(class_0_pixels * 100 / 10000)},\n",
    "        'deforestation': {'pixels': int(class_1_pixels), 'percent': float(class_1_pixels/total_valid*100), 'area_ha': float(class_1_pixels * 100 / 10000)},\n",
    "        'non_forest': {'pixels': int(class_2_pixels), 'percent': float(class_2_pixels/total_valid*100), 'area_ha': float(class_2_pixels * 100 / 10000)},\n",
    "        'reforestation': {'pixels': int(class_3_pixels), 'percent': float(class_3_pixels/total_valid*100), 'area_ha': float(class_3_pixels * 100 / 10000)}\n",
    "    }\n",
    "}\n",
    "\n",
    "stats_path = OUTPUT_DIR / f'statistics_{timestamp}.json'\n",
    "with open(stats_path, 'w') as f:\n",
    "    json.dump(stats_output, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Statistics saved to: {stats_path.name}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6327f11",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9569052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:55:27 - core.visualization - INFO - \n",
      "Plotting 4-class multiclass map...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating visualization...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-21 18:56:22 - core.visualization - INFO -   ‚úì Saved to: ..\\results\\inference\\plots\\prediction_map_20251121_185525.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Visualization saved to: prediction_map_20251121_185525.png\n"
     ]
    }
   ],
   "source": [
    "from core.visualization import Visualizer\n",
    "\n",
    "print(\"Creating visualization...\\n\")\n",
    "\n",
    "# Initialize Visualizer\n",
    "visualizer = Visualizer()\n",
    "\n",
    "# Plot 4-class multiclass map\n",
    "plot_path = OUTPUT_DIR / 'plots' / f'prediction_map_{timestamp}.png'\n",
    "visualizer.plot_multiclass_map(\n",
    "    multiclass_map=multiclass_map,\n",
    "    valid_mask=valid_mask,\n",
    "    output_path=plot_path\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Visualization saved to: {plot_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7baa8",
   "metadata": {},
   "source": [
    "## üìä Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f50882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INFERENCE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "üìÖ INPUT DATA:\n",
      "  Sentinel-2 before: S2_2024_04_04.tif\n",
      "  Sentinel-2 after:  S2_2025_04_04.tif\n",
      "  Sentinel-1 before: S1_2024_04_04_matched_S2_2024_04_04.tif\n",
      "  Sentinel-1 after:  S1_2025_04_05_matched_S2_2025_04_04.tif\n",
      "\n",
      "ü§ñ MODEL:\n",
      "  Model path: ..\\results\\models\\cnn_final_model.pth\n",
      "  Device: cuda\n",
      "  Parameters: 36,676\n",
      "\n",
      "üìä RESULTS:\n",
      "  Total area classified: 162468.50 ha\n",
      "  Forest Stable:    120716.91 ha (74.3%)\n",
      "  Deforestation:     7282.15 ha (4.5%)\n",
      "  Non-forest:       29528.54 ha (18.2%)\n",
      "  Reforestation:     4940.90 ha (3.0%)\n",
      "\n",
      "‚è±Ô∏è  EXECUTION TIME:\n",
      "  Prediction: 902.07 seconds (15.03 minutes)\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "  Rasters:\n",
      "    - prediction_multiclass_20251121_185525.tif\n",
      "  Data:\n",
      "    - metadata_20251121_185525.json\n",
      "    - statistics_20251121_185525.json\n",
      "  Plots:\n",
      "    - prediction_map_20251121_185525.png\n",
      "\n",
      "üìç OUTPUT LOCATION:\n",
      "  d:\\ninhhaidang\\25-26_HKI_DATN_21021411_DangNH\\notebook\\..\\results\\inference\n",
      "\n",
      "‚úÖ All files saved successfully!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INFERENCE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìÖ INPUT DATA:\")\n",
    "print(f\"  Sentinel-2 before: {s2_before_path.name}\")\n",
    "print(f\"  Sentinel-2 after:  {s2_after_path.name}\")\n",
    "print(f\"  Sentinel-1 before: {s1_before_path.name}\")\n",
    "print(f\"  Sentinel-1 after:  {s1_after_path.name}\")\n",
    "\n",
    "print(\"\\nü§ñ MODEL:\")\n",
    "print(f\"  Model path: {MODEL_PATH}\")\n",
    "print(f\"  Device: {CONFIG['device']}\")\n",
    "print(f\"  Parameters: {total_params:,}\")\n",
    "\n",
    "print(\"\\nüìä RESULTS:\")\n",
    "print(f\"  Total area classified: {total_valid * 100 / 10000:.2f} ha\")\n",
    "print(f\"  Forest Stable:    {class_0_pixels * 100 / 10000:8.2f} ha ({class_0_pixels/total_valid*100:.1f}%)\")\n",
    "print(f\"  Deforestation:    {class_1_pixels * 100 / 10000:8.2f} ha ({class_1_pixels/total_valid*100:.1f}%)\")\n",
    "print(f\"  Non-forest:       {class_2_pixels * 100 / 10000:8.2f} ha ({class_2_pixels/total_valid*100:.1f}%)\")\n",
    "print(f\"  Reforestation:    {class_3_pixels * 100 / 10000:8.2f} ha ({class_3_pixels/total_valid*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è  EXECUTION TIME:\")\n",
    "print(f\"  Prediction: {prediction_time:.2f} seconds ({prediction_time/60:.2f} minutes)\")\n",
    "\n",
    "print(\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"  Rasters:\")\n",
    "print(f\"    - {multiclass_output_path.name}\")\n",
    "print(f\"  Data:\")\n",
    "print(f\"    - {metadata_path.name}\")\n",
    "print(f\"    - {stats_path.name}\")\n",
    "print(f\"  Plots:\")\n",
    "print(f\"    - {plot_path.name}\")\n",
    "\n",
    "print(\"\\nüìç OUTPUT LOCATION:\")\n",
    "print(f\"  {OUTPUT_DIR.absolute()}\")\n",
    "\n",
    "print(\"\\n‚úÖ All files saved successfully!\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
