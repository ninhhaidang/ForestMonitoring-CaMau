\section{Phương pháp nghiên cứu}

Phần này trình bày phương pháp nghiên cứu và quy trình được minh họa trong Hình~\ref{fig:methodology-flowchart}. Quy trình bao gồm năm giai đoạn chính: thu thập và tiền xử lý dữ liệu, trích xuất đặc trưng, chuẩn bị mẫu huấn luyện, huấn luyện mô hình, và áp dụng mô hình.

% Sơ đồ quy trình phương pháp nghiên cứu
\begin{figure}[H]
\centering
\includegraphics[width=0.9425\textwidth]{img/chapter3/flowchart.png}
\caption{Sơ đồ quy trình phương pháp nghiên cứu phát hiện biến động rừng}
\label{fig:methodology-flowchart}
\end{figure}

\subsection{Trích xuất đặc trưng}

\subsubsection{Xây dựng feature stack}

Việc kết hợp dữ liệu SAR và quang học (data fusion) đã được chứng minh là hiệu quả trong nhiều nghiên cứu phân loại lớp phủ đất \citeen{ienco2019, hu2020}. Cách tiếp cận này tận dụng ưu điểm bổ sung của hai nguồn dữ liệu: SAR cung cấp thông tin về cấu trúc và độ ẩm bề mặt, trong khi quang học cung cấp thông tin về đặc tính quang phổ của thực vật.

Tổng cộng 27 features được xây dựng từ hai nguồn dữ liệu. \textbf{Sentinel-2} đóng góp 21 features, bao gồm 7 bands/chỉ số (B4, B8, B11, B12, NDVI, NBR, NDMI) cho kỳ trước, 7 bands/chỉ số tương ứng cho kỳ sau, và 7 giá trị delta (hiệu số giữa kỳ sau và kỳ trước). \textbf{Sentinel-1} đóng góp 6 features, bao gồm 2 bands (VV, VH) cho kỳ trước, 2 bands tương ứng cho kỳ sau, và 2 giá trị delta.

\begin{table}[H]
\centering
\caption{Chi tiết 27 đặc trưng sử dụng trong mô hình}
\label{tab:features_detail}
\begin{tabular}{|c|c|c|l|l|}
\hline
\textbf{Chỉ số} & \textbf{Nguồn} & \textbf{Thời kỳ} & \textbf{Đặc trưng} & \textbf{Mô tả} \\
\hline
0-6 & S2 & Kỳ trước & B4, B8, B11, B12, NDVI, NBR, NDMI & Quang phổ kỳ trước \\
\hline
7-13 & S2 & Kỳ sau & B4, B8, B11, B12, NDVI, NBR, NDMI & Quang phổ kỳ sau \\
\hline
14-20 & S2 & Biến đổi & $\Delta$B4, $\Delta$B8, ... & Biến đổi quang phổ \\
\hline
21-22 & S1 & Kỳ trước & VV, VH & SAR kỳ trước \\
\hline
23-24 & S1 & Kỳ sau & VV, VH & SAR kỳ sau \\
\hline
25-26 & S1 & Biến đổi & $\Delta$VV, $\Delta$VH & Biến đổi SAR \\
\hline
\end{tabular}
\end{table}

\subsubsection{Trích xuất patch 3×3}

Với mỗi điểm thực địa, một patch kích thước 3×3 pixels được trích xuất từ feature stack. Kích thước 3×3 được lựa chọn vì cho phép mô hình học được thông tin ngữ cảnh không gian xung quanh pixel trung tâm, phù hợp với độ phân giải 10m của Sentinel (mỗi patch tương đương vùng 30m × 30m), và giảm thiểu nhiễu từ các pixel lân cận không đồng nhất.

Kết quả là mỗi mẫu có kích thước (3, 3, 27) — tương ứng với chiều cao, chiều rộng và số kênh đặc trưng.

\subsection{Chuẩn bị mẫu huấn luyện}

\subsubsection{Chuẩn hóa dữ liệu}

Việc chuẩn hóa dữ liệu là bước quan trọng để đảm bảo các features có cùng phạm vi giá trị, giúp quá trình huấn luyện mô hình hội tụ nhanh và ổn định hơn. Nghiên cứu này áp dụng phương pháp chuẩn hóa Z-score:

\begin{equation}
x_{normalized} = \frac{x - \mu}{\sigma}
\end{equation}

trong đó $x$ là giá trị gốc, $\mu$ là giá trị trung bình và $\sigma$ là độ lệch chuẩn.

Để đảm bảo tính khoa học và tránh hiện tượng rò rỉ dữ liệu, các tham số chuẩn hóa ($\mu$ và $\sigma$) được tính toán chỉ trên tập huấn luyện theo quy trình bốn bước. Đầu tiên, stratified split được thực hiện để tách 20\% dữ liệu làm tập test cố định trước khi tính toán bất kỳ thống kê nào. Tiếp theo, mean và std được tính cho từng feature trên tập training. Sau đó, các tham số đã tính được sử dụng để chuẩn hóa cả tập training, validation và test. Cuối cùng, các tham số được lưu lại để áp dụng cho dữ liệu mới khi dự đoán.

\subsubsection{Phân chia dữ liệu}

Chiến lược chia dữ liệu được thiết kế theo khuyến nghị của Roberts et al. \citeen{roberts2017} về cross-validation cho dữ liệu không gian, đảm bảo đánh giá khách quan. Quy trình chia dữ liệu bao gồm bốn bước. Bước thứ nhất, tách 20\% dữ liệu làm tập test cố định (526 mẫu) — tập này không được sử dụng trong quá trình huấn luyện hay tinh chỉnh siêu tham số. Bước thứ hai, áp dụng 5-Fold Cross Validation trên 80\% còn lại (2,104 mẫu) để tìm kiếm siêu tham số tối ưu và đánh giá độ ổn định của mô hình. Bước thứ ba, huấn luyện mô hình cuối cùng trên toàn bộ 80\% dữ liệu training. Bước thứ tư, đánh giá mô hình cuối cùng trên 20\% tập test để báo cáo kết quả.

Việc sử dụng stratified sampling đảm bảo tỷ lệ các lớp (Rừng ổn định, Mất rừng, Phi rừng, Phục hồi rừng) được duy trì đồng đều trong cả tập training và test.

\subsection{Kiến trúc mô hình CNN}

Mô hình nhận đầu vào là tensor kích thước (batch\_size, 3, 3, 27), sau đó được chuyển đổi sang định dạng PyTorch (batch\_size, 27, 3, 3). Kiến trúc bao gồm năm thành phần chính. Thành phần thứ nhất là khối tích chập 1 gồm Conv2D (64 filters, kernel 3×3), BatchNorm2D, ReLU và Dropout2D (p=0.7). Thành phần thứ hai là khối tích chập 2 gồm Conv2D (32 filters, kernel 3×3), BatchNorm2D, ReLU và Dropout2D (p=0.7). Thành phần thứ ba là lớp Global Average Pooling có chức năng gộp thông tin không gian. Thành phần thứ tư là khối kết nối đầy đủ gồm Linear (32→64), BatchNorm1D, ReLU và Dropout (p=0.7). Thành phần thứ năm là lớp đầu ra Linear (64→4) cho 4 lớp phân loại.

Với 36,676 tham số, mô hình có độ phức tạp vừa phải, phù hợp với quy mô bộ dữ liệu 2,630 mẫu. Kiến trúc tổng quan của mô hình được minh họa trong Hình~\ref{fig:cnn_architecture}.

\begin{figure}[H]
\centering
\includegraphics[width=0.95\textwidth]{CNN-architecture.png}
\caption{Kiến trúc mô hình mạng nơ-ron tích chập (CNN) được sử dụng trong nghiên cứu}
\label{fig:cnn_architecture}
\end{figure}

\begin{table}[H]
\centering
\caption{Chi tiết số tham số huấn luyện của mô hình}
\label{tab:model_params}
\begin{tabular}{|l|c|l|}
\hline
\textbf{Lớp} & \textbf{Số tham số} & \textbf{Cách tính} \\
\hline
Tích chập 1 + Chuẩn hóa batch 1 & 15,680 & 27×3×3×64 + 128 \\
\hline
Tích chập 2 + Chuẩn hóa batch 2 & 18,496 & 64×3×3×32 + 64 \\
\hline
Kết nối đầy đủ 1 + Chuẩn hóa batch 3 & 2,240 & 32×64 + 64 + 128 \\
\hline
Kết nối đầy đủ 2 (Đầu ra) & 260 & 64×4 + 4 \\
\hline
\textbf{Tổng cộng} & \textbf{36,676} & \\
\hline
\end{tabular}
\end{table}

\subsection{Chiến lược điều chuẩn và huấn luyện}

Với bộ dữ liệu có quy mô nhỏ, nghiên cứu kết hợp ba kỹ thuật điều chuẩn. Kỹ thuật thứ nhất là chuẩn hóa theo lô (Batch Normalization) \citeen{ioffe2015} được áp dụng sau mỗi lớp tích chập và fully-connected. Kỹ thuật thứ hai là Dropout với tỷ lệ 70\% \citeen{srivastava2014} --- tỷ lệ cao do tỷ lệ mẫu/tham số thấp (khoảng 72:1). Kỹ thuật thứ ba là phân rã trọng số với hệ số $\lambda = 10^{-3}$ thông qua optimizer AdamW.

\begin{table}[H]
\centering
\caption{Cấu hình siêu tham số huấn luyện}
\label{tab:hyperparams}
\begin{tabular}{|l|c|l|}
\hline
\textbf{Tham số} & \textbf{Giá trị} & \textbf{Giải thích} \\
\hline
epochs & 200 & Số epochs tối đa với early stopping \\
\hline
batch\_size & 64 & Cân bằng giữa độ ổn định và tốc độ \\
\hline
learning\_rate & 0.001 & Learning rate khởi tạo cho AdamW \\
\hline
weight\_decay & $10^{-3}$ & Hệ số điều chuẩn L2 \\
\hline
dropout\_rate & 0.7 & Dropout cao để điều chuẩn mạnh \\
\hline
early\_stopping & 15 epochs & Patience trước khi dừng sớm \\
\hline
\end{tabular}
\end{table}

Nghiên cứu sử dụng AdamW \citeen{loshchilov2019} — biến thể cải tiến của Adam với phân rã trọng số tách rời. ReduceLROnPlateau scheduler tự động giảm learning rate (factor=0.5, patience=10) khi validation loss không cải thiện.

Quy trình huấn luyện được thực hiện qua bốn bước. Đầu tiên, trọng số được khởi tạo theo phương pháp Kaiming/He initialization \citeen{he2015}. Tiếp theo, 5-Fold Cross Validation được thực hiện trên 80\% dữ liệu để đánh giá độ ổn định của mô hình. Sau đó, Final Model được huấn luyện trên toàn bộ 80\% dữ liệu với cơ chế early stopping. Cuối cùng, mô hình được đánh giá trên 20\% test set cố định.

\subsection{Áp dụng mô hình}

Sau khi huấn luyện, mô hình được áp dụng để phân loại toàn bộ vùng nghiên cứu với khoảng 16.2 triệu pixels hợp lệ. Quy trình dự đoán bắt đầu bằng việc tải feature stack 27 channels cho toàn vùng, sau đó trích xuất patch 3×3 cho mỗi pixel hợp lệ. Các patches được chuẩn hóa Z-score sử dụng mean và std từ tập training, rồi thực hiện forward pass qua mô hình và lấy argmax để xác định lớp phân loại. Kết quả cuối cùng được xuất dưới dạng GeoTIFF.

Do kích thước lớn của vùng nghiên cứu, việc dự đoán được thực hiện theo batch (10,000 pixels) với GPU inference và mixed precision (FP16) để tối ưu hóa bộ nhớ và tốc độ.
