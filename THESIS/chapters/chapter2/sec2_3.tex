\section{Phương pháp phân loại ảnh viễn thám}

\subsection{Pixel-based vs Patch-based Classification}

\textbf{Pixel-based Classification:}

Mỗi pixel được phân loại độc lập dựa trên vector đặc trưng:
\begin{equation}
\mathbf{x}_i = [f_1, f_2, ..., f_n], \quad y_i = \text{classifier}(\mathbf{x}_i)
\end{equation}

\textbf{Ưu điểm:} Đơn giản, dễ triển khai, tốc độ xử lý nhanh.

\textbf{Nhược điểm:} Không tận dụng ngữ cảnh không gian, dễ tạo ra nhiễu dạng salt-and-pepper.

\textbf{Patch-based Classification:}

Trích xuất patches (windows) xung quanh mỗi pixel:
\begin{equation}
P_i = \text{extract\_patch}(I, \text{center}=(row_i, col_i), \text{size}=k \times k)
\end{equation}
\begin{equation}
y_i = \text{classifier}(P_i)
\end{equation}

\textbf{Ưu điểm:} Sử dụng ngữ cảnh không gian, kết quả mượt hơn, phù hợp với CNN.

\subsection{Confusion Matrix}

Confusion Matrix (Ma trận nhầm lẫn) là công cụ cơ bản để đánh giá hiệu suất của mô hình phân loại, đặc biệt quan trọng trong các bài toán phân loại ảnh viễn thám \cite{foody2002}. Ma trận này tổng hợp kết quả dự đoán của mô hình so với nhãn thực tế.

\textbf{Cấu trúc Confusion Matrix (cho bài toán nhị phân):}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
& \textbf{Predicted Positive} & \textbf{Predicted Negative} \\
\hline
\textbf{Actual Positive} & True Positive (TP) & False Negative (FN) \\
\hline
\textbf{Actual Negative} & False Positive (FP) & True Negative (TN) \\
\hline
\end{tabular}
\caption{Cấu trúc Confusion Matrix nhị phân}
\label{tab:confusion_matrix_binary}
\end{table}

\textbf{Các thành phần của Confusion Matrix:}

\begin{itemize}
    \item \textbf{True Positive (TP)}: Số mẫu dương được dự đoán đúng là dương. Trong bài toán phát hiện mất rừng, đây là các điểm thực sự mất rừng và mô hình dự đoán đúng.
    \item \textbf{True Negative (TN)}: Số mẫu âm được dự đoán đúng là âm. Các điểm không mất rừng được mô hình nhận diện chính xác.
    \item \textbf{False Positive (FP)}: Số mẫu âm bị dự đoán nhầm là dương (lỗi loại I). Các điểm không mất rừng nhưng bị mô hình phân loại nhầm là mất rừng.
    \item \textbf{False Negative (FN)}: Số mẫu dương bị dự đoán nhầm là âm (lỗi loại II). Các điểm thực sự mất rừng nhưng mô hình không phát hiện được.
\end{itemize}

\textbf{Confusion Matrix đa lớp:}

Với bài toán phân loại $K$ lớp (như trong nghiên cứu này với 4 lớp), Confusion Matrix có kích thước $K \times K$:
\begin{equation}
C_{ij} = \text{số mẫu thuộc lớp } i \text{ được dự đoán là lớp } j
\end{equation}

Các phần tử trên đường chéo chính ($C_{ii}$) biểu thị số mẫu được phân loại đúng. Tổng các phần tử ngoài đường chéo biểu thị tổng số lỗi phân loại.

\subsection{Evaluation Metrics}

Các chỉ số đánh giá được tính toán dựa trên Confusion Matrix để đo lường hiệu suất phân loại từ nhiều góc độ khác nhau \cite{sokolova2009}.

\textbf{Accuracy:}
\begin{equation}
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\textbf{Precision (Positive Predictive Value):}
\begin{equation}
\text{Precision} = \frac{TP}{TP + FP}
\end{equation}

\textbf{Recall (Sensitivity, True Positive Rate):}
\begin{equation}
\text{Recall} = \frac{TP}{TP + FN}
\end{equation}

\textbf{F1-Score (Harmonic Mean):}
\begin{equation}
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

\textbf{ROC-AUC (Area Under ROC Curve):}

Các tiêu chuẩn diễn giải ROC-AUC theo Hosmer và Lemeshow \cite{hosmer2013}: AUC = 0.5 tương ứng với classifier ngẫu nhiên; 0.5 < AUC < 0.7 là phân biệt kém; 0.7 $\leq$ AUC < 0.8 là chấp nhận được; 0.8 $\leq$ AUC < 0.9 là xuất sắc; và AUC $\geq$ 0.9 là vượt trội.

\subsection{Cross Validation}

Cross Validation (Kiểm định chéo) là phương pháp đánh giá mô hình giúp ước lượng khả năng generalization của mô hình trên dữ liệu chưa thấy, đồng thời giảm thiểu bias do cách chia dữ liệu \cite{kohavi1995}.

\textbf{K-Fold Cross Validation:}

Dữ liệu được chia thành $K$ phần (folds) bằng nhau. Trong mỗi vòng lặp, một fold được sử dụng làm tập kiểm tra và $K-1$ folds còn lại làm tập huấn luyện:
\begin{equation}
\text{CV Score} = \frac{1}{K} \sum_{i=1}^{K} \text{Score}_i
\end{equation}

Trong đó, $\text{Score}_i$ là kết quả đánh giá trên fold thứ $i$. Phương pháp này đảm bảo mọi mẫu đều được sử dụng để kiểm tra đúng một lần.

\textbf{Stratified K-Fold Cross Validation:}

Stratified K-Fold là biến thể của K-Fold, đảm bảo tỷ lệ các lớp trong mỗi fold tương đương với tỷ lệ trong toàn bộ tập dữ liệu. Điều này đặc biệt quan trọng khi dữ liệu có sự mất cân bằng giữa các lớp (imbalanced data).

Ví dụ: Nếu tập dữ liệu có 80\% lớp ``Rừng ổn định'' và 5\% lớp ``Mất rừng'', Stratified K-Fold đảm bảo mỗi fold cũng duy trì tỷ lệ này, giúp mô hình được đánh giá công bằng trên tất cả các lớp.

\textbf{Ưu điểm của Cross Validation:}
\begin{itemize}
    \item Tận dụng tối đa dữ liệu cho cả huấn luyện và đánh giá
    \item Giảm variance trong ước lượng hiệu suất
    \item Phát hiện overfitting hiệu quả hơn so với chia train/test đơn giản
\end{itemize}

\subsection{Data Normalization}

Chuẩn hóa dữ liệu (Data Normalization) là bước tiền xử lý quan trọng trong học máy, giúp các features có cùng scale và cải thiện hiệu suất huấn luyện \cite{sola1997}.

\textbf{Z-score Normalization (Standardization):}

Z-score chuyển đổi dữ liệu về phân phối với trung bình bằng 0 và độ lệch chuẩn bằng 1:
\begin{equation}
z = \frac{x - \mu}{\sigma}
\end{equation}

Trong đó, $x$ là giá trị gốc, $\mu$ là trung bình của feature và $\sigma$ là độ lệch chuẩn. Sau chuẩn hóa, khoảng 68\% dữ liệu nằm trong $[-1, 1]$ và 95\% nằm trong $[-2, 2]$.

\textbf{Tại sao cần chuẩn hóa cho CNN:}
\begin{itemize}
    \item Các features có scale khác nhau (ví dụ: NDVI trong $[-1, 1]$, backscatter trong $[-25, 0]$ dB) sẽ ảnh hưởng không đều đến gradient
    \item Chuẩn hóa giúp gradient descent hội tụ nhanh hơn
    \item Tránh các vấn đề số học như overflow/underflow
    \item Batch Normalization hoạt động hiệu quả hơn khi input đã được chuẩn hóa
\end{itemize}

\textbf{Lưu ý quan trọng:} Các tham số $\mu$ và $\sigma$ phải được tính trên tập huấn luyện và áp dụng cho cả tập kiểm tra. Việc tính $\mu$, $\sigma$ trên toàn bộ dữ liệu (bao gồm cả test set) sẽ gây ra data leakage.

\subsection{Ground Truth và Data Leakage}

\textbf{Ground Truth (Dữ liệu mẫu):}

Ground Truth là tập dữ liệu tham chiếu với nhãn chính xác, được sử dụng để huấn luyện và đánh giá mô hình phân loại \cite{foody2002}. Trong viễn thám, Ground Truth có thể thu thập từ nhiều nguồn:
\begin{itemize}
    \item Khảo sát thực địa (field survey): Đáng tin cậy nhất nhưng tốn kém
    \item Diễn giải ảnh độ phân giải cao: Sử dụng ảnh Google Earth, máy bay không người lái
    \item Dữ liệu lịch sử: Bản đồ quy hoạch rừng, số liệu kiểm kê
\end{itemize}

Chất lượng Ground Truth ảnh hưởng trực tiếp đến độ tin cậy của kết quả phân loại. Ground Truth không chính xác hoặc không đại diện sẽ dẫn đến mô hình học sai và đánh giá không phản ánh thực tế.

\textbf{Data Leakage (Rò rỉ dữ liệu):}

Data Leakage xảy ra khi thông tin từ tập kiểm tra ``rò rỉ'' vào quá trình huấn luyện, dẫn đến kết quả đánh giá quá lạc quan và mô hình không generalize tốt trên dữ liệu thực tế \cite{kaufman2012}.

\textbf{Các dạng Data Leakage phổ biến trong viễn thám:}
\begin{itemize}
    \item \textbf{Spatial leakage}: Các điểm huấn luyện và kiểm tra nằm gần nhau về mặt địa lý, dẫn đến spatial autocorrelation. Giải pháp: chia dữ liệu theo vùng địa lý hoặc đảm bảo khoảng cách tối thiểu giữa train/test.
    \item \textbf{Temporal leakage}: Sử dụng thông tin từ thời điểm sau để dự đoán thời điểm trước. Giải pháp: chia dữ liệu theo thời gian, đảm bảo tập huấn luyện chỉ chứa dữ liệu trước tập kiểm tra.
    \item \textbf{Feature leakage}: Tính toán statistics (mean, std) trên toàn bộ dữ liệu thay vì chỉ trên tập huấn luyện. Giải pháp: fit scaler trên train set, transform cả train và test.
\end{itemize}

Trong nghiên cứu này, data leakage được phòng tránh bằng cách sử dụng Stratified K-Fold Cross Validation và tính toán các tham số chuẩn hóa riêng cho từng fold.