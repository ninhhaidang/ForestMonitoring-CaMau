\section{Phương pháp phân loại ảnh viễn thám}

\subsection{Pixel-based vs Patch-based Classification}

Trong phân loại ảnh viễn thám, có hai phương pháp tiếp cận chính: phân loại dựa trên pixel và phân loại dựa trên patch \cite{blaschke2010, zhang2016}.

\textbf{Pixel-based Classification:}

Mỗi pixel được phân loại độc lập dựa trên vector đặc trưng:
\begin{equation}
\mathbf{x}_i = [f_1, f_2, ..., f_n], \quad y_i = \text{classifier}(\mathbf{x}_i)
\end{equation}

\textbf{Ưu điểm:} Đơn giản, dễ triển khai, tốc độ xử lý nhanh.

\textbf{Nhược điểm:} Không tận dụng ngữ cảnh không gian, dễ tạo ra nhiễu dạng salt-and-pepper.

\textbf{Patch-based Classification:}

Trích xuất patches (windows) xung quanh mỗi pixel:
\begin{equation}
P_i = \text{extract\_patch}(I, \text{center}=(row_i, col_i), \text{size}=k \times k)
\end{equation}
\begin{equation}
y_i = \text{classifier}(P_i)
\end{equation}

\textbf{Ưu điểm:} Sử dụng ngữ cảnh không gian, kết quả mượt hơn, phù hợp với CNN.

\subsection{Confusion Matrix}

Confusion Matrix (Ma trận nhầm lẫn) là công cụ cơ bản để đánh giá hiệu suất của mô hình phân loại, đặc biệt quan trọng trong các bài toán phân loại ảnh viễn thám \cite{foody2002}. Ma trận này tổng hợp kết quả dự đoán của mô hình so với nhãn thực tế.

\textbf{Cấu trúc Confusion Matrix (cho bài toán nhị phân):}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
& \textbf{Predicted Positive} & \textbf{Predicted Negative} \\
\hline
\textbf{Actual Positive} & True Positive (TP) & False Negative (FN) \\
\hline
\textbf{Actual Negative} & False Positive (FP) & True Negative (TN) \\
\hline
\end{tabular}
\caption{Cấu trúc Confusion Matrix nhị phân}
\label{tab:confusion_matrix_binary}
\end{table}

\textbf{Các thành phần của Confusion Matrix:}

Ma trận nhầm lẫn bao gồm bốn thành phần chính. \textbf{True Positive (TP)} là số mẫu dương được dự đoán đúng là dương — trong bài toán phát hiện mất rừng, đây là các điểm thực sự mất rừng và mô hình dự đoán đúng. \textbf{True Negative (TN)} là số mẫu âm được dự đoán đúng là âm, tức các điểm không mất rừng được mô hình nhận diện chính xác. \textbf{False Positive (FP)} là số mẫu âm bị dự đoán nhầm là dương (lỗi loại I), tức các điểm không mất rừng nhưng bị mô hình phân loại nhầm là mất rừng. \textbf{False Negative (FN)} là số mẫu dương bị dự đoán nhầm là âm (lỗi loại II), tức các điểm thực sự mất rừng nhưng mô hình không phát hiện được.

\textbf{Confusion Matrix đa lớp:}

Với bài toán phân loại $K$ lớp (như trong nghiên cứu này với 4 lớp), Confusion Matrix có kích thước $K \times K$:
\begin{equation}
C_{ij} = \text{số mẫu thuộc lớp } i \text{ được dự đoán là lớp } j
\end{equation}

Các phần tử trên đường chéo chính ($C_{ii}$) biểu thị số mẫu được phân loại đúng. Tổng các phần tử ngoài đường chéo biểu thị tổng số lỗi phân loại.

\subsection{Evaluation Metrics}

Các chỉ số đánh giá được tính toán dựa trên Confusion Matrix để đo lường hiệu suất phân loại từ nhiều góc độ khác nhau \cite{sokolova2009}.

\textbf{Accuracy:}
\begin{equation}
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\textbf{Precision (Positive Predictive Value):}
\begin{equation}
\text{Precision} = \frac{TP}{TP + FP}
\end{equation}

\textbf{Recall (Sensitivity, True Positive Rate):}
\begin{equation}
\text{Recall} = \frac{TP}{TP + FN}
\end{equation}

\textbf{F1-Score (Harmonic Mean):}
\begin{equation}
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

\textbf{ROC-AUC (Area Under ROC Curve):}

Các tiêu chuẩn diễn giải ROC-AUC theo Hosmer và Lemeshow \cite{hosmer2013}: AUC = 0.5 tương ứng với classifier ngẫu nhiên; 0.5 < AUC < 0.7 là phân biệt kém; 0.7 $\leq$ AUC < 0.8 là chấp nhận được; 0.8 $\leq$ AUC < 0.9 là xuất sắc; và AUC $\geq$ 0.9 là vượt trội.

\subsection{Cross Validation}

Cross Validation (Kiểm định chéo) là phương pháp đánh giá mô hình giúp ước lượng khả năng generalization của mô hình trên dữ liệu chưa thấy, đồng thời giảm thiểu bias do cách chia dữ liệu \cite{kohavi1995}.

\textbf{K-Fold Cross Validation:}

Dữ liệu được chia thành $K$ phần (folds) bằng nhau. Trong mỗi vòng lặp, một fold được sử dụng làm tập kiểm tra và $K-1$ folds còn lại làm tập huấn luyện:
\begin{equation}
\text{CV Score} = \frac{1}{K} \sum_{i=1}^{K} \text{Score}_i
\end{equation}

Trong đó, $\text{Score}_i$ là kết quả đánh giá trên fold thứ $i$. Phương pháp này đảm bảo mọi mẫu đều được sử dụng để kiểm tra đúng một lần.

\textbf{Stratified K-Fold Cross Validation:}

Stratified K-Fold là biến thể của K-Fold, đảm bảo tỷ lệ các lớp trong mỗi fold tương đương với tỷ lệ trong toàn bộ tập dữ liệu. Điều này đặc biệt quan trọng khi dữ liệu có sự mất cân bằng giữa các lớp (imbalanced data).

Ví dụ: Nếu tập dữ liệu có 80\% lớp ``Rừng ổn định'' và 5\% lớp ``Mất rừng'', Stratified K-Fold đảm bảo mỗi fold cũng duy trì tỷ lệ này, giúp mô hình được đánh giá công bằng trên tất cả các lớp.

\textbf{Ưu điểm của Cross Validation:}

Cross Validation mang lại nhiều lợi ích quan trọng: tận dụng tối đa dữ liệu cho cả huấn luyện và đánh giá, giảm variance trong ước lượng hiệu suất, và phát hiện overfitting hiệu quả hơn so với chia train/test đơn giản.

\subsection{Data Normalization}

Chuẩn hóa dữ liệu (Data Normalization) là bước tiền xử lý quan trọng trong học máy, giúp các features có cùng scale và cải thiện hiệu suất huấn luyện \cite{sola1997}.

\textbf{Z-score Normalization (Standardization):}

Z-score chuyển đổi dữ liệu về phân phối với trung bình bằng 0 và độ lệch chuẩn bằng 1:
\begin{equation}
z = \frac{x - \mu}{\sigma}
\end{equation}

Trong đó, $x$ là giá trị gốc, $\mu$ là trung bình của feature và $\sigma$ là độ lệch chuẩn. Sau chuẩn hóa, khoảng 68\% dữ liệu nằm trong $[-1, 1]$ và 95\% nằm trong $[-2, 2]$.

\textbf{Tại sao cần chuẩn hóa cho CNN:}

Việc chuẩn hóa dữ liệu cho CNN là cần thiết vì các features có scale khác nhau (ví dụ: NDVI trong $[-1, 1]$, backscatter trong $[-25, 0]$ dB) sẽ ảnh hưởng không đều đến gradient. Chuẩn hóa giúp gradient descent hội tụ nhanh hơn, tránh các vấn đề số học như overflow/underflow, và Batch Normalization hoạt động hiệu quả hơn khi input đã được chuẩn hóa.

\textbf{Lưu ý quan trọng:} Các tham số $\mu$ và $\sigma$ phải được tính trên tập huấn luyện và áp dụng cho cả tập kiểm tra. Việc tính $\mu$, $\sigma$ trên toàn bộ dữ liệu (bao gồm cả test set) sẽ gây ra rò rỉ dữ liệu.

\subsection{Dữ liệu thực địa và Rò rỉ dữ liệu}

\textbf{Dữ liệu thực địa (Ground Truth):}

Dữ liệu thực địa là tập dữ liệu tham chiếu với nhãn chính xác, được sử dụng để huấn luyện và đánh giá mô hình phân loại \cite{foody2002}. Trong viễn thám, dữ liệu thực địa có thể thu thập từ nhiều nguồn: khảo sát thực địa (field survey) là phương pháp đáng tin cậy nhất nhưng tốn kém; diễn giải ảnh độ phân giải cao sử dụng ảnh Google Earth hoặc máy bay không người lái; và dữ liệu lịch sử như bản đồ quy hoạch rừng, số liệu kiểm kê.

Chất lượng dữ liệu thực địa ảnh hưởng trực tiếp đến độ tin cậy của kết quả phân loại. Dữ liệu thực địa không chính xác hoặc không đại diện sẽ dẫn đến mô hình học sai và đánh giá không phản ánh thực tế.

\textbf{Rò rỉ dữ liệu (Data Leakage):}

Rò rỉ dữ liệu xảy ra khi thông tin từ tập kiểm tra ``rò rỉ'' vào quá trình huấn luyện, dẫn đến kết quả đánh giá quá lạc quan và mô hình không generalize tốt trên dữ liệu thực tế \cite{kaufman2012}.

\textbf{Các dạng rò rỉ dữ liệu phổ biến trong viễn thám:}

Có ba dạng rò rỉ dữ liệu phổ biến trong viễn thám. \textbf{Rò rỉ không gian (Spatial leakage)} xảy ra khi các điểm huấn luyện và kiểm tra nằm gần nhau về mặt địa lý, dẫn đến spatial autocorrelation; giải pháp là chia dữ liệu theo vùng địa lý hoặc đảm bảo khoảng cách tối thiểu giữa train/test. \textbf{Rò rỉ thời gian (Temporal leakage)} xảy ra khi sử dụng thông tin từ thời điểm sau để dự đoán thời điểm trước; giải pháp là chia dữ liệu theo thời gian, đảm bảo tập huấn luyện chỉ chứa dữ liệu trước tập kiểm tra. \textbf{Rò rỉ đặc trưng (Feature leakage)} xảy ra khi tính toán statistics (mean, std) trên toàn bộ dữ liệu thay vì chỉ trên tập huấn luyện; giải pháp là fit scaler trên train set, transform cả train và test.

Trong nghiên cứu này, rò rỉ dữ liệu được phòng tránh bằng cách sử dụng Stratified K-Fold Cross Validation và tính toán các tham số chuẩn hóa riêng cho từng fold.