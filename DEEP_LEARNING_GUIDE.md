# ğŸ§  Deep Learning Pipeline - Quick Start Guide

HÆ°á»›ng dáº«n nhanh Ä‘á»ƒ cháº¡y pipeline CNN phÃ¡t hiá»‡n máº¥t rá»«ng vá»›i spatial context.

---

## ğŸ“Š Tá»•ng quan

**Pipeline nÃ y lÃ m gÃ¬?**
- Sá»­ dá»¥ng **2D CNN** vá»›i patches 3x3 (thay vÃ¬ single pixel nhÆ° Random Forest)
- Khai thÃ¡c **spatial context** â†’ giáº£m nhiá»…u "láº¥m táº¥m"
- **Spatial-aware splitting** â†’ trÃ¡nh data leakage
- Káº¿t quáº£: Classification map **mÆ°á»£t mÃ  hÆ¡n** Random Forest

**KhÃ¡c biá»‡t chÃ­nh vá»›i Random Forest:**

| Aspect | Random Forest | CNN (Deep Learning) |
|--------|--------------|---------------------|
| Input | Single pixel (27 features) | Patch 3x3 (27 features Ã— 9 pixels) |
| Spatial context | âŒ No | âœ… Yes (3x3 neighborhood) |
| Training time | ~5-10 min | ~15-20 min |
| Result smoothness | âš ï¸ CÃ³ noise láº¥m táº¥m | âœ… MÆ°á»£t hÆ¡n |
| Accuracy | Good baseline | Similar or better |
| GPU | Not needed | Recommended |

---

## ğŸš€ CÃ¡ch cháº¡y

### Option 1: Cháº¡y vá»›i settings máº·c Ä‘á»‹nh

```bash
cd src
python main_dl.py
```

**Settings máº·c Ä‘á»‹nh:**
- Patch size: 3x3
- Epochs: 50 (cÃ³ early stopping)
- Batch size: 32
- Learning rate: 0.001
- Device: CUDA (tá»± Ä‘á»™ng fallback CPU náº¿u khÃ´ng cÃ³ GPU)

### Option 2: Custom settings

```bash
# Cháº¡y vá»›i 100 epochs
python main_dl.py --epochs 100

# Cháº¡y vá»›i batch size lá»›n hÆ¡n (náº¿u cÃ³ GPU memory)
python main_dl.py --batch-size 64

# Force CPU (náº¿u GPU gáº·p váº¥n Ä‘á»)
python main_dl.py --device cpu

# Káº¿t há»£p
python main_dl.py --epochs 100 --batch-size 64 --device cuda
```

---

## ğŸ“ Output Files

Sau khi cháº¡y xong, check folder `results/`:

```
results/
â”œâ”€â”€ rasters/
â”‚   â”œâ”€â”€ cnn_classification.tif      # Binary map (0=No loss, 1=Deforestation)
â”‚   â””â”€â”€ cnn_probability.tif         # Probability map (0.0-1.0)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cnn_model.pth               # Trained CNN model
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ cnn_training_patches.npz    # Training patches (cÃ³ thá»ƒ load láº¡i)
    â”œâ”€â”€ cnn_evaluation_metrics.json # Accuracy, Precision, Recall, F1, AUC
    â””â”€â”€ cnn_training_history.json   # Training curves (loss/accuracy per epoch)
```

---

## ğŸ” Hiá»ƒu Pipeline

### Pipeline 8 bÆ°á»›c:

```
1. Load Data
   â””â”€ Sentinel-1, Sentinel-2, Ground Truth, Boundary

2. Feature Extraction
   â””â”€ 27 features (same as Random Forest)

3. Spatial-Aware Splitting â­ (NEW!)
   â””â”€ Cluster nearby points â†’ Split by cluster
   â””â”€ Ensure NO overlap between train/val/test

4. Extract Patches â­ (NEW!)
   â””â”€ Extract 3x3 patches at ground truth locations
   â””â”€ Normalize patches (z-score)

5. Train CNN
   â””â”€ 2D CNN with 2 conv layers + FC layers
   â””â”€ Early stopping, learning rate scheduling
   â””â”€ ~50K parameters

6. Evaluate
   â””â”€ Test set metrics: Accuracy, Precision, Recall, F1, AUC

7. Predict Full Raster
   â””â”€ Sliding window over entire area
   â””â”€ Generate classification + probability maps

8. Save Results
   â””â”€ GeoTIFF rasters with metadata
```

---

## âš™ï¸ Configuration

Náº¿u muá»‘n thay Ä‘á»•i settings chi tiáº¿t hÆ¡n, edit file `src/common/config.py`:

```python
DL_CONFIG = {
    # Model architecture
    'model_type': 'standard',       # 'standard' hoáº·c 'deeper'
    'patch_size': 3,                 # 3x3 patches (30m x 30m)
    'dropout_rate': 0.5,             # Dropout Ä‘á»ƒ trÃ¡nh overfitting

    # Training parameters
    'epochs': 50,                    # Max epochs (cÃ³ early stopping)
    'batch_size': 32,                # Batch size
    'learning_rate': 0.001,          # Initial learning rate
    'weight_decay': 1e-4,            # L2 regularization
    'early_stopping_patience': 10,   # Stop náº¿u val loss khÃ´ng giáº£m sau 10 epochs

    # Spatial splitting
    'cluster_distance': 50.0,        # Cluster points within 50m
    'train_size': 0.70,              # 70% train
    'val_size': 0.15,                # 15% validation
    'test_size': 0.15,               # 15% test

    # Normalization
    'normalize_method': 'standardize', # 'standardize' or 'minmax'

    # Device
    'device': 'cuda',                # 'cuda' or 'cpu'

    # Prediction
    'pred_batch_size': 1000,         # Batch size cho full raster prediction
    'pred_stride': 1,                # Stride=1 â†’ dense prediction
}
```

---

## ğŸ¯ Spatial-Aware Splitting (TrÃ¡nh Data Leakage)

### âš ï¸ Váº¥n Ä‘á»

Náº¿u cÃ³ 2 training points gáº§n nhau (<30m):
```
Point A: Patch bao phá»§ pixels (98-102, 198-202)
Point B: Patch bao phá»§ pixels (100-104, 200-204)
         â†’ OVERLAP!
```

Náº¿u Point A á»Ÿ train set, Point B á»Ÿ test set:
- Model Ä‘Ã£ "nhÃ¬n tháº¥y" vÃ¹ng cá»§a Point B khi training (qua patch A)
- Test accuracy sáº½ bá»‹ thá»•i phá»“ng (khÃ´ng Ä‘Ãºng)

### âœ… Giáº£i phÃ¡p cá»§a chÃºng ta

```python
1. Cluster cÃ¡c points gáº§n nhau (distance < 50m)
2. Split theo CLUSTER (khÃ´ng pháº£i individual points)
3. Táº¥t cáº£ points trong 1 cluster â†’ cÃ¹ng á»Ÿ train hoáº·c cÃ¹ng á»Ÿ test
4. Verify: Ä‘áº£m báº£o khoáº£ng cÃ¡ch giá»¯a train/test >= 50m
```

**Káº¿t quáº£:**
- âœ… NO data leakage
- âœ… Test accuracy pháº£n Ã¡nh kháº£ nÄƒng generalization tháº­t
- âœ… An toÃ n vá»›i patch size 3x3 (30m)

---

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

Dá»±a trÃªn nghiÃªn cá»©u tÆ°Æ¡ng tá»± vá»›i small dataset:

| Metric | Expected Range | Note |
|--------|----------------|------|
| **Accuracy** | 85-92% | Similar to RF |
| **Precision** | 82-90% | Slightly better than RF |
| **Recall** | 80-88% | Depends on class balance |
| **F1-Score** | 82-89% | Balanced metric |
| **ROC-AUC** | 88-94% | Good discrimination |

**So sÃ¡nh vá»›i Random Forest:**
- Accuracy: TÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c hÆ¡i cao hÆ¡n má»™t chÃºt
- Smoothness: **RÃµ rá»‡t tá»‘t hÆ¡n** (Ã­t noise láº¥m táº¥m)
- Training time: Cháº­m hÆ¡n (~2-3x)

---

## ğŸ’¡ Tips & Tricks

### 1. **Náº¿u bá»‹ Out of Memory (GPU)**

```python
# Edit config.py
DL_CONFIG['batch_size'] = 16  # Giáº£m tá»« 32 xuá»‘ng 16
```

Hoáº·c:
```bash
python main_dl.py --batch-size 16 --device cpu
```

### 2. **Náº¿u bá»‹ Overfitting (Val accuracy giáº£m)**

```python
# TÄƒng regularization
DL_CONFIG['dropout_rate'] = 0.6      # Tá»« 0.5 lÃªn 0.6
DL_CONFIG['weight_decay'] = 1e-3     # Tá»« 1e-4 lÃªn 1e-3
```

Hoáº·c giáº£m sá»‘ epochs:
```bash
python main_dl.py --epochs 30
```

### 3. **Náº¿u muá»‘n train lÃ¢u hÆ¡n**

```bash
python main_dl.py --epochs 100
```

Early stopping sáº½ tá»± Ä‘á»™ng dá»«ng náº¿u khÃ´ng improve.

### 4. **Náº¿u khÃ´ng cÃ³ GPU**

```bash
python main_dl.py --device cpu
```

Training sáº½ cháº­m hÆ¡n (~30-40 min) nhÆ°ng váº«n cháº¡y Ä‘Æ°á»£c.

---

## ğŸ”¬ PhÃ¢n tÃ­ch káº¿t quáº£

### 1. **Xem training history**

```python
import json

with open('results/data/cnn_training_history.json', 'r') as f:
    history = json.load(f)

# Plot training curves
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

# Loss
plt.subplot(1, 2, 1)
plt.plot(history['train_loss'], label='Train Loss')
plt.plot(history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')

# Accuracy
plt.subplot(1, 2, 2)
plt.plot(history['train_acc'], label='Train Acc')
plt.plot(history['val_acc'], label='Val Acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.tight_layout()
plt.savefig('results/plots/training_curves.png', dpi=300)
plt.show()
```

### 2. **Load vÃ  visualize káº¿t quáº£**

```python
import rasterio
import matplotlib.pyplot as plt

# Load classification map
with rasterio.open('results/rasters/cnn_classification.tif') as src:
    cnn_classification = src.read(1)

# Load probability map
with rasterio.open('results/rasters/cnn_probability.tif') as src:
    cnn_probability = src.read(1)

# Visualize
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

axes[0].imshow(cnn_classification, cmap='RdYlGn')
axes[0].set_title('CNN Classification (Binary)')
axes[0].axis('off')

im = axes[1].imshow(cnn_probability, cmap='RdYlGn_r', vmin=0, vmax=1)
axes[1].set_title('CNN Probability (0-1)')
axes[1].axis('off')
plt.colorbar(im, ax=axes[1])

plt.tight_layout()
plt.savefig('results/plots/cnn_results.png', dpi=300)
plt.show()
```

### 3. **So sÃ¡nh vá»›i Random Forest**

```python
# Load RF results
with rasterio.open('results/rasters/rf_classification.tif') as src:
    rf_classification = src.read(1)

# Compare
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

axes[0].imshow(rf_classification, cmap='RdYlGn')
axes[0].set_title('Random Forest')
axes[0].axis('off')

axes[1].imshow(cnn_classification, cmap='RdYlGn')
axes[1].set_title('CNN')
axes[1].axis('off')

# Difference
diff = cnn_classification.astype(int) - rf_classification.astype(int)
axes[2].imshow(diff, cmap='bwr', vmin=-1, vmax=1)
axes[2].set_title('Difference (CNN - RF)')
axes[2].axis('off')

plt.tight_layout()
plt.savefig('results/plots/rf_vs_cnn.png', dpi=300)
plt.show()
```

---

## ğŸ› Troubleshooting

### Lá»—i: "ModuleNotFoundError: No module named 'torch'"

```bash
# Install PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Lá»—i: "CUDA out of memory"

```bash
# Giáº£m batch size
python main_dl.py --batch-size 16

# Hoáº·c dÃ¹ng CPU
python main_dl.py --device cpu
```

### Lá»—i: "RuntimeError: expected scalar type Float but found Double"

â†’ ÄÃ¢y lÃ  bug trong code. ÄÃ£ handle sáºµn báº±ng `.float()` conversions.

### Model khÃ´ng há»c (loss khÃ´ng giáº£m)

1. Check data normalization: patches pháº£i Ä‘Æ°á»£c normalize
2. Check learning rate: cÃ³ thá»ƒ quÃ¡ cao hoáº·c quÃ¡ tháº¥p
3. Check labels: Ä‘Ãºng format (0/1) chÆ°a?

---

## ğŸ“š TÃ i liá»‡u tham kháº£o

- **Deep Learning Module README**: `src/deep_learning/README.md`
- **Main Pipeline**: `src/main_dl.py`
- **Configuration**: `src/common/config.py` (DL_CONFIG section)
- **Compare with RF**: `src/main.py` (Random Forest pipeline)

---

## âœ… Checklist

TrÆ°á»›c khi cháº¡y, Ä‘áº£m báº£o:

- [ ] ÄÃ£ cÃ³ dá»¯ liá»‡u trong `data/raw/` (Sentinel-1, Sentinel-2, Ground Truth, Boundary)
- [ ] ÄÃ£ install PyTorch (`pip install torch`)
- [ ] ÄÃ£ check GPU availability (hoáº·c sáºµn sÃ ng dÃ¹ng CPU)
- [ ] ÄÃ£ cháº¡y Random Forest trÆ°á»›c (Ä‘á»ƒ so sÃ¡nh)

**Sáºµn sÃ ng?**
```bash
cd src
python main_dl.py
```

**Thá»i gian cháº¡y:** ~15-25 phÃºt (GPU) hoáº·c ~30-45 phÃºt (CPU)

Good luck! ğŸš€
