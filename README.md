# á»¨ng dá»¥ng Viá»…n thÃ¡m vÃ  Há»c sÃ¢u trong GiÃ¡m sÃ¡t Biáº¿n Ä‘á»™ng Rá»«ng tá»‰nh CÃ  Mau

**Äá»“ Ã¡n tá»‘t nghiá»‡p - CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥**

Sinh viÃªn: **Ninh Háº£i ÄÄƒng** (MSSV: 21021411)
NÄƒm há»c: 2025 - 2026, Há»c ká»³ I

---

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n nÃ y phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng tá»± Ä‘á»™ng giÃ¡m sÃ¡t biáº¿n Ä‘á»™ng rá»«ng táº¡i tá»‰nh CÃ  Mau sá»­ dá»¥ng káº¿t há»£p dá»¯ liá»‡u viá»…n thÃ¡m Ä‘a nguá»“n (Sentinel-1 SAR vÃ  Sentinel-2 Optical) vÃ  mÃ´ hÃ¬nh há»c sÃ¢u (Deep Learning). Há»‡ thá»‘ng cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i cÃ¡c khu vá»±c máº¥t rá»«ng dá»±a trÃªn phÃ¢n tÃ­ch chuá»—i thá»i gian áº£nh vá»‡ tinh.

### Má»¥c tiÃªu

- PhÃ¡t triá»ƒn mÃ´ hÃ¬nh deep learning Ä‘á»ƒ phÃ¡t hiá»‡n máº¥t rá»«ng tá»« áº£nh vá»‡ tinh Ä‘a thá»i gian
- Káº¿t há»£p dá»¯ liá»‡u SAR (Sentinel-1) vÃ  Optical (Sentinel-2) Ä‘á»ƒ nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c
- Táº¡o báº£n Ä‘á»“ phÃ¢n loáº¡i toÃ n bá»™ khu vá»±c rá»«ng tá»‰nh CÃ  Mau

---

## ğŸ“Š Dá»¯ liá»‡u

### Ground Truth Points
- **Tá»•ng sá»‘ Ä‘iá»ƒm:** 1,285 Ä‘iá»ƒm training
- **PhÃ¢n bá»‘:**
  - Label 0 (KhÃ´ng máº¥t rá»«ng): 650 Ä‘iá»ƒm (50.6%)
  - Label 1 (Máº¥t rá»«ng): 635 Ä‘iá»ƒm (49.4%)
- **Format:** CSV file vá»›i cÃ¡c trÆ°á»ng: `id`, `label`, `x`, `y` (tá»a Ä‘á»™ UTM Zone 48N)
- **File:** `data/raw/ground_truth/Training_Points_CSV.csv`

### Sentinel-2 (Optical)
- **7 bands** gá»“m spectral bands vÃ  spectral indices:
  - **Spectral bands:** B4 (Red), B8 (NIR), B11 (SWIR1), B12 (SWIR2)
  - **Spectral indices:** NDVI, NBR, NDMI
- **Äá»™ phÃ¢n giáº£i khÃ´ng gian:** 10m
- **Ká»³ áº£nh:**
  - TrÆ°á»›c: 30/01/2024 (`S2_2024_01_30.tif`)
  - Sau: 28/02/2025 (`S2_2025_02_28.tif`)
- **ÄÃ£ xá»­ lÃ½:** Cáº¯t theo ranh giá»›i rá»«ng tá»‰nh CÃ  Mau, masked NoData

### Sentinel-1 (SAR)
- **2 bands:** VV vÃ  VH polarization
- **Äá»™ phÃ¢n giáº£i khÃ´ng gian:** 10m (matched vá»›i Sentinel-2)
- **Ká»³ áº£nh:**
  - TrÆ°á»›c: 04/02/2024 (`S1_2024_02_04_matched_S2_2024_01_30.tif`)
  - Sau: 22/02/2025 (`S1_2025_02_22_matched_S2_2025_02_28.tif`)
- **ÄÃ£ xá»­ lÃ½:** Co-registered vá»›i Sentinel-2, cáº¯t theo ranh giá»›i rá»«ng

### Boundary Shapefile
- **File:** `data/raw/boundary/forest_boundary.shp`
- **Má»¥c Ä‘Ã­ch:** Giá»›i háº¡n khu vá»±c phÃ¢n tÃ­ch chá»‰ trong vÃ¹ng rá»«ng

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
25-26_HKI_DATN_21021411_DangNH/
â”‚
â”œâ”€â”€ data/                           # ThÆ° má»¥c chá»©a dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                        # Dá»¯ liá»‡u gá»‘c
â”‚   â”‚   â”œâ”€â”€ ground_truth/           # Ground truth CSV
â”‚   â”‚   â”œâ”€â”€ sentinel-1/             # áº¢nh Sentinel-1 SAR
â”‚   â”‚   â”œâ”€â”€ sentinel-2/             # áº¢nh Sentinel-2 Optical
â”‚   â”‚   â””â”€â”€ boundary/               # Shapefile ranh giá»›i rá»«ng
â”‚   â”œâ”€â”€ processed/                  # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â””â”€â”€ patches/                    # Patches Ä‘Ã£ trÃ­ch xuáº¥t
â”‚
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ config.py                   # Cáº¥u hÃ¬nh chung
â”‚   â”œâ”€â”€ utils.py                    # HÃ m tiá»‡n Ã­ch
â”‚   â”œâ”€â”€ preprocessing.py            # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ dataset.py                  # PyTorch Dataset (náº¿u cÃ³)
â”‚   â””â”€â”€ (cÃ¡c module khÃ¡c sáº½ Ä‘Æ°á»£c thÃªm)
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ 01_data_exploration.ipynb   # KhÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚
â”œâ”€â”€ models/                         # ThÆ° má»¥c lÆ°u trained models
â”œâ”€â”€ figures/                        # Visualizations vÃ  plots
â”œâ”€â”€ logs/                           # Training logs
â”‚
â”œâ”€â”€ environment.yml                 # Conda environment
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                       # File nÃ y

```

---

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

### Pháº§n cá»©ng sá»­ dá»¥ng
- **CPU:** Intel Xeon X5670 (hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng)
- **RAM:** 64GB DDR3
- **GPU:** NVIDIA GTX 1060 6GB hoáº·c cao hÆ¡n (há»— trá»£ CUDA)
- **Storage:** â‰¥50GB dung lÆ°á»£ng trá»‘ng

### Pháº§n má»m
- **OS:** Windows 10/11, Linux, macOS
- **Python:** 3.8 - 3.11
- **CUDA:** 11.8+ (náº¿u sá»­ dá»¥ng GPU)
- **Conda/Miniconda:** PhiÃªn báº£n má»›i nháº¥t

---

## âš™ï¸ CÃ i Ä‘áº·t

### BÆ°á»›c 1: Clone repository

```bash
git clone https://github.com/Geospatial-Technology-Lab/25-26_HKI_DATN_21021411_DangNH.git
cd 25-26_HKI_DATN_21021411_DangNH
```

### BÆ°á»›c 2: Táº¡o Conda environment

```bash
conda env create -f environment.yml
conda activate dang
```

**Hoáº·c** sá»­ dá»¥ng pip:

```bash
pip install -r requirements.txt
```

### BÆ°á»›c 3: Verify installation

```python
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

---

## ğŸš€ Sá»­ dá»¥ng

### 1. KhÃ¡m phÃ¡ dá»¯ liá»‡u (Data Exploration)

Cháº¡y notebook Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  visualize dá»¯ liá»‡u:

```bash
cd notebooks
jupyter notebook 01_data_exploration.ipynb
```

**Notebook nÃ y sáº½:**
- Load vÃ  phÃ¢n tÃ­ch ground truth points
- Visualize Sentinel-1 vÃ  Sentinel-2 imagery
- Kiá»ƒm tra value ranges vÃ  data quality
- TrÃ­ch xuáº¥t vÃ  hiá»ƒn thá»‹ sample patches
- Táº¡o cÃ¡c visualizations trong folder `figures/`

**Outputs:**
- CÃ¡c visualizations sáº½ Ä‘Æ°á»£c lÆ°u trong folder `figures/`
- Bao gá»“m: band comparisons, ground truth visualization, sample patches, etc.

### 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing)

TrÃ­ch xuáº¥t patches tá»« toÃ n bá»™ ground truth points:

```bash
python -c "from src.preprocessing import create_patches_dataset; create_patches_dataset(patch_size=64)"
```

**Output:**
- `data/patches/patches_64x64.pkl` - File chá»©a patches vÃ  labels

### 3. Training mÃ´ hÃ¬nh

> **Status:** Script training vÃ  pipeline chÆ°a Ä‘Æ°á»£c hoÃ n thiá»‡n. Sáº½ Ä‘Æ°á»£c develop sau khi xÃ¡c Ä‘á»‹nh kiáº¿n trÃºc model.

### 4. Inference (Dá»± Ä‘oÃ¡n toÃ n bá»™ khu vá»±c)

> **Status:** Script inference sáº½ Ä‘Æ°á»£c develop sau khi hoÃ n thÃ nh training vÃ  chá»n Ä‘Æ°á»£c best model.

---

## ğŸ§  Input Data Structure

### Input Specification
- **18 channels** tá»« 2 ká»³ áº£nh:
  - **Ká»³ 2024:** 7 bands S2 + 2 bands S1 = 9 channels
  - **Ká»³ 2025:** 7 bands S2 + 2 bands S1 = 9 channels
- **Patch size:** 64Ã—64 pixels
- **Channel order:**
  ```
  [0-6]:   S2 2024 (B4, B8, B11, B12, NDVI, NBR, NDMI)
  [7-8]:   S1 2024 (VV, VH)
  [9-15]:  S2 2025 (B4, B8, B11, B12, NDVI, NBR, NDMI)
  [16-17]: S1 2025 (VV, VH)
  ```

### Model Architecture

> **Status:** Kiáº¿n trÃºc mÃ´ hÃ¬nh deep learning chÆ°a Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh. Sáº½ thá»­ nghiá»‡m vÃ  lá»±a chá»n sau.

---

## âš™ï¸ Training Configuration

#### ÄÃ£ xÃ¡c Ä‘á»‹nh:
- **Mixed Precision (AMP):** Enabled - Tiáº¿t kiá»‡m ~40% VRAM, tÄƒng tá»‘c training
- **Batch size:** 16-24 (tÃ¹y model, Ä‘Æ°á»£c test Ä‘á»ƒ táº­n dá»¥ng tá»‘i Ä‘a 6GB VRAM vá»›i AMP)
- **Gradient Accumulation:** 2 steps (Effective batch size = 32-48 tÃ¹y batch size thá»±c táº¿)
- **Data split:** 70% train, 15% validation, 15% test
- **DataLoader Strategy:** Cache toÃ n bá»™ 1,285 patches trong RAM (~380MB) Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™

#### ChÆ°a xÃ¡c Ä‘á»‹nh (sáº½ thá»­ nghiá»‡m):
- **Optimizer:** TBD (Adam, AdamW, SGD, etc.)
- **Learning rate:** TBD
- **Learning rate scheduler:** TBD (CosineAnnealing, ReduceLROnPlateau, etc.)
- **Loss function:** TBD (CrossEntropyLoss, Focal Loss, etc.)
- **Epochs:** TBD
- **Early stopping patience:** TBD
- **Data augmentation:** TBD (Rotation, Flip, Noise, etc.)

---

## ğŸ“ˆ Káº¿t quáº£

> **Status:** Äang trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m vÃ  training models.

### Metrics

CÃ¡c metrics Ä‘Ã¡nh giÃ¡ sáº½ bao gá»“m:
- **Accuracy:** Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Precision:** Äá»™ chÃ­nh xÃ¡c cá»§a class "Máº¥t rá»«ng"
- **Recall:** Kháº£ nÄƒng phÃ¡t hiá»‡n máº¥t rá»«ng
- **F1-Score:** Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- **Confusion Matrix:** Ma tráº­n nháº§m láº«n
- **ROC-AUC:** Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC

### Káº¿t quáº£ so sÃ¡nh models

(Sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau khi hoÃ n thÃ nh training vÃ  evaluation)

### Deforestation Map

(Báº£n Ä‘á»“ phÃ¢n loáº¡i toÃ n bá»™ khu vá»±c rá»«ng CÃ  Mau sáº½ Ä‘Æ°á»£c táº¡o sau khi chá»n Ä‘Æ°á»£c best model)

---

## ğŸ“ Preprocessing Pipeline

### 1. Sentinel-2 Preprocessing
- Äá»c 7 bands tá»« GeoTIFF
- Xá»­ lÃ½ NoData values (convert to NaN)
- Clip outliers vá» physical ranges:
  - Spectral bands (B4, B8, B11, B12): [0, 1]
  - Spectral indices (NDVI, NBR, NDMI): [-1, 1]
- Apply boundary mask (chá»‰ giá»¯ pixels trong vÃ¹ng rá»«ng)

### 2. Sentinel-1 Preprocessing
- Äá»c VV vÃ  VH bands (dB values)
- Apply boundary mask
- MinMax normalization: [min, max] â†’ [0, 1]

### 3. Patch Extraction
- Extract 64Ã—64 patches táº¡i cÃ¡c ground truth points
- Stack 18 channels: [S2_2024, S1_2024, S2_2025, S1_2025]
- Reject patches chá»©a NaN hoáº·c all-zero values
- LÆ°u thÃ nh pickle file cho training

---

## ğŸ”§ Tá»‘i Æ°u hÃ³a cho GTX 1060 6GB + 64GB RAM

Dá»± Ã¡n Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘áº·c biá»‡t cho cáº¥u hÃ¬nh pháº§n cá»©ng:

### GPU Optimization (GTX 1060 6GB):
- **Mixed Precision Training (AMP):** Enabled
  - Giáº£m ~40% VRAM usage (float16 thay vÃ¬ float32)
  - TÄƒng tá»‘c training ~20-30%
  - KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘á»™ chÃ­nh xÃ¡c

- **Batch size:** 16-24 (tÃ¹y Ä‘á»™ phá»©c táº¡p cá»§a model)
  - ÄÆ°á»£c test Ä‘á»ƒ táº­n dá»¥ng tá»‘i Ä‘a 6GB VRAM
  - Model nháº¹ â†’ batch size lá»›n hÆ¡n
  - Model náº·ng â†’ batch size nhá» hÆ¡n

- **Gradient Accumulation:** 2 steps
  - Effective batch size = 32-48
  - GiÃºp training á»•n Ä‘á»‹nh hÆ¡n vá»›i dataset nhá» (1,285 samples)
  - Trade-off: cháº­m hÆ¡n ~15-20% nhÆ°ng káº¿t quáº£ tá»‘t hÆ¡n

### RAM Optimization (64GB):
- **Cache patches trong RAM:**
  - Load toÃ n bá»™ 1,285 patches vÃ o RAM (~380 MB)
  - Training Cá»°C NHANH (khÃ´ng cáº§n Ä‘á»c disk má»—i epoch)
  - Dataset nhá» nÃªn hoÃ n toÃ n kháº£ thi

- **DataLoader minimal:**
  - `num_workers = 4` (Ä‘á»§ vÃ¬ data Ä‘Ã£ trong RAM)
  - `pin_memory = True` (tÄƒng tá»‘c CPU â†’ GPU transfer)
  - `prefetch_factor = 2` (giáº£m vÃ¬ khÃ´ng cáº§n prefetch nhiá»u)
  - `persistent_workers = True` (giá»¯ workers alive giá»¯a epochs)

### Estimated Resource Usage:
- **VRAM:** ~4.5-5.5 GB / 6 GB (~85-95% utilization)
- **RAM:** ~15-20 GB / 64 GB (patches cache + system + PyTorch)
- **Training Speed:** ~5-10 giÃ¢y/epoch (vá»›i cached data)

---

## ğŸ“š ThÆ° viá»‡n chÃ­nh

- **PyTorch** 2.0+ - Deep learning framework
- **torchvision** - Computer vision models
- **segmentation-models-pytorch** - U-Net implementation
- **rasterio** - Äá»c/ghi GeoTIFF files
- **geopandas** - Xá»­ lÃ½ vector data (shapefiles)
- **numpy** - Numerical operations
- **pandas** - Data manipulation
- **matplotlib, seaborn** - Visualization
- **scikit-learn** - Metrics vÃ  utilities
- **tqdm** - Progress bars

---

## ğŸ¤ ÄÃ³ng gÃ³p

Dá»± Ã¡n nÃ y lÃ  Ä‘á»“ Ã¡n tá»‘t nghiá»‡p cÃ¡ nhÃ¢n. Má»i Ä‘Ã³ng gÃ³p, Ã½ kiáº¿n, vÃ  gÃ³p Ã½ xin vui lÃ²ng liÃªn há»‡ qua email hoáº·c táº¡o issue trÃªn GitHub.

---

## ğŸ“§ LiÃªn há»‡

- **Sinh viÃªn:** Ninh Háº£i ÄÄƒng
- **Email:** ninhhaidangg@gmail.com
- **GitHub:** [ninhhaidang](https://github.com/ninhhaidang)
- **ÄÆ¡n vá»‹:** TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ - ÄHQGHN

---

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  giÃ¡o dá»¥c.

---

## ğŸ™ Lá»i cáº£m Æ¡n

- Giáº£ng viÃªn hÆ°á»›ng dáº«n: TS. HÃ  Minh CÆ°á»ng, ThS, HoÃ ng TÃ­ch PhÃºc
- PhÃ²ng thÃ­ nghiá»‡m: Geospatial Technology Lab
- Viá»‡n CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥ - TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡, ÄHQGHN

---

**Cáº­p nháº­t láº§n cuá»‘i:** 06/01/2025
