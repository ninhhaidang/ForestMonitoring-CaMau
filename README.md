# ğŸŒ³ Forest Change Detection - Ca Mau Mangrove

**PhÃ¡t hiá»‡n máº¥t rá»«ng ngáº­p máº·n CÃ  Mau sá»­ dá»¥ng Deep Learning vá»›i dá»¯ liá»‡u Ä‘a nguá»“n vá»‡ tinh**

**Sinh viÃªn**: Ninh Háº£i ÄÄƒng (MSSV: 21021411)
**TrÆ°á»ng**: Äáº¡i há»c CÃ´ng nghá»‡ - ÄHQGHN
**NÄƒm há»c**: 2025-2026

---

## ğŸ“‹ Má»¤C ÄÃCH Dá»° ÃN

### Váº¥n Ä‘á»:
PhÃ¡t hiá»‡n vÃ  láº­p báº£n Ä‘á»“ **máº¥t rá»«ng ngáº­p máº·n** táº¡i khu vá»±c CÃ  Mau trong giai Ä‘oáº¡n 2024-2025 báº±ng phÆ°Æ¡ng phÃ¡p há»c sÃ¢u (Deep Learning).

### Giáº£i phÃ¡p:
Sá»­ dá»¥ng **3 mÃ´ hÃ¬nh Deep Learning nháº¹** (PyTorch) Ä‘á»ƒ phÃ¢n loáº¡i tá»«ng pixel trÃªn áº£nh vá»‡ tinh:
- **Pixel = 0**: KhÃ´ng máº¥t rá»«ng (rá»«ng cÃ²n nguyÃªn váº¹n)
- **Pixel = 1**: Máº¥t rá»«ng (phÃ¡ rá»«ng/chuyá»ƒn Ä‘á»•i Ä‘áº¥t)

### Äáº§u vÃ o (INPUT):
1. **4 áº£nh vá»‡ tinh GeoTIFF** (toÃ n bá»™ vÃ¹ng CÃ  Mau):
   - Sentinel-1 Time 1 (2024-02-04): 2 bands (VH, VH/VV Ratio)
   - Sentinel-1 Time 2 (2025-02-22): 2 bands (VH, VH/VV Ratio)
   - Sentinel-2 Time 1 (2024-01-30): 7 bands (B4, B8, B11, B12, NDVI, NBR, NDMI)
   - Sentinel-2 Time 2 (2025-02-28): 7 bands (B4, B8, B11, B12, NDVI, NBR, NDMI)

2. **1 file CSV** vá»›i 1,285 Ä‘iá»ƒm training (tá»a Ä‘á»™ x, y + nhÃ£n):
   - 650 Ä‘iá»ƒm "khÃ´ng máº¥t rá»«ng" (label = 0)
   - 635 Ä‘iá»ƒm "máº¥t rá»«ng" (label = 1)

### Äáº§u ra (OUTPUT):
1. **probability_map.tif** - Báº£n Ä‘á»“ xÃ¡c suáº¥t máº¥t rá»«ng (giÃ¡ trá»‹ 0.0 â†’ 1.0)
2. **binary_map.tif** - Báº£n Ä‘á»“ phÃ¢n loáº¡i nhá»‹ phÃ¢n (0 = khÃ´ng máº¥t, 1 = máº¥t rá»«ng)
3. **visualization.png** - Báº£n Ä‘á»“ mÃ u (Xanh lÃ¡ = khÃ´ng máº¥t, Äá» = máº¥t rá»«ng)

---

## ğŸ”¬ PHÆ¯Æ NG PHÃP

### 1. Chuáº©n bá»‹ dá»¯ liá»‡u:
- Extract patches 256Ã—256 pixels táº¡i tá»a Ä‘á»™ (x,y) tá»« CSV
- Má»—i patch chá»©a **18 bands tá»•ng cá»™ng**:
  - Time 1: 9 bands (2 S1 + 7 S2)
  - Time 2: 9 bands (2 S1 + 7 S2)
- Split: 80% train (1,028), 10% val (128), 10% test (129)

### 2. Training:
So sÃ¡nh **3 mÃ´ hÃ¬nh Deep Learning nháº¹** tá»« thÆ° viá»‡n `segmentation_models_pytorch`:

| MÃ´ hÃ¬nh | Encoder | Params | Tá»‘c Ä‘á»™ | Äáº·c Ä‘iá»ƒm |
|---------|---------|--------|--------|----------|
| **UNet-EfficientNet-B0** | EfficientNet-B0 | ~5M | Nhanh | â­ CÃ¢n báº±ng tá»‘t |
| **UNet-MobileNetV2** | MobileNetV2 | ~2M | Ráº¥t nhanh | Nháº¹ nháº¥t, phÃ¹ há»£p mobile |
| **FPN-EfficientNet-B0** | EfficientNet-B0 | ~6M | Trung bÃ¬nh | Accuracy cao nháº¥t |

**Training config:**
- Loss: CrossEntropyLoss (binary classification)
- Optimizer: AdamW
- Learning rate: 1e-4
- Batch size: 16
- Epochs: 50 (vá»›i early stopping)
- Augmentation: Random flip, rotation

### 3. Inference (Whole Scene):
- **Sliding window 256Ã—256** vá»›i overlap trÃªn toÃ n bá»™ 4 áº£nh GeoTIFF gá»‘c
- Merge predictions tá»« táº¥t cáº£ windows â†’ Probability map (0.0-1.0)
- Apply threshold (0.5) â†’ Binary map (0/1)

### 4. Táº¡o báº£n Ä‘á»“ cuá»‘i cÃ¹ng:
- Save probability map dáº¡ng GeoTIFF (float32)
- Save binary map dáº¡ng GeoTIFF (uint8)
- Colorize vÃ  export PNG (visualization)

---

## ğŸ“ Cáº¤U TRÃšC Dá»® LIá»†U

```
project/
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â””â”€â”€ raw/                          # Data gá»‘c
â”‚       â”œâ”€â”€ sentinel1/
â”‚       â”‚   â”œâ”€â”€ S1_2024_02_04_matched_S2_2024_01_30.tif  (490MB)
â”‚       â”‚   â””â”€â”€ S1_2025_02_22_matched_S2_2025_02_28.tif  (489MB)
â”‚       â”œâ”€â”€ sentinel2/
â”‚       â”‚   â”œâ”€â”€ S2_2024_01_30.tif                        (1.5GB)
â”‚       â”‚   â””â”€â”€ S2_2025_02_28.tif                        (1.5GB)
â”‚       â””â”€â”€ ground_truth/
â”‚           â””â”€â”€ Training_Points_CSV.csv                  (1,285 points)
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                     # Jupyter notebooks chÃ­nh
â”‚   â”œâ”€â”€ 1_train_models.ipynb         # Train 3 models
â”‚   â”œâ”€â”€ 2_inference_wholescene.ipynb # Whole scene inference
â”‚   â””â”€â”€ 3_create_maps.ipynb          # Generate final outputs
â”‚
â”œâ”€â”€ ğŸ“‚ src/                           # Source code modules
â”‚   â”œâ”€â”€ dataset.py                    # PyTorch Dataset
â”‚   â”œâ”€â”€ models.py                     # Model definitions
â”‚   â””â”€â”€ utils.py                      # Helper functions
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # Saved models
â”‚   â”œâ”€â”€ unet_efficientnet/
â”‚   â”‚   â””â”€â”€ best_model.pth
â”‚   â”œâ”€â”€ unet_mobilenet/
â”‚   â”‚   â””â”€â”€ best_model.pth
â”‚   â””â”€â”€ fpn_efficientnet/
â”‚       â””â”€â”€ best_model.pth
â”‚
â””â”€â”€ ğŸ“‚ results/                       # Outputs
    â””â”€â”€ whole_scene/
        â”œâ”€â”€ probability_map.tif       # ğŸ¯ XÃ¡c suáº¥t [0.0-1.0]
        â”œâ”€â”€ binary_map.tif            # ğŸ¯ Nhá»‹ phÃ¢n [0,1]
        â””â”€â”€ visualization.png         # ğŸ¯ Visualization (RGB)
```

---

## ğŸš€ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### BÆ°á»›c 0: CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Option 1: Sá»­ dá»¥ng Conda (Recommended)
conda env create -f environment.yml
conda activate dang

# Option 2: Sá»­ dá»¥ng pip
pip install -r requirements.txt
pip install segmentation-models-pytorch
```

**YÃªu cáº§u:**
- Python 3.8+
- PyTorch 1.13+ (CUDA 11.7+)
- GPU NVIDIA (16GB VRAM khuyáº¿n nghá»‹)
- RAM: 32GB
- Disk: ~10GB trá»‘ng

---

### BÆ°á»›c 1: Train Models

```bash
jupyter notebook notebooks/1_train_models.ipynb
```

**Notebook nÃ y sáº½:**
1. Load patches tá»« CSV coordinates
2. Táº¡o PyTorch DataLoader (train/val split)
3. Train 3 models vá»›i real-time monitoring:
   - Loss/Accuracy curves (live update)
   - Sample predictions visualization
   - Progress bars
4. Save best model checkpoint vÃ o `models/{model_name}/`

**Output:**
- `models/unet_efficientnet/best_model.pth`
- `models/unet_mobilenet/best_model.pth`
- `models/fpn_efficientnet/best_model.pth`
- Training history plots

**Thá»i gian**: ~30-60 phÃºt/model (GPU)

---

### BÆ°á»›c 2: Inference Whole Scene

```bash
jupyter notebook notebooks/2_inference_wholescene.ipynb
```

**Notebook nÃ y sáº½:**
1. Load best model
2. Load 4 áº£nh GeoTIFF gá»‘c (toÃ n bá»™ vÃ¹ng)
3. Sliding window 256Ã—256 vá»›i overlap
4. Predict tá»«ng window
5. Merge predictions â†’ Probability map (numpy array)
6. Visualize progress real-time

**Output:**
- Probability map (numpy array, sáº½ save á»Ÿ bÆ°á»›c 3)
- Preview visualization

**Thá»i gian**: ~10-30 phÃºt (tÃ¹y kÃ­ch thÆ°á»›c áº£nh)

---

### BÆ°á»›c 3: Create Final Maps

```bash
jupyter notebook notebooks/3_create_maps.ipynb
```

**Notebook nÃ y sáº½:**
1. Load probability map tá»« bÆ°á»›c 2
2. Apply threshold (0.5) â†’ Binary map
3. Colorize (0 â†’ Green, 1 â†’ Red)
4. Save 3 outputs dáº¡ng GeoTIFF/PNG

**Output:**
- `results/whole_scene/probability_map.tif` (Float32, 0.0-1.0)
- `results/whole_scene/binary_map.tif` (UInt8, 0-1)
- `results/whole_scene/visualization.png` (RGB)

**Thá»i gian**: ~5 phÃºt

---

## ğŸ“Š Káº¾T QUáº¢ Ká»² Vá»ŒNG

### Metrics (Test set - 129 patches):
- **Accuracy**: 85-90%
- **F1-Score**: 0.85-0.90
- **IoU**: 0.75-0.85

### Báº£n Ä‘á»“ cuá»‘i cÃ¹ng:
- Probability map: XÃ¡c suáº¥t máº¥t rá»«ng táº¡i má»—i pixel
- Binary map: PhÃ¢n loáº¡i rÃµ rÃ ng (0/1)
- Visualization: Trá»±c quan, dá»… hiá»ƒu cho bÃ¡o cÃ¡o

### Statistics vÃ­ dá»¥:
```
Tá»•ng pixels: 50,000,000
KhÃ´ng máº¥t rá»«ng (0): 30,000,000 (60%)
Máº¥t rá»«ng (1): 20,000,000 (40%)
```

---

## ğŸ”§ TECHNICAL DETAILS

### Multi-Sensor Data Fusion:
- **Sentinel-1 (SAR)**: KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng mÃ¢y, nháº¡y vá»›i cáº¥u trÃºc thá»±c váº­t
- **Sentinel-2 (Optical)**: Phá»• pháº£n xáº¡ chi tiáº¿t, indices thá»±c váº­t (NDVI, NBR, NDMI)
- **Fusion**: Concat 18 bands â†’ Single input tensor

### Model Architecture:
```python
# UNet-EfficientNet Example
Input: (B, 18, 256, 256)  # 18 bands, 256x256 patch
  â†“
Encoder: EfficientNet-B0 (pretrained on ImageNet, adapted to 18 channels)
  â†“
Decoder: UNet decoder with skip connections
  â†“
Output: (B, 2, 256, 256)  # 2 classes (no change, change)
  â†“
Softmax â†’ Probability map: (B, 256, 256) values in [0.0, 1.0]
```

### Sliding Window Strategy:
```
Window size: 256Ã—256
Overlap: 32 pixels
Step: 224 pixels
Total windows: ~5,000-10,000 (depends on scene size)
```

---

## ğŸ“š THÆ¯ VIá»†N Sá»¬ Dá»¤NG

### Core Libraries:
- **PyTorch** (1.13+): Deep learning framework
- **segmentation_models_pytorch**: Pre-built segmentation models
- **rasterio**: Read/write GeoTIFF
- **albumentations**: Data augmentation
- **pandas**: CSV processing
- **matplotlib/seaborn**: Visualization

### Model Library:
```python
import segmentation_models_pytorch as smp

model = smp.Unet(
    encoder_name='efficientnet-b0',
    encoder_weights='imagenet',
    in_channels=18,
    classes=2
)
```

---

## ğŸ¯ SO SÃNH 3 MODELS

| TiÃªu chÃ­ | UNet-EfficientNet | UNet-MobileNet | FPN-EfficientNet |
|----------|-------------------|----------------|------------------|
| **Params** | ~5M | ~2M | ~6M |
| **Inference Speed** | âš¡âš¡âš¡ | âš¡âš¡âš¡âš¡ | âš¡âš¡ |
| **Accuracy** | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| **Memory (VRAM)** | ~4GB | ~2GB | ~6GB |
| **Training Time** | ~45 min | ~30 min | ~60 min |
| **Best For** | CÃ¢n báº±ng | Production, Mobile | Highest Accuracy |

---

## âš ï¸ LÆ¯U Ã

### 1. Data Location:
- Äáº£m báº£o 4 áº£nh TIFF + CSV trong `data/raw/`
- Kiá»ƒm tra tá»a Ä‘á»™ CSV khá»›p vá»›i coordinate system cá»§a áº£nh

### 2. GPU Memory:
- UNet-MobileNet: OK vá»›i GPU 8GB
- UNet-EfficientNet: Cáº§n GPU 12GB
- FPN-EfficientNet: Cáº§n GPU 16GB
- Giáº£m batch_size náº¿u bá»‹ OOM

### 3. Whole Scene Inference:
- CÃ³ thá»ƒ máº¥t 10-30 phÃºt tÃ¹y kÃ­ch thÆ°á»›c áº£nh
- Progress bar sáº½ hiá»ƒn thá»‹ tiáº¿n Ä‘á»™
- Náº¿u quÃ¡ lÃ¢u, cÃ³ thá»ƒ chá»‰ inference má»™t pháº§n áº£nh

---

## ğŸ“ CITATION

```bibtex
@thesis{dang2025forest,
  title={Forest Change Detection in Ca Mau using Multi-Sensor Deep Learning},
  author={Ninh Háº£i ÄÄƒng},
  school={VNU University of Engineering and Technology},
  year={2025},
  type={Bachelor's Thesis}
}
```

---

## ğŸ“§ LIÃŠN Há»†

**Sinh viÃªn**: Ninh Háº£i ÄÄƒng
**MSSV**: 21021411
**Email**: ninhhaidangg@gmail.com
**TrÆ°á»ng**: Äáº¡i há»c CÃ´ng nghá»‡ - ÄHQGHN

---

## ğŸ“„ LICENSE

MIT License - Xem file LICENSE

---

## ğŸ™ ACKNOWLEDGMENTS

- **segmentation_models_pytorch**: https://github.com/qubvel/segmentation_models.pytorch
- **PyTorch**: https://pytorch.org/
- **Sentinel Hub**: Dá»¯ liá»‡u vá»‡ tinh Sentinel-1/2
- **VNU-UET**: Há»— trá»£ tÃ i nguyÃªn vÃ  hÆ°á»›ng dáº«n

---

**Last Updated**: 2025-10-18
**Status**: âœ… Ready for development
