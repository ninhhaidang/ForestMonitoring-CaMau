# PhÃ¡t Hiá»‡n Máº¥t Rá»«ng CÃ  Mau Sá»­ Dá»¥ng SNUNet-CD

**Ninh Háº£i ÄÄƒng (21021411) - Äá»“ Ãn Tá»‘t Nghiá»‡p - 2025**

PhÃ¡t hiá»‡n máº¥t rá»«ng ngáº­p máº·n tá»± Ä‘á»™ng sá»­ dá»¥ng Deep Learning káº¿t há»£p áº£nh vá»‡ tinh Ä‘a thá»i gian (Sentinel-2 + Sentinel-1).

---

## ğŸ“Š Dá»¯ Liá»‡u

### Ground Truth
- **1,285 Ä‘iá»ƒm** thá»±c Ä‘á»‹a (shapefile + CSV)
- **635 Ä‘iá»ƒm máº¥t rá»«ng** (49.4%)
- **650 Ä‘iá»ƒm khÃ´ng máº¥t** (50.6%)
- Chia: 80% train (1,028) / 10% val (128) / 10% test (129)

### Sentinel-2 (Quang há»c)
- **T1:** 30/01/2024 â†’ **T2:** 28/02/2025
- **4 bands:** B4 (Äá»), B8 (Cáº­n há»“ng ngoáº¡i), B11 (SWIR1), B12 (SWIR2)
- **3 chá»‰ sá»‘:** NDVI (thá»±c váº­t), NBR (chÃ¡y rá»«ng), NDMI (Ä‘á»™ áº©m)
- **Äá»™ phÃ¢n giáº£i:** 10-20m
- **Files:** 2 file Ã— 1.5GB GeoTIFF

### Sentinel-1 (SAR)
- **T1:** 04/02/2024 â†’ **T2:** 22/02/2025
- **2 features:** VH polarization, Ratio (VV-VH)
- **Äá»™ phÃ¢n giáº£i:** 10m
- **Files:** 2 file Ã— 1.5GB GeoTIFF

### Channels Input

**Phase 1 (chá»‰ S2): 14 channels**
```
TrÆ°á»›c T1: [B4, B8, B11, B12, NDVI, NBR, NDMI] = 7 channels
Sau T2:   [B4, B8, B11, B12, NDVI, NBR, NDMI] = 7 channels
Tá»•ng: 14 channels
```

**Phase 2 (S2+S1): 18 channels**
```
TrÆ°á»›c T1: [B4, B8, B11, B12, NDVI, NBR, NDMI, VH, Ratio] = 9 channels
Sau T2:   [B4, B8, B11, B12, NDVI, NBR, NDMI, VH, Ratio] = 9 channels
Tá»•ng: 18 channels
```

---

## ğŸ§  Model & Training

### Kiáº¿n TrÃºc: SNUNet-CD
```python
SNUNet-CD (Siamese Nested U-Net)
â”œâ”€â”€ Encoder: Siamese (shared weights)
â”‚   â”œâ”€â”€ in_channels: 7 (Phase 1) hoáº·c 9 (Phase 2)
â”‚   â”œâ”€â”€ width: 16
â”‚   â”œâ”€â”€ depth: 4 blocks
â”‚   â””â”€â”€ channels: [16, 32, 64, 128]
â”œâ”€â”€ ECAM: Enhanced Channel Attention Module
â”œâ”€â”€ Decoder: Nested vá»›i dense skip connections
â”‚   â””â”€â”€ channels: [128, 64, 32, 16]
â””â”€â”€ Head: 2 classes (binary change detection)

Sá»‘ parameters: ~1.2M
```

### Config Training
```python
# Hyperparameters
optimizer: AdamW(lr=0.01, weight_decay=0.0005)
scheduler: PolynomialLR(power=0.9, min_lr=1e-4)
loss: CrossEntropyLoss
batch_size: 8
patch_size: 256Ã—256
max_iterations: 40,000
validation_interval: 4,000
workers: 4

# Data Augmentation
RandomRotate(prob=0.5, degree=180)
RandomCrop(256Ã—256)
RandomFlip(horizontal + vertical, prob=0.5)
Normalize(mean=[...], std=[...])
```

### Metrics ÄÃ¡nh GiÃ¡
- Overall Accuracy (má»¥c tiÃªu: >90%)
- F1-Score (má»¥c tiÃªu: >0.85)
- IoU (má»¥c tiÃªu: >0.75)
- Precision (má»¥c tiÃªu: >0.88)
- Recall (má»¥c tiÃªu: >0.82)

---

## ğŸ’» MÃ´i TrÆ°á»ng

### Pháº§n Cá»©ng
```
CPU: Intel Xeon E5-2678 v3 (12 cores @ 2.5GHz)
RAM: 32GB DDR3 ECC
GPU: NVIDIA RTX A4000 (16GB VRAM, 6144 CUDA cores)
Storage: 4TB HDD
OS: Windows 11 Pro
```

### ThÆ° Viá»‡n & PhiÃªn Báº£n
```yaml
# Core
Python: 3.8.20
PyTorch: 1.13.1+cu117
CUDA: 11.7
cuDNN: 8.5.0

# Framework
Open-CD: 1.1.0
  â”œâ”€â”€ MMSegmentation: 1.2.2
  â”œâ”€â”€ MMEngine: 0.10.4
  â”œâ”€â”€ MMCV: 2.1.0
  â””â”€â”€ MMPretrain: 1.2.0

# Geospatial
GDAL: 3.9.2
rasterio: 1.3.11
geopandas: 0.14.4
shapely: 2.0.4

# Image Processing
opencv-python: 4.12.0
albumentations: 1.4.18
pillow: 10.4.0

# Scientific
numpy: 1.24.4
scipy: 1.13.1
pandas: 2.0.3
scikit-learn: 1.3.2

# Visualization
matplotlib: 3.7.5
seaborn: 0.13.2
```

### CÃ i Äáº·t
```bash
# Táº¡o environment
conda env create -f environment.yml
conda activate dang

# CÃ i Open-CD
cd open-cd && pip install -v -e . && cd ..

# Verify
python -c "import torch; print(torch.__version__, torch.cuda.is_available())"
# Expected: 1.13.1+cu117 True
```

---

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # âœ… ÄÃƒ CÃ“
â”‚   â”‚   â”œâ”€â”€ sentinel2/                # 2 files (3GB)
â”‚   â”‚   â”‚   â”œâ”€â”€ S2_2024_01_30.tif    # Before T1
â”‚   â”‚   â”‚   â””â”€â”€ S2_2025_02_28.tif    # After T2
â”‚   â”‚   â”œâ”€â”€ sentinel1/                # 2 files (3GB)
â”‚   â”‚   â”‚   â”œâ”€â”€ S1_2024_02_04_matched_S2_2024_01_30.tif
â”‚   â”‚   â”‚   â””â”€â”€ S1_2025_02_22_matched_S2_2025_02_28.tif
â”‚   â”‚   â””â”€â”€ ground_truth/             # 11 files
â”‚   â”‚       â”œâ”€â”€ Training_Points_CSV.csv
â”‚   â”‚       â””â”€â”€ Training_Points__SHP.*
â”‚   â”œâ”€â”€ processed/                    # â³ Cáº¦N Táº O
â”‚   â”‚   â”œâ”€â”€ phase1_s2only/
â”‚   â”‚   â””â”€â”€ phase2_s2s1/
â”‚   â””â”€â”€ samples/                      # â³ Cáº¦N Táº O
â”‚       â”œâ”€â”€ phase1_s2only/train|val|test/
â”‚       â””â”€â”€ phase2_s2s1/train|val|test/
â”‚
â”œâ”€â”€ notebooks/                        # â³ Cáº¦N CHáº Y
â”‚   â”œâ”€â”€ 01_exploration/
â”‚   â”œâ”€â”€ 02_preprocessing/
â”‚   â”œâ”€â”€ 03_phase1_s2only/
â”‚   â”œâ”€â”€ 04_phase2_s2s1/
â”‚   â””â”€â”€ 05_comparison/
â”‚
â”œâ”€â”€ configs/                          # âœ… ÄÃƒ CÃ“
â”‚   â”œâ”€â”€ phase1_snunet_s2only.py       # Config 14 channels
â”‚   â””â”€â”€ phase2_snunet_s2s1.py         # Config 18 channels
â”‚
â”œâ”€â”€ src/                              # âœ… ÄÃƒ CÃ“
â”‚   â”œâ”€â”€ data_utils.py                 # Load, visualize, tÃ­nh indices
â”‚   â”œâ”€â”€ training_utils.py             # Checkpoint, logging
â”‚   â””â”€â”€ evaluation_utils.py           # Metrics, confusion matrix
â”‚
â”œâ”€â”€ experiments/                      # â³ SAU KHI TRAIN
â”‚   â”œâ”€â”€ phase1_s2only/
â”‚   â”‚   â”œâ”€â”€ checkpoints/              # Model weights
â”‚   â”‚   â”œâ”€â”€ logs/                     # Training logs
â”‚   â”‚   â”œâ”€â”€ metrics/                  # JSON metrics
â”‚   â”‚   â””â”€â”€ predictions/              # Predictions máº«u
â”‚   â””â”€â”€ phase2_s2s1/
â”‚
â”œâ”€â”€ results/                          # â³ SAU KHI INFERENCE
â”‚   â”œâ”€â”€ maps/                         # Báº£n Ä‘á»“ change detection
â”‚   â”œâ”€â”€ statistics/                   # Thá»‘ng kÃª
â”‚   â””â”€â”€ figures/                      # HÃ¬nh áº£nh cho bÃ¡o cÃ¡o
â”‚
â”œâ”€â”€ thesis/                           # â³ CHO BÃO CÃO
â”‚   â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ tables/
â”‚   â””â”€â”€ slides/
â”‚
â”œâ”€â”€ docs/                             # âœ… ÄÃƒ CÃ“
â”‚   â”œâ”€â”€ 00_project_overview.md
â”‚   â”œâ”€â”€ 01_data_guide.md
â”‚   â””â”€â”€ 02_training_guide.md
â”‚
â””â”€â”€ open-cd/                          # âœ… ÄÃƒ CÃ“ (cloned)
    â””â”€â”€ tools/
        â”œâ”€â”€ train.py
        â””â”€â”€ test.py
```

---

## âœ… Tiáº¿n Äá»™ Thá»±c Hiá»‡n

### ÄÃƒ HOÃ€N THÃ€NH âœ… (3 tuáº§n trÆ°á»›c)

- [x] **Setup mÃ´i trÆ°á»ng**
  - [x] CÃ i Python 3.8.20, PyTorch 1.13.1+cu117, CUDA 11.7
  - [x] CÃ i Open-CD 1.1.0 vÃ  dependencies
  - [x] Verify GPU RTX A4000 hoáº¡t Ä‘á»™ng tá»‘t

- [x] **Thu tháº­p dá»¯ liá»‡u**
  - [x] Sentinel-2: 2 files (3GB) - T1, T2
  - [x] Sentinel-1: 2 files (3GB) - matched vá»›i S2
  - [x] Ground truth: 1,285 Ä‘iá»ƒm (shapefile + CSV)

- [x] **Thiáº¿t káº¿ dá»± Ã¡n**
  - [x] Cáº¥u trÃºc thÆ° má»¥c rÃµ rÃ ng
  - [x] Migration tá»« cáº¥u trÃºc cÅ©
  - [x] Cleanup cÃ¡c file khÃ´ng cáº§n thiáº¿t

- [x] **Táº¡o config files**
  - [x] `configs/phase1_snunet_s2only.py` (14 channels)
  - [x] `configs/phase2_snunet_s2s1.py` (18 channels)

- [x] **Viáº¿t utility functions**
  - [x] `src/data_utils.py` (load, visualize, NDVI/NBR/NDMI)
  - [x] `src/training_utils.py` (checkpoint handling)
  - [x] `src/evaluation_utils.py` (metrics, confusion matrix)

- [x] **Documentation**
  - [x] README.md (file nÃ y)
  - [x] docs/ (3 files hÆ°á»›ng dáº«n)

---

## ğŸ“… TIMELINE 1 TUáº¦N (7 NGÃ€Y)

### NGÃ€Y 1 (Thá»© 2): KhÃ¡m PhÃ¡ & Tiá»n Xá»­ LÃ½ â³
**Thá»i gian: 8-10 giá»**

**SÃ¡ng (4h):**
- [ ] **1.1. Explore Sentinel-2** (1.5h)
  - Load T1, T2
  - Visualize RGB composite
  - TÃ­nh NDVI, NBR, NDMI
  - PhÃ¢n tÃ­ch thá»‘ng kÃª
  
- [ ] **1.2. Explore Sentinel-1** (1h)
  - Load SAR data
  - Visualize VH backscatter
  - So sÃ¡nh T1 vs T2
  
- [ ] **1.3. Analyze Ground Truth** (1.5h)
  - Load 1,285 Ä‘iá»ƒm
  - Visualize phÃ¢n bá»‘ khÃ´ng gian
  - Verify class balance

**Chiá»u (4-6h):**
- [ ] **2.1. Preprocess Phase 1** (2h)
  - Extract 4 bands tá»« S2
  - Compute 3 indices
  - Normalize [0,1]
  - Save â†’ `data/processed/phase1_s2only/`
  
- [ ] **2.2. Preprocess Phase 2** (2h)
  - Merge S2 (7ch) + S1 (2ch)
  - Verify co-registration
  - Save â†’ `data/processed/phase2_s2s1/`

**Káº¿t quáº£:** Data Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ táº¡o training samples

---

### NGÃ€Y 2 (Thá»© 3): Táº¡o Training Samples â³
**Thá»i gian: 6-8 giá»**

- [ ] **2.3. Create Training Samples** (6-8h)
  - Extract 256Ã—256 patches xung quanh 1,285 ground truth points
  - Implement coordinate transformation (lat/lon â†’ pixel)
  - Stratified split: 80/10/10
  - Save patches:
    - `data/samples/phase1_s2only/train/` (1,028 patches)
    - `data/samples/phase1_s2only/val/` (128 patches)
    - `data/samples/phase1_s2only/test/` (129 patches)
    - `data/samples/phase2_s2s1/train/` (same split)
  - Visualize má»™t sá»‘ samples Ä‘á»ƒ verify
  - Test dataloader vá»›i Open-CD

**Káº¿t quáº£:** 1,285 Ã— 2 phases = 2,570 training patches sáºµn sÃ ng

---

### NGÃ€Y 3 (Thá»© 4): Training Phase 1 (Buá»•i 1) â³
**Thá»i gian: Training cháº¡y 12-16h, monitor 2-3h**

**SÃ¡ng:**
- [ ] **Báº¯t Ä‘áº§u training Phase 1** (10-15 phÃºt setup)
  ```bash
  python open-cd/tools/train.py configs/phase1_snunet_s2only.py
  ```
- [ ] Setup TensorBoard monitoring
  ```bash
  tensorboard --logdir experiments/phase1_s2only/logs
  ```
- [ ] Verify training báº¯t Ä‘áº§u:
  - Loss giáº£m
  - GPU utilization ~90%
  - No errors

**Trong ngÃ y:**
- [ ] Monitor training má»—i 2-3h
- [ ] Check validation metrics (má»—i 4k iterations)
- [ ] **Training cháº¡y qua Ä‘Ãªm** (40k iterations â‰ˆ 12-16h)

**Chiá»u (tÃ¹y chá»n):**
- [ ] Chuáº©n bá»‹ notebook evaluation
- [ ] Viáº¿t script Ä‘á»ƒ parse logs
- [ ] Chuáº©n bá»‹ visualizations

**Káº¿t quáº£ buá»•i sÃ¡ng ngÃ y 4:** Phase 1 training hoÃ n thÃ nh

---

### NGÃ€Y 4 (Thá»© 5): Evaluate Phase 1 & Start Phase 2 â³
**Thá»i gian: 3h evaluate + Training Phase 2 cháº¡y qua Ä‘Ãªm**

**SÃ¡ng (3h):**
- [ ] **Evaluate Phase 1** 
  - Chá» training Phase 1 hoÃ n thÃ nh (~7-8h sÃ¡ng)
  - Run test:
    ```bash
    python open-cd/tools/test.py \
        configs/phase1_snunet_s2only.py \
        experiments/phase1_s2only/checkpoints/best_model.pth
    ```
  - PhÃ¢n tÃ­ch metrics:
    - Overall Accuracy
    - F1-Score
    - IoU
    - Precision/Recall
  - Plot confusion matrix
  - Visualize predictions (10-20 samples)
  - Save results â†’ `experiments/phase1_s2only/metrics/`

**TrÆ°a (1h):**
- [ ] Tá»•ng káº¿t Phase 1
- [ ] Note cÃ¡c váº¥n Ä‘á»/cáº£i thiá»‡n

**Chiá»u (10-15 phÃºt + cháº¡y qua Ä‘Ãªm):**
- [ ] **Báº¯t Ä‘áº§u training Phase 2**
  ```bash
  python open-cd/tools/train.py configs/phase2_snunet_s2s1.py
  ```
- [ ] Setup monitoring
- [ ] Verify training báº¯t Ä‘áº§u
- [ ] **Training cháº¡y qua Ä‘Ãªm** (40k iterations â‰ˆ 12-16h)

**Káº¿t quáº£ buá»•i sÃ¡ng ngÃ y 5:** Phase 2 training hoÃ n thÃ nh

---

### NGÃ€Y 5 (Thá»© 6): Evaluate Phase 2 & So SÃ¡nh â³
**Thá»i gian: 6-8 giá»**

**SÃ¡ng (3h):**
- [ ] **Evaluate Phase 2**
  - Chá» training hoÃ n thÃ nh (~7-8h sÃ¡ng)
  - Run test
  - PhÃ¢n tÃ­ch metrics
  - Plot confusion matrix
  - Visualize predictions
  - Save results

**Chiá»u (3-5h):**
- [ ] **So sÃ¡nh Phase 1 vs Phase 2**
  - Táº¡o comparison table:
    | Metric | Phase 1 | Phase 2 | Î” |
    |--------|---------|---------|---|
    | Accuracy | ... | ... | ... |
    | F1-Score | ... | ... | ... |
  - Confusion matrices side-by-side
  - Sample predictions comparison
  - Statistical significance test (t-test)
  - Error analysis:
    - Identify failure cases
    - Analyze where S1 helps
  - Save report â†’ `results/statistics/comparison.md`

**Káº¿t quáº£:** Hiá»ƒu rÃµ Phase 2 cáº£i thiá»‡n bao nhiÃªu so vá»›i Phase 1

---

### NGÃ€Y 6 (Thá»© 7): Inference ToÃ n Tá»‰nh â³
**Thá»i gian: 6-10 giá» (tÃ¹y diá»‡n tÃ­ch inference)**

- [ ] **Inference trÃªn toÃ n bá»™ tá»‰nh CÃ  Mau**
  - Chá»n best model (Phase 1 hoáº·c Phase 2)
  - Implement sliding window inference (256Ã—256 vá»›i overlap)
  - Run inference trÃªn toÃ n bá»™ region (cÃ³ thá»ƒ máº¥t 4-8h)
  - Merge predictions â†’ báº£n Ä‘á»“ change detection
  
- [ ] **TÃ­nh toÃ¡n thá»‘ng kÃª**
  - Tá»•ng diá»‡n tÃ­ch máº¥t rá»«ng (kmÂ²)
  - PhÃ¢n bá»‘ theo vÃ¹ng
  - Temporal analysis
  - Export â†’ `results/statistics/deforestation_stats.csv`

- [ ] **Táº¡o visualizations**
  - Change detection map (GeoTIFF + PNG)
  - Heatmap thay Ä‘á»•i
  - Comparison with ground truth overlay
  - Save â†’ `results/maps/` vÃ  `results/figures/`

**Káº¿t quáº£:** Báº£n Ä‘á»“ change detection hoÃ n chá»‰nh cho toÃ n tá»‰nh

---

### NGÃ€Y 7 (Chá»§ Nháº­t): Finalize & Documentation â³
**Thá»i gian: 6-8 giá»**

**SÃ¡ng (3-4h):**
- [ ] **Tá»•ng há»£p káº¿t quáº£**
  - Compile táº¥t cáº£ metrics
  - Táº¡o summary tables
  - Export figures cháº¥t lÆ°á»£ng cao cho thesis
  - Organize trong `thesis/figures/` vÃ  `thesis/tables/`

**Chiá»u (3-4h):**
- [ ] **Update documentation**
  - Update README vá»›i actual results
  - Ghi chÃº lessons learned
  - Document final metrics
  - List limitations & future work
  
- [ ] **Prepare presentation materials**
  - Key findings slides
  - Demo materials
  - Screenshots vÃ  visualizations

- [ ] **Backup & Archive**
  - Backup toÃ n bá»™ code + data quan trá»ng
  - Archive experiments
  - Clean up temporary files

**Káº¿t quáº£:** Dá»± Ã¡n hoÃ n thÃ nh, sáºµn sÃ ng bÃ¡o cÃ¡o

---

## ğŸš€ Quick Commands

### Environment
```bash
conda activate dang
conda deactivate
```

### GPU Check
```bash
nvidia-smi
nvidia-smi -l 1  # Monitor má»—i 1 giÃ¢y
```

### Training
```bash
# Phase 1 (S2 only)
python open-cd/tools/train.py configs/phase1_snunet_s2only.py

# Phase 2 (S2+S1)
python open-cd/tools/train.py configs/phase2_snunet_s2s1.py
```

### Testing
```bash
# Phase 1
python open-cd/tools/test.py \
    configs/phase1_snunet_s2only.py \
    experiments/phase1_s2only/checkpoints/best_model.pth

# Phase 2
python open-cd/tools/test.py \
    configs/phase2_snunet_s2s1.py \
    experiments/phase2_s2s1/checkpoints/best_model.pth
```

### Monitoring
```bash
# TensorBoard
tensorboard --logdir experiments/phase1_s2only/logs
tensorboard --logdir experiments/phase2_s2s1/logs

# Check logs
Get-Content experiments\phase1_s2only\*.log -Tail 50
```

### Jupyter
```bash
jupyter lab
jupyter notebook
```

---

## ğŸ“Š Expected Results (Dá»± Kiáº¿n)

### Phase 1 (S2 only)
- **Accuracy:** ~88-92%
- **F1-Score:** ~0.83-0.87
- **IoU:** ~0.72-0.78
- **Training time:** ~12-16h (40k iterations)

### Phase 2 (S2 + S1)
- **Accuracy:** ~90-94% (+2-4%)
- **F1-Score:** ~0.86-0.91 (+0.03-0.05)
- **IoU:** ~0.76-0.82 (+0.04-0.06)
- **Training time:** ~12-16h (40k iterations)

### Improvement vá»›i S1
- Giáº£m false positives (precision tÄƒng)
- Giáº£m false negatives trong vÃ¹ng mÃ¢y (recall tÄƒng)
- Robust hÆ¡n vá»›i Ä‘iá»u kiá»‡n thá»i tiáº¿t

---

## ğŸ“ Files Quan Trá»ng

### Configs
```python
# configs/phase1_snunet_s2only.py
model = dict(
    backbone=dict(in_channels=7),  # S2 only
    decode_head=dict(num_classes=2)
)
data = dict(
    samples_per_gpu=8,
    data_root='data/samples/phase1_s2only'
)
optimizer = dict(type='AdamW', lr=0.01)
runner = dict(max_iters=40000)
```

```python
# configs/phase2_snunet_s2s1.py
model = dict(
    backbone=dict(in_channels=9),  # S2 + S1
)
data = dict(
    data_root='data/samples/phase2_s2s1'
)
# CÃ²n láº¡i giá»‘ng Phase 1
```

### Utility Functions
```python
# src/data_utils.py
load_geotiff(filepath)              # Load GeoTIFF
visualize_rgb(data, bands)          # Visualize RGB
calculate_ndvi(nir, red)            # NDVI
calculate_nbr(nir, swir2)           # NBR
calculate_ndmi(nir, swir1)          # NDMI

# src/evaluation_utils.py
calculate_metrics(y_true, y_pred)   # All metrics
plot_confusion_matrix(y_true, y_pred)
```

---

## â° Thá»i Gian Æ¯á»›c TÃ­nh Chi Tiáº¿t

| NgÃ y | Task | Giá» lÃ m | Giá» chá» | Tá»•ng |
|------|------|---------|---------|------|
| **1** | Explore + Preprocess | 8-10h | - | 8-10h |
| **2** | Create samples | 6-8h | - | 6-8h |
| **3** | Start Phase 1 training | 0.5h | 12-16h | ~16h |
| **4** | Eval P1 + Start P2 | 3h | 12-16h | ~19h |
| **5** | Eval P2 + Compare | 6-8h | - | 6-8h |
| **6** | Inference | 6-10h | - | 6-10h |
| **7** | Finalize | 6-8h | - | 6-8h |
| **Tá»•ng** | | **36-50h** lÃ m viá»‡c | **24-32h** chá» training |

**LÆ°u Ã½:** 
- Training cháº¡y tá»± Ä‘á»™ng qua Ä‘Ãªm â†’ tiáº¿t kiá»‡m thá»i gian
- NgÃ y 3-4 cÃ³ thá»ƒ lÃ m viá»‡c khÃ¡c trong khi training
- Cáº§n monitor Ä‘á»‹nh ká»³ Ä‘á»ƒ catch errors

---

## ğŸ¯ Checklist Tá»•ng Quan

### Tuáº§n NÃ y (7 NgÃ y)
- [ ] NgÃ y 1: Explore & Preprocess data
- [ ] NgÃ y 2: Create training samples
- [ ] NgÃ y 3: Training Phase 1 (qua Ä‘Ãªm)
- [ ] NgÃ y 4: Evaluate Phase 1 + Training Phase 2 (qua Ä‘Ãªm)
- [ ] NgÃ y 5: Evaluate Phase 2 + Comparison
- [ ] NgÃ y 6: Inference toÃ n tá»‰nh
- [ ] NgÃ y 7: Finalize & Documentation

### Deliverables
- [ ] Trained models (2 phases)
- [ ] Metrics reports (JSON + markdown)
- [ ] Change detection maps
- [ ] Statistics & analysis
- [ ] Visualizations cho thesis
- [ ] Updated documentation

---

**Cáº­p nháº­t láº§n cuá»‘i:** 13/10/2025  
**Tráº¡ng thÃ¡i:** Chuáº©n bá»‹ báº¯t Ä‘áº§u (NgÃ y 1/7)  
**Timeline:** 1 tuáº§n (aggressive)  
**Tiáº¿n Ä‘á»™ hiá»‡n táº¡i:** Setup hoÃ n táº¥t, sáºµn sÃ ng execution