# á»¨ng dá»¥ng Viá»…n thÃ¡m vÃ  Há»c sÃ¢u trong GiÃ¡m sÃ¡t Biáº¿n Ä‘á»™ng Rá»«ng tá»‰nh CÃ  Mau

**Äá»“ Ã¡n tá»‘t nghiá»‡p - CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥**

Sinh viÃªn: **Ninh Háº£i ÄÄƒng** (MSSV: 21021411)
NÄƒm há»c: 2025 - 2026, Há»c ká»³ I

---

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n nÃ y phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng tá»± Ä‘á»™ng giÃ¡m sÃ¡t biáº¿n Ä‘á»™ng rá»«ng táº¡i tá»‰nh CÃ  Mau sá»­ dá»¥ng káº¿t há»£p dá»¯ liá»‡u viá»…n thÃ¡m Ä‘a nguá»“n (Sentinel-1 SAR vÃ  Sentinel-2 Optical) vÃ  mÃ´ hÃ¬nh há»c sÃ¢u (Deep Learning). Há»‡ thá»‘ng cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n vÃ  phÃ¢n loáº¡i cÃ¡c khu vá»±c máº¥t rá»«ng dá»±a trÃªn phÃ¢n tÃ­ch chuá»—i thá»i gian áº£nh vá»‡ tinh.

### Má»¥c tiÃªu

- PhÃ¡t triá»ƒn mÃ´ hÃ¬nh machine learning Ä‘á»ƒ phÃ¡t hiá»‡n máº¥t rá»«ng tá»« áº£nh vá»‡ tinh Ä‘a thá»i gian
- Káº¿t há»£p dá»¯ liá»‡u SAR (Sentinel-1) vÃ  Optical (Sentinel-2) Ä‘á»ƒ nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c
- So sÃ¡nh hiá»‡u suáº¥t giá»¯a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng (Random Forest) vÃ  Deep Learning (CNN)
- Táº¡o báº£n Ä‘á»“ phÃ¢n loáº¡i toÃ n bá»™ khu vá»±c rá»«ng tá»‰nh CÃ  Mau

---

## ğŸ”„ Pipeline Tá»•ng Quan

```mermaid
flowchart TD
    A[ğŸ“¡ Dá»¯ liá»‡u Ä‘áº§u vÃ o] --> B[Sentinel-2<br/>7 bands Ã— 2 ká»³]
    A --> C[Sentinel-1<br/>2 bands Ã— 2 ká»³]
    A --> D[Ground Truth<br/>1,285 points]
    A --> E[Boundary<br/>Shapefile]

    B --> F[ğŸ”§ Tiá»n xá»­ lÃ½]
    C --> F
    E --> F

    F --> G[Clip Outliers<br/>Mask NoData]
    G --> H[Apply Boundary Mask]
    H --> I[Normalize Values]

    I --> J[ğŸ“¦ Patch Extraction]
    D --> J

    J --> K[18-channel patches<br/>64Ã—64 pixels<br/>1,285 samples]

    K --> L[ğŸ“Š Data Split]
    L --> M[Train: 899<br/>70%]
    L --> N[Val: 193<br/>15%]
    L --> O[Test: 193<br/>15%]

    M --> P[ğŸŒ² Random Forest<br/>Baseline ML]
    M --> Q[ğŸ§  Simple CNN<br/>Deep Learning]

    N --> P
    N --> Q

    P --> R[ğŸ“ˆ Evaluation]
    Q --> R

    O --> R

    R --> S[Metrics:<br/>Accuracy, Precision,<br/>Recall, F1, AUC]

    S --> T{Best Model?}

    T -->|RF better| U[Use RF for inference]
    T -->|CNN better| V[Use CNN for inference]

    U --> W[ğŸ—ºï¸ Full Area Inference]
    V --> W

    W --> X[Deforestation Map<br/>CÃ  Mau Province]

    style A fill:#e1f5ff
    style F fill:#fff4e1
    style J fill:#f0e1ff
    style L fill:#e1ffe1
    style P fill:#ffe1e1
    style Q fill:#ffe1e1
    style R fill:#fff9e1
    style W fill:#e1f5e1
    style X fill:#90EE90
```

---

## ğŸ“Š Dá»¯ liá»‡u

### Ground Truth Points
- **Tá»•ng sá»‘ Ä‘iá»ƒm:** 1,285 Ä‘iá»ƒm training
- **PhÃ¢n bá»‘:**
  - Label 0 (KhÃ´ng máº¥t rá»«ng): 650 Ä‘iá»ƒm (50.6%)
  - Label 1 (Máº¥t rá»«ng): 635 Ä‘iá»ƒm (49.4%)
- **Format:** CSV file vá»›i cÃ¡c trÆ°á»ng: `id`, `label`, `x`, `y` (tá»a Ä‘á»™ UTM Zone 48N)
- **File:** `data/raw/ground_truth/Training_Points_CSV.csv`

### Sentinel-2 (Optical)
- **7 bands** gá»“m spectral bands vÃ  spectral indices:
  - **Spectral bands:** B4 (Red), B8 (NIR), B11 (SWIR1), B12 (SWIR2)
  - **Spectral indices:** NDVI, NBR, NDMI
- **Äá»™ phÃ¢n giáº£i khÃ´ng gian:** 10m
- **Ká»³ áº£nh:**
  - TrÆ°á»›c: 30/01/2024 (`S2_2024_01_30.tif`)
  - Sau: 28/02/2025 (`S2_2025_02_28.tif`)
- **ÄÃ£ xá»­ lÃ½:** Cáº¯t theo ranh giá»›i rá»«ng tá»‰nh CÃ  Mau, masked NoData

### Sentinel-1 (SAR)
- **2 bands:** VV vÃ  VH polarization
- **Äá»™ phÃ¢n giáº£i khÃ´ng gian:** 10m (matched vá»›i Sentinel-2)
- **Ká»³ áº£nh:**
  - TrÆ°á»›c: 04/02/2024 (`S1_2024_02_04_matched_S2_2024_01_30.tif`)
  - Sau: 22/02/2025 (`S1_2025_02_22_matched_S2_2025_02_28.tif`)
- **ÄÃ£ xá»­ lÃ½:** Co-registered vá»›i Sentinel-2, cáº¯t theo ranh giá»›i rá»«ng

### Boundary Shapefile
- **File:** `data/raw/boundary/forest_boundary.shp`
- **Má»¥c Ä‘Ã­ch:** Giá»›i háº¡n khu vá»±c phÃ¢n tÃ­ch chá»‰ trong vÃ¹ng rá»«ng

---

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
25-26_HKI_DATN_21021411_DangNH/
â”‚
â”œâ”€â”€ data/                           # ThÆ° má»¥c chá»©a dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                        # Dá»¯ liá»‡u gá»‘c
â”‚   â”‚   â”œâ”€â”€ ground_truth/           # Ground truth CSV
â”‚   â”‚   â”œâ”€â”€ sentinel-1/             # áº¢nh Sentinel-1 SAR
â”‚   â”‚   â”œâ”€â”€ sentinel-2/             # áº¢nh Sentinel-2 Optical
â”‚   â”‚   â””â”€â”€ boundary/               # Shapefile ranh giá»›i rá»«ng
â”‚   â”œâ”€â”€ processed/                  # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â””â”€â”€ patches/                    # Patches Ä‘Ã£ trÃ­ch xuáº¥t
â”‚
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ config.py                   # Cáº¥u hÃ¬nh chung
â”‚   â”œâ”€â”€ utils.py                    # HÃ m tiá»‡n Ã­ch
â”‚   â”œâ”€â”€ preprocessing.py            # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ dataset.py                  # PyTorch Dataset (náº¿u cÃ³)
â”‚   â””â”€â”€ (cÃ¡c module khÃ¡c sáº½ Ä‘Æ°á»£c thÃªm)
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â””â”€â”€ 01_data_exploration.ipynb   # KhÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚
â”œâ”€â”€ models/                         # ThÆ° má»¥c lÆ°u trained models
â”œâ”€â”€ figures/                        # Visualizations vÃ  plots
â”œâ”€â”€ logs/                           # Training logs
â”‚
â”œâ”€â”€ environment.yml                 # Conda environment
â”œâ”€â”€ requirements.txt                # Python dependencies
â””â”€â”€ README.md                       # File nÃ y

```

---

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

### Pháº§n cá»©ng sá»­ dá»¥ng
- **CPU:** Intel Xeon X5670 (hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng)
- **RAM:** 64GB DDR3
- **GPU:** NVIDIA GTX 1060 6GB hoáº·c cao hÆ¡n (há»— trá»£ CUDA)
- **Storage:** â‰¥50GB dung lÆ°á»£ng trá»‘ng

### Pháº§n má»m
- **OS:** Windows 10/11, Linux, macOS
- **Python:** 3.8 - 3.11
- **CUDA:** 11.8+ (náº¿u sá»­ dá»¥ng GPU)
- **Conda/Miniconda:** PhiÃªn báº£n má»›i nháº¥t

---

## âš™ï¸ CÃ i Ä‘áº·t

### BÆ°á»›c 1: Clone repository

```bash
git clone https://github.com/Geospatial-Technology-Lab/25-26_HKI_DATN_21021411_DangNH.git
cd 25-26_HKI_DATN_21021411_DangNH
```

### BÆ°á»›c 2: Táº¡o Conda environment

```bash
conda env create -f environment.yml
conda activate dang
```

**Hoáº·c** sá»­ dá»¥ng pip:

```bash
pip install -r requirements.txt
```

### BÆ°á»›c 3: Verify installation

```python
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

---

## ğŸš€ Sá»­ dá»¥ng

### 1. KhÃ¡m phÃ¡ dá»¯ liá»‡u (Data Exploration)

Cháº¡y notebook Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  visualize dá»¯ liá»‡u:

```bash
cd notebooks
jupyter notebook 01_data_exploration.ipynb
```

**Notebook nÃ y sáº½:**
- Load vÃ  phÃ¢n tÃ­ch ground truth points
- Visualize Sentinel-1 vÃ  Sentinel-2 imagery
- Kiá»ƒm tra value ranges vÃ  data quality
- TrÃ­ch xuáº¥t vÃ  hiá»ƒn thá»‹ sample patches
- Táº¡o cÃ¡c visualizations trong folder `figures/`

**Outputs:**
- CÃ¡c visualizations sáº½ Ä‘Æ°á»£c lÆ°u trong folder `figures/`
- Bao gá»“m: band comparisons, ground truth visualization, sample patches, etc.

### 2. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Data Preprocessing)

TrÃ­ch xuáº¥t patches tá»« toÃ n bá»™ ground truth points:

```bash
python -c "from src.preprocessing import create_patches_dataset; create_patches_dataset(patch_size=64)"
```

**Output:**
- `data/patches/patches_64x64.pkl` - File chá»©a patches vÃ  labels

### 3. Training mÃ´ hÃ¬nh

> **Status:** Script training vÃ  pipeline chÆ°a Ä‘Æ°á»£c hoÃ n thiá»‡n. Sáº½ Ä‘Æ°á»£c develop sau khi xÃ¡c Ä‘á»‹nh kiáº¿n trÃºc model.

### 4. Inference (Dá»± Ä‘oÃ¡n toÃ n bá»™ khu vá»±c)

> **Status:** Script inference sáº½ Ä‘Æ°á»£c develop sau khi hoÃ n thÃ nh training vÃ  chá»n Ä‘Æ°á»£c best model.

---

## ğŸ§  MÃ´ hÃ¬nh vÃ  PhÆ°Æ¡ng phÃ¡p

### Input Data Specification
- **18 channels** tá»« 2 ká»³ áº£nh:
  - **Ká»³ 2024:** 7 bands S2 + 2 bands S1 = 9 channels
  - **Ká»³ 2025:** 7 bands S2 + 2 bands S1 = 9 channels
- **Patch size:** 64Ã—64 pixels
- **Channel order:**
  ```
  [0-6]:   S2 2024 (B4, B8, B11, B12, NDVI, NBR, NDMI)
  [7-8]:   S1 2024 (VV, VH)
  [9-15]:  S2 2025 (B4, B8, B11, B12, NDVI, NBR, NDMI)
  [16-17]: S1 2025 (VV, VH)
  ```

---

### ğŸ¯ Phase 1: Baseline Models

Dá»± Ã¡n báº¯t Ä‘áº§u vá»›i 2 models cÆ¡ báº£n Ä‘á»ƒ thiáº¿t láº­p baseline vÃ  so sÃ¡nh giá»¯a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng vÃ  deep learning.

#### ğŸŒ² Model 1: Random Forest (Baseline Traditional ML)

**Má»¥c Ä‘Ã­ch:** Baseline Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ liá»‡u deep learning cÃ³ thá»±c sá»± vÆ°á»£t trá»™i hÆ¡n phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng khÃ´ng.

**Pipeline:**
```
18-channel patch (18, 64, 64)
    â†“
Feature Extraction (handcrafted):
  â€¢ Per-channel statistics: mean, std, min, max
    â†’ 18 channels Ã— 4 stats = 72 features
  â€¢ Per-channel percentiles: 25th, 50th, 75th
    â†’ 18 channels Ã— 3 = 54 features
  â€¢ Temporal difference features (2025 - 2024):
    â†’ Mean diff, Std diff per band = ~18 features
  â€¢ Total: ~144 features
    â†“
Random Forest Classifier
  â€¢ n_estimators: 500 trees
  â€¢ max_depth: 20
  â€¢ min_samples_split: 10
  â€¢ class_weight: balanced (náº¿u cáº§n)
    â†“
Binary Classification (0: No loss, 1: Deforestation)
```

**Äáº·c Ä‘iá»ƒm:**
- â±ï¸ **Training time:** VÃ i phÃºt
- ğŸ’¾ **Memory:** Minimal (~100MB)
- ğŸ“Š **Interpretable:** Feature importance cÃ³ thá»ƒ visualize
- ğŸ¯ **Expected accuracy:** 75-85% (estimation)

**ThÆ° viá»‡n:** `scikit-learn`

---

#### ğŸ§  Model 2: Simple CNN (Baseline Deep Learning)

**Má»¥c Ä‘Ã­ch:** Baseline deep learning Ä‘á»ƒ há»c features tá»± Ä‘á»™ng tá»« raw patches.

**Architecture:**
```python
SimpleCNN(
  # Input: (batch, 18, 64, 64)

  # Conv Block 1
  Conv2d(18, 32, kernel_size=3, padding=1)
  BatchNorm2d(32)
  ReLU()
  MaxPool2d(2, 2)  # â†’ (32, 32, 32)
  Dropout(0.3)

  # Conv Block 2
  Conv2d(32, 64, kernel_size=3, padding=1)
  BatchNorm2d(64)
  ReLU()
  MaxPool2d(2, 2)  # â†’ (64, 16, 16)
  Dropout(0.3)

  # Conv Block 3
  Conv2d(64, 128, kernel_size=3, padding=1)
  BatchNorm2d(128)
  ReLU()
  MaxPool2d(2, 2)  # â†’ (128, 8, 8)
  Dropout(0.4)

  # Conv Block 4
  Conv2d(128, 256, kernel_size=3, padding=1)
  BatchNorm2d(256)
  ReLU()
  MaxPool2d(2, 2)  # â†’ (256, 4, 4)
  Dropout(0.5)

  # Classifier
  GlobalAvgPool2d()  # â†’ (256,)
  Linear(256, 128)
  ReLU()
  Dropout(0.5)
  Linear(128, 2)
  # Output: (batch, 2) â†’ Softmax
)
```

**Äáº·c Ä‘iá»ƒm:**
- ğŸ“Š **Parameters:** ~1.2M
- ğŸ’¾ **VRAM:** ~2.5-3GB vá»›i batch_size=24 (AMP enabled)
- â±ï¸ **Training time:** ~5-10 phÃºt/epoch (vá»›i cache in RAM)
- ğŸ¯ **Expected accuracy:** 80-90% (estimation)
- ğŸ›¡ï¸ **Regularization:** Heavy dropout, BatchNorm, L2 weight decay

**Táº¡i sao Simple CNN:**
- âœ… **Dataset nhá» (899 training samples):** Model Ä‘Æ¡n giáº£n chá»‘ng overfit tá»‘t
- âœ… **Lightweight:** Fit thoáº£i mÃ¡i trong GTX 1060 6GB
- âœ… **Baseline tá»‘t:** Dá»… train, dá»… debug, dá»… so sÃ¡nh
- âœ… **Proven:** 4-layer CNN Ä‘á»§ cho binary classification

**ThÆ° viá»‡n:** `PyTorch`

---

### ğŸ“Š So sÃ¡nh Models

| Aspect | Random Forest | Simple CNN |
|--------|--------------|------------|
| **Approach** | Traditional ML | Deep Learning |
| **Features** | Handcrafted (144) | Learned automatically |
| **Parameters** | ~500 trees | ~1.2M weights |
| **Training Time** | ~5 phÃºt | ~50-100 phÃºt (10 epochs) |
| **VRAM** | N/A (CPU only) | ~3GB |
| **Interpretability** | â­â­â­â­â­ High | â­â­ Low |
| **Scalability** | â­â­ Limited | â­â­â­â­ Good |
| **Expected Acc** | 75-85% | 80-90% |

---

### ğŸ”® Future Phases (náº¿u Phase 1 thÃ nh cÃ´ng)

Náº¿u Phase 1 cho káº¿t quáº£ tá»‘t, sáº½ thá»­ nghiá»‡m thÃªm:
- **Phase 2:** Siamese Network (chuyÃªn biá»‡t cho change detection)
- **Phase 3:** ResNet18, EfficientNet-B0 (náº¿u cáº§n capacity cao hÆ¡n)

---

## âš™ï¸ Training Configuration

### Configuration cho Simple CNN

#### âœ… ÄÃ£ xÃ¡c Ä‘á»‹nh:

**Data Configuration:**
- **Data split:** 70% train (899), 15% val (193), 15% test (193)
- **Cache strategy:** Load toÃ n bá»™ 1,285 patches vÃ o RAM (~380MB)
- **Data augmentation:** TBD (cÃ³ thá»ƒ thÃªm RandomFlip, RandomRotation náº¿u cáº§n)

**Model Training:**
- **Batch size:** 24 (tá»‘i Æ°u cho Simple CNN vá»›i GTX 1060 6GB)
- **Mixed Precision (AMP):** Enabled - Tiáº¿t kiá»‡m ~40% VRAM, tÄƒng tá»‘c training
- **Gradient Accumulation:** 2 steps â†’ Effective batch size = 48

**Optimization:**
- **Optimizer:** Adam hoáº·c AdamW (TBD sau thá»­ nghiá»‡m)
- **Learning rate:** 1e-3 â†’ 1e-4 (sáº½ grid search)
- **Weight decay (L2):** 1e-4 (chá»‘ng overfit)
- **Scheduler:** ReduceLROnPlateau hoáº·c CosineAnnealing (TBD)

**Regularization:**
- **Dropout:** 0.3 â†’ 0.5 (progressive, Ä‘Ã£ cÃ³ trong architecture)
- **BatchNorm:** Enabled trong má»i conv blocks
- **Early stopping:** Patience = 10-15 epochs

**Training Duration:**
- **Max epochs:** 50-100 (hoáº·c Ä‘áº¿n khi early stopping)
- **Validation frequency:** Má»—i epoch

**Loss Function:**
- **Primary:** CrossEntropyLoss
- **Alternative:** Focal Loss (náº¿u class imbalance sau augmentation)

#### ğŸ“Š Expected Training Resources:

| Resource | Simple CNN | Random Forest |
|----------|-----------|---------------|
| **VRAM** | ~2.5-3GB | N/A (CPU only) |
| **RAM** | ~5-10GB | ~2-5GB |
| **Time/Epoch** | ~5-10 phÃºt | N/A |
| **Total Time** | ~2-4 giá» (20-40 epochs) | ~5-10 phÃºt |

### Configuration cho Random Forest

**KhÃ´ng cáº§n GPU training configuration.** RF sáº½ Ä‘Æ°á»£c train trÃªn CPU vá»›i:
- n_estimators: 500
- max_depth: 20
- min_samples_split: 10
- n_jobs: -1 (dÃ¹ng all CPU cores)

---

## ğŸ”¬ Training Process (Phase 1)

### Flowchart chi tiáº¿t:

```mermaid
flowchart LR
    A[ğŸ“¦ Patches Dataset<br/>1,285 samples] --> B{Split Data<br/>70/15/15}

    B --> C[ğŸ“ Train Set<br/>899 samples]
    B --> D[âœ… Val Set<br/>193 samples]
    B --> E[ğŸ§ª Test Set<br/>193 samples]

    C --> F1[ğŸŒ² Random Forest<br/>Training]
    C --> F2[ğŸ§  Simple CNN<br/>Training]

    F1 --> G1[Feature<br/>Extraction<br/>144 features]
    G1 --> H1[RF Model<br/>500 trees]

    F2 --> G2[Mini-batch<br/>BS=24, AMP]
    G2 --> H2[CNN Forward<br/>+ Backprop]
    H2 --> I2{Epoch<br/>Complete?}

    I2 -->|No| G2
    I2 -->|Yes| J2[Validate<br/>on Val Set]

    D --> J1[Validate RF]
    D --> J2

    H1 --> J1

    J1 --> K1[RF Metrics:<br/>Acc, F1, AUC]
    J2 --> K2[CNN Metrics:<br/>Acc, F1, AUC]

    K2 --> L2{Early<br/>Stop?}
    L2 -->|No, Continue| G2
    L2 -->|Yes| M2[Best CNN<br/>Model]

    K1 --> M1[Final RF<br/>Model]
    M2 --> N[ğŸ“Š Final Evaluation<br/>on Test Set]
    M1 --> N

    E --> N

    N --> O{Compare<br/>Performance}

    O --> P1[RF Results:<br/>Acc, Precision,<br/>Recall, F1, AUC,<br/>Confusion Matrix]
    O --> P2[CNN Results:<br/>Acc, Precision,<br/>Recall, F1, AUC,<br/>Confusion Matrix]

    P1 --> Q[ğŸ“ Analysis &<br/>Report]
    P2 --> Q

    Q --> R{Decision}
    R -->|CNN significantly better| S1[âœ… Use CNN<br/>Proceed Phase 2]
    R -->|RF comparable| S2[âœ… Use RF<br/>ML sufficient]
    R -->|Both good| S3[âœ… Ensemble<br/>RF + CNN]

    style A fill:#e1f5ff
    style C fill:#ffe1e1
    style D fill:#fff4e1
    style E fill:#e1ffe1
    style F1 fill:#d4f1d4
    style F2 fill:#ffd4d4
    style M1 fill:#90EE90
    style M2 fill:#FFB6C1
    style N fill:#FFE4B5
    style Q fill:#DDA0DD
    style S1 fill:#98FB98
    style S2 fill:#98FB98
    style S3 fill:#98FB98
```

---

## ğŸ“ˆ Káº¿t quáº£

> **Status:** Äang trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m vÃ  training models.

### Metrics

CÃ¡c metrics Ä‘Ã¡nh giÃ¡ sáº½ bao gá»“m:
- **Accuracy:** Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Precision:** Äá»™ chÃ­nh xÃ¡c cá»§a class "Máº¥t rá»«ng"
- **Recall:** Kháº£ nÄƒng phÃ¡t hiá»‡n máº¥t rá»«ng
- **F1-Score:** Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
- **Confusion Matrix:** Ma tráº­n nháº§m láº«n
- **ROC-AUC:** Diá»‡n tÃ­ch dÆ°á»›i Ä‘Æ°á»ng cong ROC

### Káº¿t quáº£ so sÃ¡nh models

(Sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau khi hoÃ n thÃ nh training vÃ  evaluation)

### Deforestation Map

(Báº£n Ä‘á»“ phÃ¢n loáº¡i toÃ n bá»™ khu vá»±c rá»«ng CÃ  Mau sáº½ Ä‘Æ°á»£c táº¡o sau khi chá»n Ä‘Æ°á»£c best model)

---

## ğŸ“ Preprocessing Pipeline

### 1. Sentinel-2 Preprocessing
- Äá»c 7 bands tá»« GeoTIFF
- Xá»­ lÃ½ NoData values (convert to NaN)
- Clip outliers vá» physical ranges:
  - Spectral bands (B4, B8, B11, B12): [0, 1]
  - Spectral indices (NDVI, NBR, NDMI): [-1, 1]
- Apply boundary mask (chá»‰ giá»¯ pixels trong vÃ¹ng rá»«ng)

### 2. Sentinel-1 Preprocessing
- Äá»c VV vÃ  VH bands (dB values)
- Apply boundary mask
- MinMax normalization: [min, max] â†’ [0, 1]

### 3. Patch Extraction
- Extract 64Ã—64 patches táº¡i cÃ¡c ground truth points
- Stack 18 channels: [S2_2024, S1_2024, S2_2025, S1_2025]
- Reject patches chá»©a NaN hoáº·c all-zero values
- LÆ°u thÃ nh pickle file cho training

---

## ğŸ”§ Tá»‘i Æ°u hÃ³a cho GTX 1060 6GB + 64GB RAM

Dá»± Ã¡n Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘áº·c biá»‡t cho cáº¥u hÃ¬nh pháº§n cá»©ng hiá»‡n cÃ³.

### GPU Optimization (GTX 1060 6GB) - Simple CNN:

#### Memory Optimization:
- **Mixed Precision Training (AMP):** âœ… Enabled
  - Giáº£m ~40% VRAM usage (float16 thay vÃ¬ float32)
  - TÄƒng tá»‘c training ~20-30%
  - KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘á»™ chÃ­nh xÃ¡c káº¿t quáº£

- **Batch size = 24:**
  - Tá»‘i Æ°u cho Simple CNN (~1.2M params)
  - VRAM usage: ~2.5-3GB / 6GB â†’ cÃ²n dÆ° ~50%
  - Thoáº£i mÃ¡i cho OS + Chrome + VSCode

- **Gradient Accumulation = 2 steps:**
  - Effective batch size = 48
  - GiÃºp training á»•n Ä‘á»‹nh hÆ¡n vá»›i dataset nhá» (899 training samples)
  - Trade-off: cháº­m hÆ¡n ~15-20% nhÆ°ng accuracy tá»‘t hÆ¡n

#### Speed Optimization:
- **cuDNN autotuner:** Enabled Ä‘á»ƒ tÃ¬m conv algorithms nhanh nháº¥t
- **TF32 precision:** Enabled trÃªn Ampere/Ada GPUs (náº¿u upgrade sau)

#### VRAM Breakdown (Simple CNN):
```
Model weights:       ~5 MB    (1.2M params Ã— 4 bytes)
Optimizer states:    ~10 MB   (Adam cÃ³ 2 states)
Batch activations:   ~800 MB  (24 samples Ã— 18ch Ã— 64Ã—64)
Gradients:          ~400 MB
Misc (cuDNN, etc):  ~800 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:              ~2.0-2.5 GB / 6 GB (40% usage)
```

---

### RAM Optimization (64GB DDR3):

#### Data Caching Strategy:
- **Cache patches trong RAM:** âœ… Recommended
  - Load toÃ n bá»™ 1,285 patches má»™t láº§n (~380 MB)
  - Training Cá»°C NHANH (khÃ´ng Ä‘á»c disk má»—i epoch)
  - Epoch time: ~5-10 phÃºt â†’ ~2-3 giÃ¢y (300x faster!)

#### DataLoader Configuration:
```python
DataLoader(
    dataset=cached_dataset,
    batch_size=24,
    shuffle=True,
    num_workers=4,         # Äá»§ vÃ¬ data Ä‘Ã£ trong RAM
    pin_memory=True,       # TÄƒng tá»‘c CPU â†’ GPU transfer
    prefetch_factor=2,     # Prefetch 2 batches/worker
    persistent_workers=True # KhÃ´ng kill workers giá»¯a epochs
)
```

#### RAM Breakdown:
```
Patches cache:       ~380 MB   (1,285 patches)
PyTorch + CUDA:      ~3 GB
OS + Background:     ~8 GB
Browser + IDE:       ~4 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Used:          ~15 GB / 64 GB (25% usage)
Available:           ~49 GB (dÆ° thá»«a nhiá»u!)
```

---

### Training Speed Estimation:

#### Simple CNN (vá»›i cache trong RAM):
- **Forward pass:** ~50ms (24 samples)
- **Backward pass:** ~80ms
- **Total per batch:** ~130ms
- **Batches per epoch:** 899/24 â‰ˆ 38 batches (vá»›i gradient accum = 2 â†’ 19 optimizer steps)
- **Time per epoch:** ~5-8 phÃºt
- **Total training (30 epochs):** ~2.5-4 giá»

#### Random Forest (CPU):
- **Feature extraction:** ~2-3 phÃºt (899 samples)
- **Training:** ~3-5 phÃºt (500 trees)
- **Total:** ~5-8 phÃºt

---

### Performance Tips:

1. **Äá»ƒ Ä‘áº¡t tá»‘c Ä‘á»™ tá»‘i Ä‘a:**
   - âœ… Cache data trong RAM (Ä‘Ã£ enable)
   - âœ… DÃ¹ng `pin_memory=True`
   - âœ… DÃ¹ng AMP (Ä‘Ã£ enable)
   - âš ï¸ ÄÃ³ng Chrome tabs khÃ´ng cáº§n thiáº¿t khi training
   - âš ï¸ Táº¯t Windows Update khi training

2. **Monitor trong training:**
   ```python
   # Trong training loop
   nvidia-smi  # Xem VRAM usage
   htop        # Xem RAM + CPU usage
   ```

3. **Náº¿u OOM (Out of Memory):**
   - Giáº£m batch_size: 24 â†’ 20 â†’ 16
   - TÄƒng gradient accumulation: 2 â†’ 3
   - Effective batch size váº«n giá»¯ = 48

---

## ğŸ“š ThÆ° viá»‡n chÃ­nh

### Deep Learning & ML:
- **PyTorch** 2.0+ - Deep learning framework cho Simple CNN
- **torchvision** - Computer vision utilities vÃ  transforms
- **scikit-learn** - Random Forest vÃ  metrics (Accuracy, Precision, Recall, F1, AUC)

### Geospatial:
- **rasterio** - Äá»c/ghi GeoTIFF files (Sentinel-1, Sentinel-2)
- **geopandas** - Xá»­ lÃ½ vector data (boundary shapefiles)
- **shapely** - Geometric operations

### Data Processing:
- **numpy** - Numerical operations vÃ  array processing
- **pandas** - Data manipulation vÃ  CSV handling

### Visualization:
- **matplotlib** - Plotting vÃ  visualization
- **seaborn** - Statistical visualization
- **plotly** (optional) - Interactive plots

### Utilities:
- **tqdm** - Progress bars
- **pyyaml** - Configuration files
- **tensorboard** (optional) - Training visualization

### Phase 1 Required:
```bash
# Minimum requirements cho Phase 1
pip install torch torchvision
pip install rasterio geopandas
pip install scikit-learn
pip install numpy pandas
pip install matplotlib seaborn tqdm
```

---

## ğŸ¤ ÄÃ³ng gÃ³p

Dá»± Ã¡n nÃ y lÃ  Ä‘á»“ Ã¡n tá»‘t nghiá»‡p cÃ¡ nhÃ¢n. Má»i Ä‘Ã³ng gÃ³p, Ã½ kiáº¿n, vÃ  gÃ³p Ã½ xin vui lÃ²ng liÃªn há»‡ qua email hoáº·c táº¡o issue trÃªn GitHub.

---

## ğŸ“§ LiÃªn há»‡

- **Sinh viÃªn:** Ninh Háº£i ÄÄƒng
- **Email:** ninhhaidangg@gmail.com
- **GitHub:** [ninhhaidang](https://github.com/ninhhaidang)
- **ÄÆ¡n vá»‹:** TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ - ÄHQGHN

---

## ğŸ“„ License

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  giÃ¡o dá»¥c.

---

## ğŸ™ Lá»i cáº£m Æ¡n

- Giáº£ng viÃªn hÆ°á»›ng dáº«n: TS. HÃ  Minh CÆ°á»ng, ThS. HoÃ ng TÃ­ch PhÃºc
- PhÃ²ng thÃ­ nghiá»‡m: Geospatial Technology Lab
- Viá»‡n CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥ - TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡, ÄHQGHN

---

**Cáº­p nháº­t láº§n cuá»‘i:** 06/01/2025
