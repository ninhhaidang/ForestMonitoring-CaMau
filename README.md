# ğŸŒ² á»¨ng Dá»¥ng Viá»…n ThÃ¡m vÃ  Há»c SÃ¢u Trong GiÃ¡m SÃ¡t Biáº¿n Äá»™ng Rá»«ng Tá»‰nh CÃ  Mau

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Äá»“ Ãn Tá»‘t Nghiá»‡p**  
> Sinh viÃªn: Ninh Háº£i ÄÄƒng (MSSV: 21021411)  
> Viá»‡n CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥  
> TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ - Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i  
> Email: ninhhaidangg@gmail.com | GitHub: [@ninhhaidang](https://github.com/ninhhaidang)

---

## ğŸ“‹ Má»¥c Lá»¥c

- [TÃ³m Táº¯t](#tÃ³m-táº¯t)
- [Giá»›i Thiá»‡u](#giá»›i-thiá»‡u)
- [Khu Vá»±c NghiÃªn Cá»©u](#khu-vá»±c-nghiÃªn-cá»©u)
- [PhÆ°Æ¡ng PhÃ¡p NghiÃªn Cá»©u](#phÆ°Æ¡ng-phÃ¡p-nghiÃªn-cá»©u)
- [Cáº¥u TrÃºc Dá»± Ãn](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
- [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng](#hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [Kiáº¿n TrÃºc MÃ´ HÃ¬nh](#kiáº¿n-trÃºc-mÃ´-hÃ¬nh)
- [Káº¿t Quáº£](#káº¿t-quáº£)
- [Tháº£o Luáº­n](#tháº£o-luáº­n)
- [HÆ°á»›ng PhÃ¡t Triá»ƒn](#hÆ°á»›ng-phÃ¡t-triá»ƒn)
- [TÃ i Liá»‡u Tham Kháº£o](#tÃ i-liá»‡u-tham-kháº£o)
- [Lá»i Cáº£m Æ n](#lá»i-cáº£m-Æ¡n)
- [Giáº¥y PhÃ©p](#giáº¥y-phÃ©p)

---

## ğŸ“– TÃ³m Táº¯t

GiÃ¡m sÃ¡t biáº¿n Ä‘á»™ng rá»«ng lÃ  nhiá»‡m vá»¥ quan trá»ng Ä‘á»‘i vá»›i báº£o tá»“n mÃ´i trÆ°á»ng vÃ  quáº£n lÃ½ tÃ i nguyÃªn rá»«ng. Tá»‰nh CÃ  Mau vá»›i há»‡ sinh thÃ¡i rá»«ng ngáº­p máº·n Ä‘áº·c trÆ°ng Ä‘ang Ä‘á»‘i máº·t vá»›i nhiá»u Ã¡p lá»±c tá»« hoáº¡t Ä‘á»™ng nuÃ´i trá»“ng thá»§y sáº£n vÃ  biáº¿n Ä‘á»•i khÃ­ háº­u, Ä‘Ã²i há»i phÆ°Æ¡ng phÃ¡p giÃ¡m sÃ¡t hiá»‡u quáº£ vÃ  ká»‹p thá»i.

CÃ¡c phÆ°Æ¡ng phÃ¡p há»c mÃ¡y truyá»n thá»‘ng (Random Forest, Gradient Boosting, SVM) Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao trong phÃ¢n loáº¡i tá»«ng pixel nhÆ°ng gáº·p pháº£i váº¥n Ä‘á» nhiá»…u muá»‘i tiÃªu (salt-and-pepper noise) do thiáº¿u nháº­n thá»©c vá» ngá»¯ cáº£nh khÃ´ng gian. Äiá»u nÃ y dáº«n Ä‘áº¿n báº£n Ä‘á»“ káº¿t quáº£ cÃ³ nhiá»u pixel bá»‹ phÃ¢n loáº¡i sai rá»i ráº¡c, lÃ m giáº£m cháº¥t lÆ°á»£ng thÃ´ng tin cho quáº£n lÃ½ rá»«ng.

Äá»“ Ã¡n nÃ y Ä‘á» xuáº¥t **khung deep learning Ä‘a thá»i gian** táº­n dá»¥ng dá»¯ liá»‡u SAR Sentinel-1 vÃ  Ä‘a phá»• Sentinel-2 Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c khu vá»±c biáº¿n Ä‘á»™ng rá»«ng táº¡i tá»‰nh CÃ  Mau giá»¯a hai thá»i Ä‘iá»ƒm 2024 vÃ  2025. Ba kiáº¿n trÃºc máº¡ng nÆ¡-ron tÃ­ch cháº­p nÃ´ng (shallow CNN) Ä‘Æ°á»£c triá»ƒn khai vÃ  so sÃ¡nh:

1. **Spatial Context CNN** (~30K tham sá»‘) - Gáº§n nháº¥t vá»›i phÆ°Æ¡ng phÃ¡p ML, bá»• sung lÃ m mÆ°á»£t khÃ´ng gian
2. **Multi-Scale CNN** (~80K tham sá»‘) - CÃ¢n báº±ng, há»c Ä‘áº·c trÆ°ng Ä‘a tá»· lá»‡  
3. **Shallow U-Net** (~120K tham sá»‘) - Kiáº¿n trÃºc encoder-decoder cho tÃ­nh liÃªn káº¿t khÃ´ng gian tá»‘i Æ°u

Khung nghiÃªn cá»©u xá»­ lÃ½ 18 kÃªnh phá»• (9 kÃªnh Ã— 2 thá»i Ä‘iá»ƒm) sá»­ dá»¥ng cÃ¡c patches 128Ã—128 pixels, huáº¥n luyá»‡n trÃªn 1.285 Ä‘iá»ƒm cÃ³ nhÃ£n vá»›i cÃ¡c lá»›p cÃ¢n báº±ng (49,4% máº¥t rá»«ng vs 50,6% khÃ´ng máº¥t rá»«ng). CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho GPU NVIDIA RTX A4000 16GB vÃ  táº¡o ra báº£n Ä‘á»“ xÃ¡c suáº¥t liÃªn tá»¥c (0-1), ká»³ vá»ng sáº½ giáº£m nhiá»…u Ä‘Ã¡ng ká»ƒ so vá»›i phÆ°Æ¡ng phÃ¡p ML truyá»n thá»‘ng.

**Tá»« khÃ³a:** GiÃ¡m sÃ¡t rá»«ng, CÃ  Mau, Rá»«ng ngáº­p máº·n, PhÃ¢n tÃ­ch Ä‘a thá»i gian, Deep Learning, Sentinel-1/2, Viá»…n thÃ¡m, CNN

---

## ğŸ¯ Giá»›i Thiá»‡u

### Bá»‘i Cáº£nh

Tá»‰nh CÃ  Mau náº±m á»Ÿ cá»±c Nam Viá»‡t Nam, sá»Ÿ há»¯u há»‡ sinh thÃ¡i rá»«ng ngáº­p máº·n rá»™ng lá»›n vá»›i vai trÃ² quan trá»ng trong viá»‡c báº£o vá»‡ bá» biá»ƒn, duy trÃ¬ Ä‘a dáº¡ng sinh há»c vÃ  lÆ°u trá»¯ carbon. Tuy nhiÃªn, rá»«ng ngáº­p máº·n CÃ  Mau Ä‘ang Ä‘á»‘i máº·t vá»›i nhiá»u thÃ¡ch thá»©c:

- **Chuyá»ƒn Ä‘á»•i má»¥c Ä‘Ã­ch sá»­ dá»¥ng Ä‘áº¥t**: Má»Ÿ rá»™ng diá»‡n tÃ­ch nuÃ´i trá»“ng thá»§y sáº£n (tÃ´m, cua)
- **Biáº¿n Ä‘á»•i khÃ­ háº­u**: XÃ¢m nháº­p máº·n, nÆ°á»›c biá»ƒn dÃ¢ng, bÃ£o lÅ©
- **Khai thÃ¡c khÃ´ng bá»n vá»¯ng**: Cháº·t phÃ¡ Ä‘á»ƒ láº¥y gá»—, than
- **Suy thoÃ¡i tá»± nhiÃªn**: GiÃ  cá»—i, bá»‡nh háº¡i

Viá»‡c giÃ¡m sÃ¡t biáº¿n Ä‘á»™ng rá»«ng truyá»n thá»‘ng dá»±a vÃ o Ä‘iá»u tra thá»±c Ä‘á»‹a tá»‘n kÃ©m vÃ  khÃ´ng thá»ƒ cáº­p nháº­t thÆ°á»ng xuyÃªn trÃªn diá»‡n rá»™ng. Viá»…n thÃ¡m vá»‡ tinh cung cáº¥p giáº£i phÃ¡p hiá»‡u quáº£ nhÆ°ng cáº§n phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ tiÃªn tiáº¿n Ä‘á»ƒ táº¡o thÃ´ng tin chÃ­nh xÃ¡c vÃ  ká»‹p thá»i.

### PhÃ¡t Biá»ƒu BÃ i ToÃ¡n

**Äáº§u vÃ o:**
- **Dá»¯ liá»‡u**: áº¢nh Sentinel-1 (SAR: VH, VV) vÃ  Sentinel-2 (Ä‘a phá»•: B4, B8, B11, B12 vÃ  cÃ¡c chá»‰ sá»‘ NDVI, NBR, NDMI) tá»« hai thá»i Ä‘iá»ƒm (2024 vÃ  2025)
- **Khu vá»±c**: Tá»‰nh CÃ  Mau
- **Ground truth**: 1.285 Ä‘iá»ƒm cÃ³ nhÃ£n (635 Ä‘iá»ƒm máº¥t rá»«ng, 650 Ä‘iá»ƒm khÃ´ng máº¥t rá»«ng)
- **ThÃ¡ch thá»©c**: PhÆ°Æ¡ng phÃ¡p ML hiá»‡n táº¡i (RF/GBT/SVM) Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao (>90%) nhÆ°ng táº¡o báº£n Ä‘á»“ cÃ³ nhiá»…u pixel rá»i ráº¡c

**Má»¥c tiÃªu:**
1. PhÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh deep learning nÃ´ng phÃ¹ há»£p vá»›i dá»¯ liá»‡u háº¡n cháº¿
2. TÃ­ch há»£p ngá»¯ cáº£nh khÃ´ng gian Ä‘á»ƒ giáº£m nhiá»…u muá»‘i tiÃªu
3. Duy trÃ¬ hoáº·c cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c so vá»›i ML baseline
4. Táº¡o báº£n Ä‘á»“ xÃ¡c suáº¥t mÆ°á»£t, dá»… diá»…n giáº£i cho cÃ´ng tÃ¡c quáº£n lÃ½
5. So sÃ¡nh ba kiáº¿n trÃºc vá»›i Ä‘á»™ phá»©c táº¡p khÃ¡c nhau

### CÃ¢u Há»i NghiÃªn Cá»©u

1. Liá»‡u cÃ¡c kiáº¿n trÃºc CNN nÃ´ng cÃ³ thá»ƒ há»c Ä‘Æ°á»£c Ä‘áº·c trÆ°ng khÃ´ng gian hiá»‡u quáº£ vá»›i chá»‰ ~1.300 máº«u huáº¥n luyá»‡n?
2. KÃ­ch thÆ°á»›c vÃ¹ng tiáº¿p nháº­n (receptive field) nÃ o phÃ¹ há»£p nháº¥t cho Ä‘áº·c Ä‘iá»ƒm rá»«ng ngáº­p máº·n CÃ  Mau?
3. Kiáº¿n trÃºc nÃ o cÃ¢n báº±ng tá»‘t nháº¥t giá»¯a Ä‘á»™ chÃ­nh xÃ¡c, Ä‘á»™ mÆ°á»£t vÃ  tá»‘c Ä‘á»™ tÃ­nh toÃ¡n?
4. Dá»¯ liá»‡u Ä‘a nguá»“n (SAR + Ä‘a phá»•) vÃ  Ä‘a thá»i gian cÃ³ cáº£i thiá»‡n kháº£ nÄƒng phÃ¡t hiá»‡n biáº¿n Ä‘á»™ng so vá»›i Ä‘Æ¡n nguá»“n?

---

## ğŸ—ºï¸ Khu Vá»±c NghiÃªn Cá»©u

### Vá»‹ TrÃ­ Äá»‹a LÃ½

- **Tá»‰nh**: CÃ  Mau
- **Vá»‹ trÃ­**: Cá»±c Nam Viá»‡t Nam (8Â°30' - 9Â°30' Báº¯c, 104Â°45' - 105Â°30' ÄÃ´ng)
- **Diá»‡n tÃ­ch tá»± nhiÃªn**: ~5.331 kmÂ²
- **Äáº·c Ä‘iá»ƒm**: Äá»‹a hÃ¬nh tháº¥p, nhiá»u sÃ´ng ráº¡ch, chá»‹u áº£nh hÆ°á»Ÿng triá»u cÆ°á»ng

### Äáº·c Äiá»ƒm Rá»«ng

- **Loáº¡i rá»«ng chÃ­nh**: Rá»«ng ngáº­p máº·n (mangrove forest)
- **CÃ¡c loÃ i Æ°u tháº¿**: ÄÆ°á»›c (Rhizophora), TrÃ m (Melaleuca), Máº¯m (Avicennia)
- **Diá»‡n tÃ­ch rá»«ng**: ~40.000 ha (sá»‘ liá»‡u tham kháº£o, cáº§n cáº­p nháº­t)
- **PhÃ¢n bá»‘**: Táº­p trung ven biá»ƒn vÃ  ven sÃ´ng

### Ãp Lá»±c LÃªn Rá»«ng

1. **NuÃ´i trá»“ng thá»§y sáº£n**: Chuyá»ƒn Ä‘á»•i rá»«ng thÃ nh ao nuÃ´i tÃ´m
2. **Khai thÃ¡c gá»—**: Láº¥y gá»— xÃ¢y dá»±ng, lÃ m than
3. **Biáº¿n Ä‘á»•i khÃ­ háº­u**: NÆ°á»›c biá»ƒn dÃ¢ng, xÃ¢m nháº­p máº·n
4. **PhÃ¡t triá»ƒn cÆ¡ sá»Ÿ háº¡ táº§ng**: XÃ¢y dá»±ng Ä‘Æ°á»ng, khu dÃ¢n cÆ°

---

## ğŸ”¬ PhÆ°Æ¡ng PhÃ¡p NghiÃªn Cá»©u

### Thu Tháº­p vÃ  Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u

#### Äáº·c Táº£ Dá»¯ Liá»‡u Äáº§u VÃ o

**Sentinel-1 (SAR C-band):**
- **KÃªnh**: 
  - VH (phÃ¢n cá»±c chÃ©o Vertical-Horizontal)
  - R = VV - VH (tá»· sá»‘ phÃ¢n cá»±c)
- **Äá»™ phÃ¢n giáº£i khÃ´ng gian**: 10m
- **NgÃ y thu tháº­p**: 
  - Thá»i Ä‘iá»ƒm 1: 04/02/2024
  - Thá»i Ä‘iá»ƒm 2: 22/02/2025
- **Æ¯u Ä‘iá»ƒm**: XuyÃªn mÃ¢y, hoáº¡t Ä‘á»™ng cáº£ ngÃ y Ä‘Ãªm, nháº¡y cáº£m vá»›i cáº¥u trÃºc tháº£m thá»±c váº­t
- **Tiá»n xá»­ lÃ½**: 
  - Hiá»‡u chuáº©n bá»©c xáº¡ (radiometric calibration)
  - Lá»c nhiá»…u Ä‘á»‘m (speckle filtering) - Lee filter
  - Hiá»‡u chÃ­nh Ä‘á»‹a hÃ¬nh (terrain correction) - Range-Doppler

**Sentinel-2 (Multispectral):**
- **KÃªnh gá»‘c**:
  - B4 (Red): 665 nm, 10m
  - B8 (NIR): 842 nm, 10m  
  - B11 (SWIR1): 1.610 nm, 20m â†’ ná»™i suy vá» 10m
  - B12 (SWIR2): 2.190 nm, 20m â†’ ná»™i suy vá» 10m
- **Chá»‰ sá»‘ tÃ­nh toÃ¡n**:
  - NDVI = (B8 - B4) / (B8 + B4) - Chá»‰ sá»‘ thá»±c váº­t
  - NBR = (B8 - B12) / (B8 + B12) - Chá»‰ sá»‘ chÃ¡y
  - NDMI = (B8 - B11) / (B8 + B11) - Chá»‰ sá»‘ Ä‘á»™ áº©m
- **NgÃ y thu tháº­p**:
  - Thá»i Ä‘iá»ƒm 1: 30/01/2024
  - Thá»i Ä‘iá»ƒm 2: 28/02/2025
- **Äá»™ che phá»§ mÃ¢y**: <10%
- **Tiá»n xá»­ lÃ½**:
  - Hiá»‡u chÃ­nh khÃ­ quyá»ƒn (atmospheric correction) - Sen2Cor
  - Loáº¡i bá» mÃ¢y (cloud masking)
  - Resample B11, B12 vá» 10m

#### Stack Äáº·c TrÆ°ng Äa Thá»i Gian

**Tá»•ng cá»™ng: 18 kÃªnh phá»•**

| STT | TÃªn KÃªnh | Nguá»“n | Thá»i Ä‘iá»ƒm | Ã nghÄ©a |
|-----|----------|-------|-----------|---------|
| 1 | VH_2024 | S1 | 2024 | Backscatter phÃ¢n cá»±c chÃ©o |
| 2 | R_2024 | S1 | 2024 | Tá»· sá»‘ VV/VH |
| 3 | B4_2024 | S2 | 2024 | Pháº£n xáº¡ vÃ¹ng Ä‘á» |
| 4 | B8_2024 | S2 | 2024 | Pháº£n xáº¡ cáº­n há»“ng ngoáº¡i |
| 5 | B11_2024 | S2 | 2024 | Pháº£n xáº¡ SWIR1 |
| 6 | B12_2024 | S2 | 2024 | Pháº£n xáº¡ SWIR2 |
| 7 | NDVI_2024 | S2 | 2024 | Äá»™ xanh thá»±c váº­t |
| 8 | NBR_2024 | S2 | 2024 | Chá»‰ sá»‘ chÃ¡y |
| 9 | NDMI_2024 | S2 | 2024 | Chá»‰ sá»‘ Ä‘á»™ áº©m |
| 10-18 | [Láº·p láº¡i] | - | 2025 | CÃ¹ng 9 kÃªnh nÄƒm 2025 |

**LÃ½ do sá»­ dá»¥ng Ä‘a thá»i gian:**
- PhÃ¡t hiá»‡n **thay Ä‘á»•i** giá»¯a hai thá»i Ä‘iá»ƒm chÃ­nh xÃ¡c hÆ¡n so vá»›i phÃ¢n loáº¡i Ä‘Æ¡n thá»i Ä‘iá»ƒm
- Giáº£m áº£nh hÆ°á»Ÿng cá»§a biáº¿n Ä‘á»™ng theo mÃ¹a (phenology)
- TÄƒng Ä‘á»™ tin cáº­y thÃ´ng qua so sÃ¡nh trá»±c tiáº¿p

#### TrÃ­ch Xuáº¥t Patches

**Quy trÃ¬nh:**
1. **Äáº§u vÃ o**: File CSV chá»©a tá»a Ä‘á»™ UTM (x, y) vÃ  nhÃ£n (0/1) cá»§a 1.285 Ä‘iá»ƒm
2. **TrÃ­ch xuáº¥t**: Vá»›i má»—i Ä‘iá»ƒm (x, y):
   - Cáº¯t vÃ¹ng 128Ã—128 pixels (1,28 km Ã— 1,28 km) xung quanh Ä‘iá»ƒm lÃ m tÃ¢m
   - Láº¥y Ä‘áº§y Ä‘á»§ 18 kÃªnh phá»• â†’ patch cÃ³ kÃ­ch thÆ°á»›c 128Ã—128Ã—18
3. **LÆ°u trá»¯**: Má»—i patch lÆ°u thÃ nh file `.npy` (NumPy array)

**LÃ½ do chá»n 128Ã—128 pixels:**
- **Ngá»¯ cáº£nh khÃ´ng gian**: 1,28Ã—1,28 km Ä‘á»§ lá»›n Ä‘á»ƒ bao quÃ¡t máº«u rá»«ng/khÃ´ng rá»«ng xung quanh
- **Bá»™ nhá»› GPU**: PhÃ¹ há»£p vá»›i batch size 16-32 trÃªn GPU 16GB
- **Receptive field**: Cho phÃ©p model há»c Ä‘áº·c trÆ°ng tá»« vÃ¹ng lÃ¢n cáº­n rá»™ng

**PhÃ¢n bá»‘ lá»›p:**
- Lá»›p 0 (KhÃ´ng máº¥t rá»«ng): 650 máº«u (50,6%)
- Lá»›p 1 (Máº¥t rá»«ng): 635 máº«u (49,4%)
- **Nháº­n xÃ©t**: Dá»¯ liá»‡u cÃ¢n báº±ng tá»‘t, khÃ´ng cáº§n weighted loss

#### TÄƒng CÆ°á»ng Dá»¯ Liá»‡u (Data Augmentation)

Do sá»‘ lÆ°á»£ng máº«u háº¡n cháº¿ (~1.300), Ã¡p dá»¥ng augmentation Ä‘á»ƒ tÄƒng tÃ­nh Ä‘a dáº¡ng:

| Ká»¹ thuáº­t | Tham sá»‘ | Má»¥c Ä‘Ã­ch |
|----------|---------|----------|
| **Rotation** | 90Â°, 180Â°, 270Â° | Báº¥t biáº¿n vá»›i hÆ°á»›ng quay |
| **Horizontal Flip** | p=0.5 | TÄƒng tÃ­nh Ä‘á»‘i xá»©ng |
| **Vertical Flip** | p=0.5 | TÄƒng tÃ­nh Ä‘á»‘i xá»©ng |
| **Gaussian Noise** | Ïƒ=0.01 | TÄƒng tÃ­nh robust vá»›i nhiá»…u |

**KÃ­ch thÆ°á»›c táº­p hiá»‡u quáº£**: ~2.500-3.000 máº«u sau augmentation

#### Chia Táº­p Train/Validation/Test

```
Tá»•ng: 1.285 patches
â”œâ”€â”€ Training:   70% â‰ˆ 900 patches   (huáº¥n luyá»‡n model)
â”œâ”€â”€ Validation: 15% â‰ˆ 190 patches   (tuning hyperparameters, early stopping)
â””â”€â”€ Test:       15% â‰ˆ 195 patches   (Ä‘Ã¡nh giÃ¡ cuá»‘i cÃ¹ng)
```

**Chia phÃ¢n táº§ng (stratified split)**: Äáº£m báº£o tá»· lá»‡ class 0/1 giá»‘ng nhau á»Ÿ cáº£ 3 táº­p

---

### Kiáº¿n TrÃºc MÃ´ HÃ¬nh

#### MÃ´ HÃ¬nh 1: Spatial Context CNN

**Triáº¿t lÃ½ thiáº¿t káº¿:**
- Giá»¯ Ä‘Æ¡n giáº£n nhÆ° ML nhÆ°ng thÃªm kháº£ nÄƒng há»c khÃ´ng gian
- "RF + spatial smoothing"

**Kiáº¿n trÃºc chi tiáº¿t:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: 128Ã—128Ã—18                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv2D(kernel=3Ã—3, filters=32)           â”‚
â”‚ BatchNorm â†’ ReLU                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv2D(kernel=3Ã—3, filters=32)           â”‚
â”‚ BatchNorm â†’ ReLU                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv2D(kernel=1Ã—1, filters=1)            â”‚
â”‚ Sigmoid (output probability [0,1])       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: 128Ã—128Ã—1 (probability map)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ThÃ´ng sá»‘:**
- Sá»‘ lá»›p tÃ­ch cháº­p: 3
- Tá»•ng tham sá»‘: ~30.000
- VÃ¹ng tiáº¿p nháº­n: 5Ã—5 pixels (50m Ã— 50m)

**Äáº·c Ä‘iá»ƒm:**
- Conv 3Ã—3 Ä‘áº§u tiÃªn: Há»c Ä‘áº·c trÆ°ng cá»¥c bá»™
- Conv 3Ã—3 thá»© hai: Má»Ÿ rá»™ng receptive field
- Conv 1Ã—1: Giá»‘ng linear classifier cá»§a ML, káº¿t há»£p cÃ¡c Ä‘áº·c trÆ°ng
- KhÃ´ng cÃ³ pooling â†’ giá»¯ nguyÃªn Ä‘á»™ phÃ¢n giáº£i

**Khi nÃ o dÃ¹ng:**
- Cáº§n baseline Ä‘Æ¡n giáº£n Ä‘á»ƒ so sÃ¡nh
- TÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿
- Æ¯u tiÃªn tá»‘c Ä‘á»™ hÆ¡n cháº¥t lÆ°á»£ng

---

#### MÃ´ HÃ¬nh 2: Multi-Scale CNN

**Triáº¿t lÃ½ thiáº¿t káº¿:**
- Há»c Ä‘á»“ng thá»i á»Ÿ nhiá»u tá»· lá»‡ khÃ´ng gian
- PhÃ¹ há»£p vá»›i máº£ng rá»«ng cÃ³ kÃ­ch thÆ°á»›c khÃ¡c nhau

**Kiáº¿n trÃºc chi tiáº¿t:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: 128Ã—128Ã—18                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BRANCH 1    â”‚  â”‚   BRANCH 2   â”‚
â”‚ Conv(3Ã—3, 32) â”‚  â”‚ Conv(5Ã—5, 32)â”‚
â”‚ BatchNorm     â”‚  â”‚ BatchNorm    â”‚
â”‚ ReLU          â”‚  â”‚ ReLU         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ CONCATENATE  â”‚
         â”‚ 32+32=64 ch  â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv2D(3Ã—3, 64) + BatchNorm + ReLU       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv2D(3Ã—3, 64) + BatchNorm + ReLU       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv2D(1Ã—1, 1) + Sigmoid                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: 128Ã—128Ã—1                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ThÃ´ng sá»‘:**
- Sá»‘ lá»›p tÃ­ch cháº­p: 5 (2 branches + 3 fusion)
- Tá»•ng tham sá»‘: ~80.000
- VÃ¹ng tiáº¿p nháº­n: Branch 1 (7Ã—7), Branch 2 (9Ã—9)

**Äáº·c Ä‘iá»ƒm:**
- **Branch 1 (3Ã—3)**: Báº¯t giá»¯ chi tiáº¿t nhá» (cáº¡nh, texture)
- **Branch 2 (5Ã—5)**: Báº¯t giá»¯ ngá»¯ cáº£nh rá»™ng (máº£ng rá»«ng)
- **Concatenation**: Káº¿t há»£p thÃ´ng tin Ä‘a tá»· lá»‡
- **Fusion layers**: Há»c cÃ¡ch káº¿t há»£p tá»‘i Æ°u hai nhÃ¡nh

**Khi nÃ o dÃ¹ng:**
- **Khuyáº¿n nghá»‹ cho production**
- CÃ¢n báº±ng accuracy-speed-smoothness
- Khi kÃ­ch thÆ°á»›c máº£ng rá»«ng thay Ä‘á»•i nhiá»u

---

#### MÃ´ HÃ¬nh 3: Shallow U-Net

**Triáº¿t lÃ½ thiáº¿t káº¿:**
- Encoder-decoder vá»›i skip connections
- "Shallow" = chá»‰ 1 level downsampling (khÃ´ng quÃ¡ sÃ¢u)

**Kiáº¿n trÃºc chi tiáº¿t:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: 128Ã—128Ã—18                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ENCODER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv(3Ã—3, 32) â†’ Conv(3Ã—3, 32)            â”‚â”€â”€â”
â”‚ BatchNorm, ReLU                          â”‚  â”‚
â”‚ MaxPool(2Ã—2) â†“ [64Ã—64Ã—32]                â”‚  â”‚
â”‚                                          â”‚  â”‚
â”‚ Conv(3Ã—3, 64) â†’ Conv(3Ã—3, 64)            â”‚  â”‚
â”‚ BatchNorm, ReLU                          â”‚  â”‚
â”‚ MaxPool(2Ã—2) â†“ [32Ã—32Ã—64]                â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â†“                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BOTTLENECK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ Conv(3Ã—3, 128) â†’ Conv(3Ã—3, 128)          â”‚  â”‚
â”‚ BatchNorm, ReLU  [32Ã—32Ã—128]             â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â†“                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DECODER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ Upsample(2Ã—2) â†‘ [64Ã—64Ã—128]              â”‚  â”‚
â”‚                                          â”‚  â”‚
â”‚ Concat â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚ [64Ã—64Ã—(128+64)=192]                     â”‚  â”‚
â”‚                                          â”‚  â”‚
â”‚ Conv(3Ã—3, 64) â†’ Conv(3Ã—3, 64)            â”‚  â”‚
â”‚ BatchNorm, ReLU                          â”‚  â”‚
â”‚                                          â”‚  â”‚
â”‚ Upsample(2Ã—2) â†‘ [128Ã—128Ã—64]             â”‚  â”‚
â”‚                                          â”‚  â”‚
â”‚ Concat â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ [128Ã—128Ã—(64+32)=96]                     â”‚
â”‚                                          â”‚
â”‚ Conv(3Ã—3, 32) â†’ Conv(3Ã—3, 32)            â”‚
â”‚ BatchNorm, ReLU                          â”‚
â”‚                                          â”‚
â”‚ Conv(1Ã—1, 1) + Sigmoid                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: 128Ã—128Ã—1                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ThÃ´ng sá»‘:**
- Sá»‘ lá»›p tÃ­ch cháº­p: 8-10
- Tá»•ng tham sá»‘: ~120.000
- VÃ¹ng tiáº¿p nháº­n: 13Ã—13 pixels (130m Ã— 130m)

**Äáº·c Ä‘iá»ƒm:**
- **Encoder**: TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cáº¥p cao thÃ´ng qua downsampling
- **Bottleneck**: Biá»ƒu diá»…n ngá»¯ nghÄ©a á»Ÿ Ä‘á»™ phÃ¢n giáº£i tháº¥p
- **Decoder**: Phá»¥c há»“i Ä‘á»™ phÃ¢n giáº£i thÃ´ng qua upsampling
- **Skip connections**: Giá»¯ láº¡i chi tiáº¿t khÃ´ng gian tá»« encoder
- Chá»‰ 1 level downsampling (shallow) trÃ¡nh overfitting vá»›i Ã­t data

**Khi nÃ o dÃ¹ng:**
- Cáº§n cháº¥t lÆ°á»£ng báº£n Ä‘á»“ tá»‘t nháº¥t
- Äá»™ mÆ°á»£t quan trá»ng (xuáº¥t báº£n, bÃ¡o cÃ¡o)
- CÃ³ Ä‘á»§ thá»i gian tÃ­nh toÃ¡n

---

### Cáº¥u HÃ¬nh Huáº¥n Luyá»‡n

#### HÃ m Loss

**Binary Cross-Entropy (BCE):**

```
L = -1/N Î£ [y_i Â· log(Å·_i) + (1-y_i) Â· log(1-Å·_i)]
```

Trong Ä‘Ã³:
- y_i: NhÃ£n thá»±c táº¿ (0 hoáº·c 1)
- Å·_i: XÃ¡c suáº¥t dá»± Ä‘oÃ¡n [0, 1]
- N: Sá»‘ pixels trong batch

**LÃ½ do chá»n BCE:**
- PhÃ¹ há»£p cho bÃ i toÃ¡n phÃ¢n loáº¡i nhá»‹ phÃ¢n
- Dá»¯ liá»‡u cÃ¢n báº±ng (49.4% vs 50.6%) â†’ khÃ´ng cáº§n weighted loss
- ÄÆ¡n giáº£n, á»•n Ä‘á»‹nh trong training

#### Optimizer vÃ  Learning Rate

**Optimizer: Adam**
- Î²â‚ = 0.9 (momentum)
- Î²â‚‚ = 0.999 (RMSprop)
- Îµ = 1e-8
- Weight decay (L2 regularization) = 1e-4

**Learning Rate Schedule:**
- Initial LR: 1e-3
- **ReduceLROnPlateau**:
  - Monitor: Validation loss
  - Factor: 0.5 (giáº£m má»™t ná»­a)
  - Patience: 5 epochs
  - Min LR: 1e-6

#### Training Configuration

```python
EPOCHS = 100
BATCH_SIZE = 16  # Tá»‘i Æ°u cho GPU 16GB
EARLY_STOPPING_PATIENCE = 10  # Stop náº¿u val_loss khÃ´ng giáº£m sau 10 epochs
```

#### Regularization

1. **Batch Normalization**: Sau má»—i Conv layer
2. **Dropout**: 0.2 (chá»‰ Model 3 - U-Net)
3. **Data Augmentation**: NhÆ° mÃ´ táº£ á»Ÿ trÃªn
4. **L2 Weight Decay**: 1e-4

---

### Chiáº¿n LÆ°á»£c Suy Luáº­n (Inference)

#### Sliding Window vá»›i Overlap

**Váº¥n Ä‘á»:** áº¢nh Ä‘áº§y Ä‘á»§ CÃ  Mau ráº¥t lá»›n (vd: 20.000 Ã— 20.000 pixels) â†’ khÃ´ng thá»ƒ input 1 láº§n

**Giáº£i phÃ¡p:** Sliding window vá»›i overlap

```
BÆ°á»›c 1: Chia áº£nh thÃ nh cÃ¡c cá»­a sá»• 128Ã—128
BÆ°á»›c 2: Stride = 64 pixels (overlap 50%)
BÆ°á»›c 3: Dá»± Ä‘oÃ¡n tá»«ng window
BÆ°á»›c 4: Blend cÃ¡c vÃ¹ng overlap (average)
BÆ°á»›c 5: GhÃ©p thÃ nh báº£n Ä‘á»“ hoÃ n chá»‰nh
```

**Code logic:**

```python
stride = 64  # 50% overlap
output = zeros_like(image)
count = zeros_like(image)

for y in range(0, H-128+1, stride):
    for x in range(0, W-128+1, stride):
        patch = image[y:y+128, x:x+128, :]
        prob = model.predict(patch)  # 128Ã—128Ã—1
        
        output[y:y+128, x:x+128] += prob
        count[y:y+128, x:x+128] += 1

probability_map = output / count  # Average overlaps
```

**Xá»­ lÃ½ biÃªn:** Reflect padding cho vÃ¹ng sÃ¡t mÃ©p

**Output:** Báº£n Ä‘á»“ xÃ¡c suáº¥t liÃªn tá»¥c [0, 1] cho toÃ n bá»™ khu vá»±c

---

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
ca-mau-deforestation/
â”‚
â”œâ”€â”€ README.md                          # File nÃ y âœ…
â”œâ”€â”€ requirements.txt                   # Python dependencies (pip) âœ…
â”œâ”€â”€ environment.yml                    # Conda environment export âœ…
â”œâ”€â”€ DATA_METADATA_REPORT.md            # BÃ¡o cÃ¡o chi tiáº¿t metadata âœ…
â”œâ”€â”€ LICENSE                            # MIT License âœ…
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Dá»¯ liá»‡u thÃ´ âœ…
â”‚   â”‚   â”œâ”€â”€ sentinel1/                 âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ S1_2024_02_04_matched_S2_2024_01_30.tif      (490 MB) âœ…
â”‚   â”‚   â”‚   â””â”€â”€ S1_2025_02_22_matched_S2_2025_02_28.tif      (489 MB) âœ…
â”‚   â”‚   â”œâ”€â”€ sentinel2/                 âœ…
â”‚   â”‚   â”‚   â”œâ”€â”€ S2_2024_01_30.tif                            (1.5 GB) âœ…
â”‚   â”‚   â”‚   â””â”€â”€ S2_2025_02_28.tif                            (1.5 GB) âœ…
â”‚   â”‚   â””â”€â”€ ground_truth/              âœ…
â”‚   â”‚       â”œâ”€â”€ Training_Points_CSV.csv       (1,285 points) âœ…
â”‚   â”‚       â””â”€â”€ Training_Points__SHP.*        (Shapefile)    âœ…
â”‚   â”‚
â”‚   â””â”€â”€ patches/                       # Patches Ä‘Ã£ extract âš ï¸ (CHÆ¯A Táº O)
â”‚       â”œâ”€â”€ train/                     âš ï¸ TRá»NG
â”‚       â”œâ”€â”€ val/                       âš ï¸ TRá»NG
â”‚       â””â”€â”€ test/                      âš ï¸ TRá»NG
â”‚
â”œâ”€â”€ src/                               âœ… (ÄÃƒ Táº O THÆ¯ Má»¤C - Cáº¦N VIáº¾T CODE)
â”‚   â”œâ”€â”€ prepare_data.py               â¬œ Tiá»n xá»­ lÃ½ vÃ  extract patches
â”‚   â”œâ”€â”€ models.py                     â¬œ 3 kiáº¿n trÃºc mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ dataset.py                    â¬œ PyTorch Dataset
â”‚   â”œâ”€â”€ train.py                      â¬œ Script huáº¥n luyá»‡n
â”‚   â”œâ”€â”€ evaluate.py                   â¬œ ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh
â”‚   â””â”€â”€ predict.py                    â¬œ Dá»± Ä‘oÃ¡n toÃ n áº£nh
â”‚
â”œâ”€â”€ notebooks/                         âœ… (ÄÃƒ Táº O)
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb     âœ… KhÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ 02_training_analysis.ipynb    â¬œ PhÃ¢n tÃ­ch quÃ¡ trÃ¬nh train
â”‚   â”œâ”€â”€ 03_results_visualization.ipynb â¬œ Trá»±c quan hÃ³a káº¿t quáº£
â”‚   â””â”€â”€ README.md                     âœ… HÆ°á»›ng dáº«n sá»­ dá»¥ng notebooks
â”‚
â”œâ”€â”€ checkpoints/                       âœ… (ÄÃƒ Táº O - Chá» model weights)
â”‚   â”œâ”€â”€ spatial_cnn_best.pth          â¬œ
â”‚   â”œâ”€â”€ multiscale_cnn_best.pth       â¬œ
â”‚   â””â”€â”€ shallow_unet_best.pth         â¬œ
â”‚
â”œâ”€â”€ outputs/                           âœ… (ÄÃƒ Táº O - Chá» inference)
â”‚   â”œâ”€â”€ probability_maps/             â¬œ
â”‚   â”œâ”€â”€ binary_maps/                  â¬œ
â”‚   â””â”€â”€ statistics/                   â¬œ
â”‚
â”œâ”€â”€ logs/                              âœ… (ÄÃƒ Táº O - Chá» training)
â”‚   â””â”€â”€ training_history.csv          â¬œ
â”‚
â””â”€â”€ figures/                           âœ… (ÄÃƒ Táº O - Chá» plots)
    â”œâ”€â”€ training_curves/              â¬œ
    â”œâ”€â”€ confusion_matrices/           â¬œ
    â””â”€â”€ maps/                         â¬œ
```

---

## ğŸ› ï¸ CÃ i Äáº·t

### YÃªu Cáº§u Há»‡ Thá»‘ng

- **OS**: Windows 10+ / Linux / macOS
- **Python**: 3.8.20 (Ä‘Ã£ test)
- **CUDA**: 11.7 (cho GPU)
- **GPU**: NVIDIA vá»›i â‰¥8GB VRAM (Ä‘Ã£ test trÃªn RTX A4000 16GB)
- **RAM**: â‰¥16GB (khuyáº¿n nghá»‹ 32GB)
- **Disk**: ~20GB (data + checkpoints + outputs)

### MÃ´i TrÆ°á»ng ÄÃ£ CÃ i Äáº·t (Current Setup)

Dá»± Ã¡n Ä‘Ã£ cÃ³ mÃ´i trÆ°á»ng conda hoÃ n chá»‰nh tÃªn **`dang`** vá»›i cÃ¡c thÆ° viá»‡n chÃ­nh:

| ThÆ° viá»‡n | PhiÃªn báº£n | Má»¥c Ä‘Ã­ch |
|----------|-----------|----------|
| PyTorch | 1.13.1+cu117 | Deep learning framework |
| GDAL | 3.6.2 | Xá»­ lÃ½ dá»¯ liá»‡u Ä‘á»‹a khÃ´ng gian |
| Rasterio | 1.3.11 | Äá»c/ghi file GeoTIFF |
| NumPy | 1.24.4 | TÃ­nh toÃ¡n máº£ng sá»‘ há»c |
| OpenCV | 4.12.0.88 | Xá»­ lÃ½ áº£nh |
| Albumentations | 1.4.18 | Data augmentation |
| Scikit-learn | 1.3.2 | Machine learning utilities |
| MMSegmentation | 1.2.2 | Segmentation framework (optional) |
| JupyterLab | 4.2.5 | MÃ´i trÆ°á»ng notebook |

### BÆ°á»›c 1: Clone Repository (náº¿u chÆ°a cÃ³)

```bash
git clone https://github.com/ninhhaidang/ca-mau-deforestation.git
cd ca-mau-deforestation
```

### BÆ°á»›c 2: KÃ­ch Hoáº¡t MÃ´i TrÆ°á»ng

MÃ´i trÆ°á»ng `dang` Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t sáºµn:

```bash
conda activate dang
```

### BÆ°á»›c 3: (TÃ¹y chá»n) CÃ i Äáº·t MÃ´i TrÆ°á»ng Má»›i

Náº¿u muá»‘n táº¡o mÃ´i trÆ°á»ng má»›i tá»« Ä‘áº§u:

**Lá»±a chá»n A: Tá»« environment.yml (Conda - Khuyáº¿n nghá»‹)**

```bash
# Táº¡o mÃ´i trÆ°á»ng má»›i tÃªn 'camau-forest'
conda env create -f environment.yml -n camau-forest
conda activate camau-forest
```

**Lá»±a chá»n B: Tá»« requirements.txt (pip)**

```bash
# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# CÃ i Ä‘áº·t PyTorch vá»›i CUDA 11.7 trÆ°á»›c
pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117

# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cÃ²n láº¡i
pip install -r requirements.txt
```

âš ï¸ **LÆ°u Ã½:**
- GDAL/Rasterio cÃ i Ä‘áº·t qua conda dá»… hÆ¡n pip (trÃªn Windows)
- Náº¿u dÃ¹ng pip, cÃ³ thá»ƒ cáº§n cÃ i GDAL wheel tá»« [Christoph Gohlke's site](https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal)

### BÆ°á»›c 4: Kiá»ƒm Tra CÃ i Äáº·t

```bash
# Kiá»ƒm tra PyTorch vÃ  CUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}')"

# Kiá»ƒm tra Rasterio
python -c "import rasterio; print(f'Rasterio: {rasterio.__version__}')"

# Kiá»ƒm tra GDAL
python -c "import osgeo.gdal as gdal; print(f'GDAL: {gdal.__version__}')"
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
PyTorch: 1.13.1+cu117
CUDA available: True
CUDA version: 11.7
Rasterio: 1.3.11
GDAL: 3.6.2
```

---

## ğŸš€ HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### BÆ°á»›c 0: KhÃ¡m PhÃ¡ Dá»¯ Liá»‡u (TÃ¹y chá»n)

TrÆ°á»›c khi preprocessing, khuyáº¿n nghá»‹ cháº¡y notebook Ä‘á»ƒ khÃ¡m phÃ¡ dá»¯ liá»‡u:

```bash
# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
conda activate dang

# Khá»Ÿi Ä‘á»™ng JupyterLab
jupyter lab

# Má»Ÿ notebook: notebooks/01_data_exploration.ipynb
# Hoáº·c cháº¡y tá»« command line:
jupyter nbconvert --execute --to notebook notebooks/01_data_exploration.ipynb
```

**Notebook nÃ y sáº½:**
- âœ… Kiá»ƒm tra metadata cá»§a 4 áº£nh TIFF
- âœ… PhÃ¢n tÃ­ch statistics (min, max, mean, std, NaN%)
- âœ… Visualize bands vÃ  vegetation indices
- âœ… So sÃ¡nh 2024 vs 2025
- âœ… Táº¡o bÃ¡o cÃ¡o vÃ  figures

**Outputs:**
- `data/metadata_summary.csv`
- `figures/band_nan_comparison.png`
- `figures/band_mean_comparison.png`
- `figures/indices_2024_vs_2025.png`
- `figures/sample_band_images.png`

**Thá»i gian:** ~2-3 phÃºt

**Chi tiáº¿t:** Xem `notebooks/README.md`

---

### BÆ°á»›c 1: Chuáº©n Bá»‹ Dá»¯ Liá»‡u

Extract patches 128Ã—128Ã—18 tá»« áº£nh Sentinel:

```bash
python src/prepare_data.py \
    --sentinel1_dir data/raw/sentinel1 \
    --sentinel2_dir data/raw/sentinel2 \
    --labels_csv data/raw/ground_truth/Training_Points_CSV.csv \
    --output_dir data/patches \
    --patch_size 128 \
    --train_ratio 0.70 \
    --val_ratio 0.15 \
    --augment
```

**Output:**
- ~900 training patches
- ~190 validation patches  
- ~195 test patches

**Thá»i gian dá»± kiáº¿n:** 5-10 phÃºt

---

### BÆ°á»›c 2: Huáº¥n Luyá»‡n MÃ´ HÃ¬nh

Huáº¥n luyá»‡n tá»«ng mÃ´ hÃ¬nh:

```bash
# MÃ´ hÃ¬nh 1: Spatial Context CNN
python src/train.py \
    --model spatial_cnn \
    --data_dir data/patches \
    --epochs 100 \
    --batch_size 16 \
    --lr 0.001 \
    --checkpoint checkpoints/spatial_cnn_best.pth

# MÃ´ hÃ¬nh 2: Multi-Scale CNN
python src/train.py \
    --model multiscale_cnn \
    --data_dir data/patches \
    --epochs 100 \
    --batch_size 16 \
    --lr 0.001 \
    --checkpoint checkpoints/multiscale_cnn_best.pth

# MÃ´ hÃ¬nh 3: Shallow U-Net
python src/train.py \
    --model shallow_unet \
    --data_dir data/patches \
    --epochs 100 \
    --batch_size 16 \
    --lr 0.001 \
    --checkpoint checkpoints/shallow_unet_best.pth
```

**Output:**
- Model weights (`.pth` files)
- Training curves (loss, accuracy over epochs)
- Validation metrics

**Thá»i gian dá»± kiáº¿n:** 30-60 phÃºt/model trÃªn RTX A4000

---

### BÆ°á»›c 3: ÄÃ¡nh GiÃ¡ vÃ  So SÃ¡nh

ÄÃ¡nh giÃ¡ 3 models trÃªn test set:

```bash
python src/evaluate.py \
    --data_dir data/patches/test \
    --checkpoints checkpoints/*.pth \
    --output_dir results
```

**Output:**
- `results/comparison_table.csv` - Báº£ng so sÃ¡nh metrics
- `results/confusion_matrices.png` - Ma tráº­n nháº§m láº«n
- `results/roc_curves.png` - ÄÆ°á»ng cong ROC

**Thá»i gian:** 2-5 phÃºt

---

### BÆ°á»›c 4: Dá»± ÄoÃ¡n ToÃ n áº¢nh

Táº¡o báº£n Ä‘á»“ xÃ¡c suáº¥t cho toÃ n tá»‰nh CÃ  Mau:

```bash
python src/predict.py \
    --sentinel1_dir data/raw/sentinel1 \
    --sentinel2_dir data/raw/sentinel2 \
    --model checkpoints/shallow_unet_best.pth \
    --output_dir outputs \
    --overlap 0.5 \
    --batch_size 32
```

**Output:**
- `outputs/probability_map.tif` - Báº£n Ä‘á»“ xÃ¡c suáº¥t GeoTIFF [0-1]
- `outputs/probability_map.png` - HÃ¬nh áº£nh trá»±c quan
- `outputs/binary_map.tif` - Báº£n Ä‘á»“ nhá»‹ phÃ¢n (threshold=0.5)
- `outputs/statistics.txt` - Thá»‘ng kÃª diá»‡n tÃ­ch

**Thá»i gian:** 10-30 phÃºt (tÃ¹y kÃ­ch thÆ°á»›c áº£nh)

---

## ğŸ—ï¸ Kiáº¿n TrÃºc MÃ´ HÃ¬nh - TÃ³m Táº¯t

### Báº£ng So SÃ¡nh

| TiÃªu ChÃ­ | Spatial Context CNN | Multi-Scale CNN | Shallow U-Net |
|----------|---------------------|-----------------|---------------|
| **Sá»‘ lá»›p** | 3 | 5 | 8-10 |
| **Tham sá»‘** | ~30K | ~80K | ~120K |
| **Receptive field** | 5Ã—5 px (50m) | 7Ã—7 px (70m) | 13Ã—13 px (130m) |
| **Äá»™ phá»©c táº¡p** | â­ | â­â­â­ | â­â­â­â­â­ |
| **Gáº§n ML nháº¥t** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Thá»i gian train dá»± kiáº¿n** | ~20-30 phÃºt | ~30-45 phÃºt | ~45-60 phÃºt |
| **Thá»i gian inference dá»± kiáº¿n** | Nhanh nháº¥t | Trung bÃ¬nh | Cháº­m nháº¥t |

### Khuyáº¿n Nghá»‹ Sá»­ Dá»¥ng

**Spatial Context CNN:**
- âœ… Baseline Ä‘Æ¡n giáº£n
- âœ… TÃ i nguyÃªn háº¡n cháº¿
- âœ… Cáº§n káº¿t quáº£ nhanh

**Multi-Scale CNN:**
- âœ… **Production model (khuyáº¿n nghá»‹)**
- âœ… CÃ¢n báº±ng tá»‘t nháº¥t
- âœ… Äa dáº¡ng kÃ­ch thÆ°á»›c máº£ng rá»«ng

**Shallow U-Net:**
- âœ… Cháº¥t lÆ°á»£ng tá»‘t nháº¥t
- âœ… Báº£n Ä‘á»“ xuáº¥t báº£n
- âœ… CÃ³ thá»i gian tÃ­nh toÃ¡n

---

## ğŸ“Š Káº¿t Quáº£

> **LÆ¯U Ã QUAN TRá»ŒNG:**  
> Pháº§n nÃ y sáº½ Ä‘Æ°á»£c cáº­p nháº­t sau khi hoÃ n thÃ nh thá»±c nghiá»‡m. CÃ¡c báº£ng dÆ°á»›i Ä‘Ã¢y lÃ  **template** Ä‘á»ƒ Ä‘iá»n káº¿t quáº£ thá»±c táº¿.

### Metrics Äá»‹nh LÆ°á»£ng (Test Set, nâ‰ˆ195)

**Báº£ng 1: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ**

| MÃ´ HÃ¬nh | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|---------|----------|-----------|--------|----------|---------|
| Random Forest (Baseline) | _TBD_ | _TBD_ | _TBD_ | _TBD_ | _TBD_ |
| Spatial Context CNN | _TBD_ | _TBD_ | _TBD_ | _TBD_ | _TBD_ |
| Multi-Scale CNN | _TBD_ | _TBD_ | _TBD_ | _TBD_ | _TBD_ |
| Shallow U-Net | _TBD_ | _TBD_ | _TBD_ | _TBD_ | _TBD_ |

**Báº£ng 2: Giáº£m nhiá»…u (Qualitative Assessment)**

| MÃ´ HÃ¬nh | Pixel Nhiá»…u Rá»i Ráº¡c* | Äiá»ƒm Äá»™ MÆ°á»£t** |
|---------|----------------------|----------------|
| Random Forest | _TBD_ | _TBD_ |
| Spatial Context CNN | _TBD_ | _TBD_ |
| Multi-Scale CNN | _TBD_ | _TBD_ |
| Shallow U-Net | _TBD_ | _TBD_ |

*Sá»‘ pixel nhiá»…u trÃªn 1000pxÂ²  
**ÄÃ¡nh giÃ¡ chá»§ quan (1-5, 5=ráº¥t mÆ°á»£t)

### Hiá»‡u Suáº¥t TÃ­nh ToÃ¡n

**Báº£ng 3: Training Performance (RTX A4000 16GB)**

| MÃ´ HÃ¬nh | Epochs Há»™i Tá»¥ | Thá»i Gian Training | GPU Memory |
|---------|---------------|-------------------|------------|
| Spatial Context CNN | _TBD_ | _TBD_ | _TBD_ |
| Multi-Scale CNN | _TBD_ | _TBD_ | _TBD_ |
| Shallow U-Net | _TBD_ | _TBD_ | _TBD_ |

**Báº£ng 4: Inference Performance**

| MÃ´ HÃ¬nh | Thá»i Gian (toÃ n áº£nh) | Throughput | GPU Memory |
|---------|---------------------|-----------|------------|
| Spatial Context CNN | _TBD_ | _TBD_ | _TBD_ |
| Multi-Scale CNN | _TBD_ | _TBD_ | _TBD_ |
| Shallow U-Net | _TBD_ | _TBD_ | _TBD_ |

### PhÃ¢n TÃ­ch Äá»‹nh TÃ­nh

_(Sáº½ cáº­p nháº­t sau thá»±c nghiá»‡m)_

- So sÃ¡nh visual giá»¯a 3 models
- VÃ­ dá»¥ vÃ¹ng giáº£m nhiá»…u tá»‘t
- TrÆ°á»ng há»£p khÃ³ (edges, vÃ¹ng chuyá»ƒn tiáº¿p)

---

## ğŸ’¬ Tháº£o Luáº­n

### ÄÃ³ng GÃ³p Khoa Há»c

1. **Ãp dá»¥ng DL cho rá»«ng ngáº­p máº·n Viá»‡t Nam**: NghiÃªn cá»©u Ä‘áº§u tiÃªn sá»­ dá»¥ng shallow CNN cho monitoring rá»«ng ngáº­p máº·n táº¡i CÃ  Mau
2. **Giáº£i quyáº¿t váº¥n Ä‘á» dá»¯ liá»‡u háº¡n cháº¿**: Chá»©ng minh shallow networks hiá»‡u quáº£ vá»›i ~1.300 samples
3. **Káº¿t há»£p Ä‘a nguá»“n**: SAR + Optical + Multi-temporal trong má»™t framework
4. **Practical deployment**: Models nháº¹, deploy Ä‘Æ°á»£c trÃªn GPU thÃ´ng thÆ°á»ng

### So SÃ¡nh Vá»›i CÃ¡c NghiÃªn Cá»©u TrÆ°á»›c

| TiÃªu ChÃ­ | NghiÃªn Cá»©u NÃ y | CÃ¡c NghiÃªn Cá»©u TrÆ°á»›c |
|----------|----------------|---------------------|
| **Khu vá»±c** | CÃ  Mau, Viá»‡t Nam | Chá»§ yáº¿u nÆ°á»›c ngoÃ i |
| **Loáº¡i rá»«ng** | Rá»«ng ngáº­p máº·n | Äa dáº¡ng |
| **Model** | Shallow CNN (3-10 layers) | Deep networks (50+ layers) |
| **Training data** | ~1.300 samples | ThÆ°á»ng >10.000 |
| **Äá»™ phá»©c táº¡p** | 30K-120K params | >1M params |
| **Focus** | Giáº£m nhiá»…u + chÃ­nh xÃ¡c | Chá»§ yáº¿u chÃ­nh xÃ¡c |

### Háº¡n Cháº¿

1. **Pháº¡m vi thá»i gian**: Chá»‰ 2 thá»i Ä‘iá»ƒm (2024-2025)
2. **Khu vá»±c**: Chá»‰ CÃ  Mau, chÆ°a test kháº£ nÄƒng tá»•ng quÃ¡t
3. **Training data**: Point labels, chÆ°a pháº£i polygon
4. **Cloud cover**: Sentinel-2 bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi mÃ¢y
5. **Validation**: ChÆ°a cÃ³ cross-regional validation

### Ã NghÄ©a Thá»±c Tiá»…n

**Cho Quáº£n LÃ½ Rá»«ng:**
- Cung cáº¥p báº£n Ä‘á»“ cáº­p nháº­t nhanh, chi phÃ­ tháº¥p
- Há»— trá»£ phÃ¡t hiá»‡n sá»›m biáº¿n Ä‘á»™ng báº¥t thÆ°á»ng
- Äá»‹nh lÆ°á»£ng diá»‡n tÃ­ch máº¥t rá»«ng cho bÃ¡o cÃ¡o

**Cho NghiÃªn Cá»©u:**
- Framework má»Ÿ rá»™ng cho cÃ¡c khu vá»±c khÃ¡c
- Benchmark cho cÃ¡c nghiÃªn cá»©u sau
- Code má»Ÿ, dá»… replicate

---

## ğŸ”® HÆ°á»›ng PhÃ¡t Triá»ƒn

### Ngáº¯n Háº¡n (3-6 thÃ¡ng)

1. **Má»Ÿ rá»™ng thá»i gian**: TÃ­ch há»£p thÃªm cÃ¡c thá»i Ä‘iá»ƒm khÃ¡c (2023, 2026)
2. **TÄƒng training data**: Bá»• sung thÃªm Ä‘iá»ƒm ground truth
3. **Ensemble**: Káº¿t há»£p 3 models Ä‘á»ƒ tÄƒng Ä‘á»™ tin cáº­y
4. **Hyperparameter tuning**: Tá»‘i Æ°u learning rate, batch size, augmentation

### Trung Háº¡n (6-12 thÃ¡ng)

1. **Cross-validation**: Test trÃªn cÃ¡c vÃ¹ng khÃ¡c (Báº¡c LiÃªu, KiÃªn Giang)
2. **Temporal extension**: Sá»­ dá»¥ng time-series (LSTM/Transformer)
3. **Multi-task learning**: PhÃ¡t hiá»‡n Ä‘á»“ng thá»i nhiá»u loáº¡i biáº¿n Ä‘á»™ng (chÃ¡y, cháº·t phÃ¡, suy thoÃ¡i)
4. **Weakly supervised**: Giáº£m nhu cáº§u labeling chÃ­nh xÃ¡c

### DÃ i Háº¡n (1-2 nÄƒm)

1. **Operational system**: Tá»± Ä‘á»™ng hÃ³a toÃ n bá»™ pipeline tá»« download áº£nh Ä‘áº¿n cáº£nh bÃ¡o
2. **Google Earth Engine**: Scale lÃªn toÃ n vÃ¹ng Äá»“ng báº±ng sÃ´ng Cá»­u Long
3. **Mobile app**: á»¨ng dá»¥ng di Ä‘á»™ng cho kiá»ƒm lÃ¢m thá»±c Ä‘á»‹a
4. **Carbon accounting**: Káº¿t há»£p vá»›i mÃ´ hÃ¬nh sinh khá»‘i Ä‘á»ƒ Æ°á»›c tÃ­nh COâ‚‚

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

### NghiÃªn Cá»©u ChÃ­nh

1. Hansen, M. C., et al. (2013). High-Resolution Global Maps of 21st-Century Forest Cover Change. *Science*.

2. Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. *MICCAI*.

3. Kattenborn, T., et al. (2021). Review on CNN in Vegetation Remote Sensing. *ISPRS Journal*.

4. Pham, T. D., et al. (2019). Monitoring Mangrove Biomass Change in Vietnam using SPOT Images and an Object-Based Approach. *GIScience & Remote Sensing*.

### Vá» Rá»«ng CÃ  Mau

5. Nguyá»…n Há»¯u Äá»©c, et al. (2018). ÄÃ¡nh giÃ¡ hiá»‡n tráº¡ng rá»«ng ngáº­p máº·n tá»‰nh CÃ  Mau. *Táº¡p chÃ­ Khoa há»c LÃ¢m nghiá»‡p*.

6. VÅ© VÄƒn Vá»¥, et al. (2020). Biáº¿n Ä‘á»™ng sá»­ dá»¥ng Ä‘áº¥t rá»«ng ngáº­p máº·n ven biá»ƒn ÄBSCL. *Táº¡p chÃ­ Khoa há»c ÄHQGHN*.

### Tools vÃ  Dá»¯ Liá»‡u

- **Sentinel Data**: European Space Agency Copernicus Programme
- **PyTorch**: Paszke et al. (2019). *NeurIPS*.
- **Rasterio**: Geospatial raster I/O for Python

---

## ğŸ™ Lá»i Cáº£m Æ n

Äá»“ Ã¡n nÃ y Ä‘Æ°á»£c hoÃ n thÃ nh dÆ°á»›i sá»± hÆ°á»›ng dáº«n cá»§a:

**Giáº£ng viÃªn hÆ°á»›ng dáº«n:** [TÃªn Giáº£ng ViÃªn]  
Viá»‡n CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥  
TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡, ÄHQGHN

ChÃ¢n thÃ nh cáº£m Æ¡n:
- **ÄHQG HÃ  Ná»™i - ÄH CÃ´ng Nghá»‡** - Cung cáº¥p tÃ i nguyÃªn vÃ  há»— trá»£
- **Sá»Ÿ NÃ´ng nghiá»‡p vÃ  PTNT tá»‰nh CÃ  Mau** - Há»— trá»£ dá»¯ liá»‡u thá»±c Ä‘á»‹a (náº¿u cÃ³)
- **ESA Copernicus** - Dá»¯ liá»‡u Sentinel miá»…n phÃ­
- **Cá»™ng Ä‘á»“ng PyTorch vÃ  GDAL** - CÃ´ng cá»¥ mÃ£ nguá»“n má»Ÿ
- **Gia Ä‘Ã¬nh vÃ  báº¡n bÃ¨** - Äá»™ng viÃªn trong suá»‘t quÃ¡ trÃ¬nh nghiÃªn cá»©u

---

## ğŸ“„ Giáº¥y PhÃ©p

Dá»± Ã¡n nÃ y Ä‘Æ°á»£c phÃ¡t hÃ nh theo giáº¥y phÃ©p MIT License. Xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t chi tiáº¿t.

### TrÃ­ch Dáº«n

Náº¿u báº¡n sá»­ dá»¥ng code hoáº·c phÆ°Æ¡ng phÃ¡p nÃ y trong nghiÃªn cá»©u, vui lÃ²ng trÃ­ch dáº«n:

```bibtex
@thesis{ninh2025camau,
  author       = {Ninh Háº£i ÄÄƒng},
  title        = {á»¨ng Dá»¥ng Viá»…n ThÃ¡m vÃ  Há»c SÃ¢u Trong GiÃ¡m SÃ¡t Biáº¿n Äá»™ng Rá»«ng Tá»‰nh CÃ  Mau},
  school       = {TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡, ÄHQG HÃ  Ná»™i},
  year         = {2025},
  type         = {Äá»“ Ã¡n Tá»‘t nghiá»‡p},
  address      = {HÃ  Ná»™i, Viá»‡t Nam},
  note         = {Viá»‡n CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥}
}
```

---

## ğŸ“ LiÃªn Há»‡

**Ninh Háº£i ÄÄƒng**  
MSSV: 21021411  
Email: ninhhaidangg@gmail.com  
GitHub: [@ninhhaidang](https://github.com/ninhhaidang)

**ÄÆ¡n vá»‹:**  
Viá»‡n CÃ´ng nghá»‡ HÃ ng khÃ´ng VÅ© trá»¥  
TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡  
Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i  
144 XuÃ¢n Thá»§y, Cáº§u Giáº¥y, HÃ  Ná»™i

---

<p align="center">
  <sub>XÃ¢y dá»±ng vá»›i â¤ï¸ vÃ¬ báº£o vá»‡ rá»«ng ngáº­p máº·n CÃ  Mau ğŸŒ²ğŸ¦€</sub>
</p>