# ·ª®ng d·ª•ng Vi·ªÖn th√°m v√† H·ªçc s√¢u trong Gi√°m s√°t Bi·∫øn ƒë·ªông R·ª´ng t·ªânh C√† Mau

**ƒê·ªì √°n t·ªët nghi·ªáp - C√¥ng ngh·ªá H√†ng kh√¥ng V≈© tr·ª•**

Sinh vi√™n: **Ninh H·∫£i ƒêƒÉng** (MSSV: 21021411)
NƒÉm h·ªçc: 2025 - 2026, H·ªçc k·ª≥ I

---

## üìã T·ªïng quan

D·ª± √°n ph√°t tri·ªÉn h·ªá th·ªëng t·ª± ƒë·ªông gi√°m s√°t bi·∫øn ƒë·ªông r·ª´ng t·∫°i t·ªânh C√† Mau s·ª≠ d·ª•ng k·∫øt h·ª£p d·ªØ li·ªáu vi·ªÖn th√°m ƒëa ngu·ªìn (Sentinel-1 SAR v√† Sentinel-2 Optical) v·ªõi hai ph∆∞∆°ng ph√°p:
- **Random Forest (RF)**: Ph√¢n lo·∫°i d·ª±a tr√™n pixel v·ªõi 27 ƒë·∫∑c tr∆∞ng th·ªùi gian
- **Convolutional Neural Network (CNN)**: Ph√¢n lo·∫°i d·ª±a tr√™n patches 3√ó3 pixels, t·ª± ƒë·ªông h·ªçc spatial patterns

C·∫£ hai ph∆∞∆°ng ph√°p ƒë·∫°t ƒë·ªô ch√≠nh x√°c > 98% trong ph√°t hi·ªán m·∫•t r·ª´ng.

---

## üîÑ Quy tr√¨nh x·ª≠ l√Ω

### T·ªïng quan workflow

```mermaid
flowchart TB
    subgraph Input["üì• INPUT DATA"]
        S2B["Sentinel-2 Before<br/>7 bands, 10m<br/>30/01/2024"]
        S2A["Sentinel-2 After<br/>7 bands, 10m<br/>28/02/2025"]
        S1B["Sentinel-1 Before<br/>VV+VH, 10m<br/>04/02/2024"]
        S1A["Sentinel-1 After<br/>VV+VH, 10m<br/>22/02/2025"]
        GT["Ground Truth<br/>2,630 points<br/>4 classes"]
        BD["Forest Boundary<br/>Shapefile"]
    end

    subgraph Processing["‚öôÔ∏è DATA PROCESSING"]
        Load["Data Loading<br/>src/core/data_loader.py"]
        FeatExt["Feature Extraction<br/>src/core/feature_extraction.py<br/>27 features = S2(21) + S1(6)"]
        Mask["Apply Forest Mask<br/>Valid pixels only"]
    end

    subgraph Split["üîÄ PIPELINE SPLIT"]
        Choice{"Ch·ªçn ph∆∞∆°ng ph√°p"}
    end

    subgraph RF["üå≤ RANDOM FOREST PIPELINE"]
        RF1["Extract Training Data<br/>Pixel-based<br/>src/models/rf/trainer.py"]
        RF2["Train/Val/Test Split<br/>70% / 15% / 15%<br/>Stratified Random"]
        RF3["Train Random Forest<br/>100 trees<br/>sklearn"]
        RF4["Evaluate Model<br/>src/core/evaluation.py<br/>Metrics + Feature Importance"]
        RF5["Predict Full Raster<br/>src/models/rf/predictor.py<br/>Batch: 10k pixels"]
        RF6["Save Results<br/>Model + Maps + Plots"]
    end

    subgraph CNN["üß† CNN PIPELINE"]
        CNN1["Spatial Clustering<br/>src/models/cnn/spatial_split.py<br/>Distance threshold: 50m"]
        CNN2["Extract 3√ó3 Patches<br/>src/models/cnn/patch_extractor.py<br/>Spatial context"]
        CNN3["Normalize Patches<br/>Z-score standardization"]
        CNN4["Train/Val/Test Split<br/>70% / 15% / 15%<br/>Cluster-based"]
        CNN5["Train CNN Model<br/>src/models/cnn/trainer.py<br/>2 Conv + GAP + FC"]
        CNN6["Evaluate Model<br/>src/core/evaluation.py<br/>Metrics + Training curves"]
        CNN7["Predict Full Raster<br/>src/models/cnn/predictor.py<br/>Sliding window"]
        CNN8["Save Results<br/>Model + Maps + Plots"]
    end

    subgraph Output["üìä OUTPUTS"]
        Model["Trained Models<br/>rf_model.pkl / cnn_model.pth"]
        Raster["Classification Maps<br/>Binary + Probability<br/>GeoTIFF format"]
        Metrics["Evaluation Metrics<br/>Accuracy, F1, ROC-AUC"]
        Plots["Visualizations<br/>Confusion Matrix, ROC, Maps"]
    end

    S2B & S2A & S1B & S1A & GT & BD --> Load
    Load --> FeatExt
    FeatExt --> Mask
    Mask --> Choice

    Choice -->|"Pixel-based"| RF1
    RF1 --> RF2 --> RF3 --> RF4 --> RF5 --> RF6

    Choice -->|"Patch-based"| CNN1
    CNN1 --> CNN2 --> CNN3 --> CNN4 --> CNN5 --> CNN6 --> CNN7 --> CNN8

    RF6 --> Model & Raster & Metrics & Plots
    CNN8 --> Model & Raster & Metrics & Plots

    style Input fill:#e1f5ff
    style Processing fill:#fff3e0
    style Split fill:#f3e5f5
    style RF fill:#e8f5e9
    style CNN fill:#fce4ec
    style Output fill:#fff9c4
```

### Random Forest Pipeline (Chi ti·∫øt)

```mermaid
flowchart LR
    subgraph Data["INPUT<br/>27 features"]
        F["Feature Stack<br/>(27, H, W)"]
        G["Ground Truth<br/>(2,630 points)"]
    end

    subgraph Extract["EXTRACT TRAINING"]
        E1["Convert coords ‚Üí pixels<br/>Geographic to raster"]
        E2["Extract pixel values<br/>At GT locations"]
        E3["Create DataFrame<br/>(N, 27 features + label)"]
    end

    subgraph Split["SPLIT DATA"]
        S1["Stratified Split<br/>sklearn.train_test_split"]
        S2["Train: 70%<br/>Val: 15%<br/>Test: 15%"]
    end

    subgraph Train["TRAIN MODEL"]
        T1["RandomForestClassifier<br/>n_estimators=100<br/>max_features='sqrt'"]
        T2["Fit on training data<br/>X_train, y_train"]
        T3["Validate on val set<br/>Early assessment"]
    end

    subgraph Eval["EVALUATE"]
        EV1["Test Set Metrics<br/>Accuracy, F1, AUC"]
        EV2["Feature Importance<br/>Gini-based ranking"]
        EV3["Cross-Validation<br/>5-fold stratified"]
    end

    subgraph Predict["PREDICT RASTER"]
        P1["Reshape features<br/>(H√óW, 27)"]
        P2["Batch prediction<br/>10k pixels/batch"]
        P3["4-class probabilities<br/>Softmax output"]
        P4["Binary conversion<br/>Class 1 vs Rest"]
        P5["Reshape to map<br/>(H, W)"]
    end

    subgraph Output["OUTPUT"]
        O1["Classification Map<br/>0/1/2/3/-1"]
        O2["Probability Map<br/>P(Deforestation)"]
        O3["Model File<br/>rf_model.pkl"]
    end

    F & G --> E1 --> E2 --> E3
    E3 --> S1 --> S2
    S2 --> T1 --> T2 --> T3
    T3 --> EV1 & EV2 & EV3
    EV1 --> P1 --> P2 --> P3 --> P4 --> P5
    P5 --> O1 & O2
    T3 --> O3

    style Data fill:#e3f2fd
    style Extract fill:#f1f8e9
    style Split fill:#fff3e0
    style Train fill:#fce4ec
    style Eval fill:#f3e5f5
    style Predict fill:#e0f2f1
    style Output fill:#fff9c4
```

### CNN Pipeline (Chi ti·∫øt)

```mermaid
flowchart LR
    subgraph Data["INPUT<br/>27 features"]
        F["Feature Stack<br/>(27, H, W)"]
        G["Ground Truth<br/>(2,630 points)"]
    end

    subgraph Spatial["SPATIAL SPLIT"]
        SP1["Hierarchical Clustering<br/>Distance: 50m threshold"]
        SP2["Cluster assignment<br/>Prevent spatial leakage"]
        SP3["Split clusters<br/>Train/Val/Test<br/>70/15/15"]
    end

    subgraph Patch["EXTRACT PATCHES"]
        PA1["Convert coords ‚Üí pixels"]
        PA2["Extract 3√ó3 patches<br/>At each GT point"]
        PA3["Check validity<br/>No NaN, within bounds"]
        PA4["Normalize<br/>Z-score: (x-Œº)/œÉ"]
    end

    subgraph Arch["CNN ARCHITECTURE"]
        A1["Input: 3√ó3√ó27"]
        A2["Conv1: 27‚Üí64<br/>BatchNorm, ReLU<br/>Dropout 0.3"]
        A3["Conv2: 64‚Üí32<br/>BatchNorm, ReLU<br/>Dropout 0.3"]
        A4["Global Avg Pool<br/>32 features"]
        A5["FC1: 32‚Üí64<br/>BatchNorm, ReLU<br/>Dropout 0.5"]
        A6["FC2: 64‚Üí4<br/>4-class logits"]
    end

    subgraph Train["TRAINING"]
        TR1["DataLoader<br/>batch_size=32"]
        TR2["Loss: CrossEntropy<br/>Optimizer: AdamW<br/>LR: 0.001"]
        TR3["Training Loop<br/>Max 50 epochs"]
        TR4["LR Scheduler<br/>ReduceLROnPlateau"]
        TR5["Early Stopping<br/>patience=10"]
        TR6["Save Best Model<br/>Min val_loss"]
    end

    subgraph Eval["EVALUATE"]
        EV1["Test Metrics<br/>Accuracy, F1, AUC"]
        EV2["Training Curves<br/>Loss, Accuracy"]
        EV3["Confusion Matrix<br/>Per-class performance"]
    end

    subgraph Predict["PREDICT RASTER"]
        PR1["Sliding Window<br/>Extract all 3√ó3 patches"]
        PR2["Normalize patches<br/>Using training stats"]
        PR3["Batch inference<br/>GPU accelerated<br/>1k patches/batch"]
        PR4["4-class probabilities<br/>Softmax"]
        PR5["Binary conversion<br/>Class 1 vs Rest"]
        PR6["Fill output map<br/>(H, W)"]
    end

    subgraph Output["OUTPUT"]
        O1["Classification Map<br/>0/1/2/3/-1"]
        O2["Probability Map<br/>P(Deforestation)"]
        O3["Model File<br/>cnn_model.pth"]
        O4["Training History<br/>Loss curves"]
    end

    F & G --> SP1 --> SP2 --> SP3
    SP3 --> PA1 --> PA2 --> PA3 --> PA4
    PA4 --> A1 --> A2 --> A3 --> A4 --> A5 --> A6
    A6 --> TR1 --> TR2 --> TR3 --> TR4 --> TR5 --> TR6
    TR6 --> EV1 & EV2 & EV3
    EV1 --> PR1 --> PR2 --> PR3 --> PR4 --> PR5 --> PR6
    PR6 --> O1 & O2
    TR6 --> O3 & O4

    style Data fill:#e3f2fd
    style Spatial fill:#fff3e0
    style Patch fill:#f1f8e9
    style Arch fill:#fce4ec
    style Train fill:#f3e5f5
    style Eval fill:#e1bee7
    style Predict fill:#e0f2f1
    style Output fill:#fff9c4
```

---

## üìä D·ªØ li·ªáu

### Ground Truth Points
- **File:** [`data/raw/samples/4labels.csv`](data/raw/samples/4labels.csv)
- **T·ªïng s·ªë ƒëi·ªÉm:** 2,630 ƒëi·ªÉm training
- **Format:** CSV v·ªõi c√°c tr∆∞·ªùng: `id`, `label`, `x`, `y` (t·ªça ƒë·ªô UTM Zone 48N, EPSG:32648)
- **Ph√¢n b·ªë labels (4 classes):**
  - **Class 0:** R·ª´ng ·ªïn ƒë·ªãnh (Forest Stable) - 656 ƒëi·ªÉm
  - **Class 1:** M·∫•t r·ª´ng (Deforestation) - 650 ƒëi·ªÉm
  - **Class 2:** Kh√¥ng ph·∫£i r·ª´ng (Non-forest) - 664 ƒëi·ªÉm
  - **Class 3:** T√°i sinh r·ª´ng (Reforestation) - 660 ƒëi·ªÉm

### Sentinel-2 (Optical)
- **7 bands** g·ªìm spectral bands v√† spectral indices:
  - **Spectral bands:** B4 (Red), B8 (NIR), B11 (SWIR1), B12 (SWIR2)
  - **Spectral indices:** NDVI, NBR, NDMI
- **ƒê·ªô ph√¢n gi·∫£i kh√¥ng gian:** 10m
- **K·ª≥ ·∫£nh:**
  - Tr∆∞·ªõc: 30/01/2024 ([`S2_2024_01_30.tif`](data/raw/sentinel-2/S2_2024_01_30.tif))
  - Sau: 28/02/2025 ([`S2_2025_02_28.tif`](data/raw/sentinel-2/S2_2025_02_28.tif))
- **X·ª≠ l√Ω:** C·∫Øt theo ranh gi·ªõi r·ª´ng, masked NoData

### Sentinel-1 (SAR)
- **2 bands:** VV v√† VH polarization
- **ƒê·ªô ph√¢n gi·∫£i kh√¥ng gian:** 10m (co-registered v·ªõi Sentinel-2)
- **K·ª≥ ·∫£nh:**
  - Tr∆∞·ªõc: 04/02/2024 ([`S1_2024_02_04_matched_S2_2024_01_30.tif`](data/raw/sentinel-1/S1_2024_02_04_matched_S2_2024_01_30.tif))
  - Sau: 22/02/2025 ([`S1_2025_02_22_matched_S2_2025_02_28.tif`](data/raw/sentinel-1/S1_2025_02_22_matched_S2_2025_02_28.tif))
- **X·ª≠ l√Ω:** Co-registered v·ªõi Sentinel-2, c·∫Øt theo ranh gi·ªõi r·ª´ng

### Boundary Shapefile
- **File:** [`data/raw/boundary/forest_boundary.shp`](data/raw/boundary/forest_boundary.shp)
- **CRS:** EPSG:32648 (WGS 84 / UTM Zone 48N)
- **M·ª•c ƒë√≠ch:** Gi·ªõi h·∫°n khu v·ª±c ph√¢n t√≠ch trong ranh gi·ªõi r·ª´ng

---

## üóÇÔ∏è C·∫•u tr√∫c d·ª± √°n

```
25-26_HKI_DATN_21021411_DangNH/
‚îú‚îÄ‚îÄ README.md                        # T√†i li·ªáu n√†y
‚îú‚îÄ‚îÄ environment.yml                  # Conda environment specification
‚îÇ
‚îú‚îÄ‚îÄ data/                            # Th∆∞ m·ª•c d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # D·ªØ li·ªáu th√¥
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentinel-1/              # ·∫¢nh SAR (VV, VH)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentinel-2/              # ·∫¢nh Optical (7 bands)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ boundary/                # Ranh gi·ªõi khu v·ª±c nghi√™n c·ª©u
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ samples/                 # Ground truth training points
‚îÇ   ‚îî‚îÄ‚îÄ inference/                   # D·ªØ li·ªáu inference (n·∫øu c√≥)
‚îÇ
‚îú‚îÄ‚îÄ src/                             # Source code ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # C·∫•u h√¨nh t·∫≠p trung (paths, hyperparameters)
‚îÇ   ‚îú‚îÄ‚îÄ main_rf.py                   # Entry point cho Random Forest pipeline
‚îÇ   ‚îú‚îÄ‚îÄ main_cnn.py                  # Entry point cho CNN pipeline
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                     # Utility functions
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                        # Core modules (shared by RF & CNN)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py           # Load Sentinel-1/2, ground truth, boundary
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_extraction.py    # T·∫°o 27-feature stack (before/after/delta)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py            # Model evaluation (metrics, CV, ROC)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visualization.py         # Plotting (confusion matrix, ROC, maps)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                      # Model-specific implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rf/                      # Random Forest (pixel-based)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py           # RF training & feature extraction
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predictor.py         # RF full raster prediction
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cnn/                     # CNN (patch-based)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ architecture.py      # CNN architecture (2 conv blocks + FC)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ trainer.py           # CNN training loop (early stopping, LR scheduler)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ patch_extractor.py   # Extract 3√ó3 patches t·ª´ ground truth
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ spatial_split.py     # Spatial-aware train/val/test split
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ predictor.py         # CNN full raster prediction (sliding window)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ calibration.py       # Probability calibration (isotonic regression)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ analysis/                    # Analysis utilities
‚îÇ       ‚îî‚îÄ‚îÄ spatial_clustering.py    # Ground truth spatial distribution analysis
‚îÇ
‚îú‚îÄ‚îÄ notebook/                        # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ rf_deforestion_detection.ipynb      # RF pipeline v·ªõi interactive exploration
‚îÇ   ‚îî‚îÄ‚îÄ cnn_deforestation_detection.ipynb   # CNN pipeline v·ªõi training visualization
‚îÇ
‚îî‚îÄ‚îÄ results/                         # Th∆∞ m·ª•c output
    ‚îú‚îÄ‚îÄ models/                      # Trained models
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_model.pkl             # Random Forest (~277 KB)
    ‚îÇ   ‚îî‚îÄ‚îÄ cnn_model.pth            # CNN PyTorch model (~448 KB)
    ‚îÇ
    ‚îú‚îÄ‚îÄ data/                        # Output data files
    ‚îÇ   ‚îú‚îÄ‚îÄ training_data.csv        # Extracted training features (RF)
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_feature_importance.csv
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_evaluation_metrics.json
    ‚îÇ   ‚îú‚îÄ‚îÄ cnn_training_patches.npz # Extracted patches (CNN)
    ‚îÇ   ‚îú‚îÄ‚îÄ cnn_evaluation_metrics.json
    ‚îÇ   ‚îî‚îÄ‚îÄ cnn_training_history.json
    ‚îÇ
    ‚îú‚îÄ‚îÄ rasters/                     # GeoTIFF output maps
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_classification.tif    # RF binary classification (0/1)
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_probability.tif       # RF probability map (0.0-1.0)
    ‚îÇ   ‚îú‚îÄ‚îÄ cnn_classification.tif   # CNN binary classification (0/1)
    ‚îÇ   ‚îî‚îÄ‚îÄ cnn_probability.tif      # CNN probability map (0.0-1.0)
    ‚îÇ
    ‚îú‚îÄ‚îÄ plots/                       # Visualization outputs (PNG, 300 DPI)
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_confusion_matrices.png
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_roc_curve.png
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_feature_importance.png
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_classification_maps.png
    ‚îÇ   ‚îú‚îÄ‚îÄ rf_cv_scores.png
    ‚îÇ   ‚îú‚îÄ‚îÄ cnn_confusion_matrices.png
    ‚îÇ   ‚îú‚îÄ‚îÄ cnn_roc_curve.png
    ‚îÇ   ‚îú‚îÄ‚îÄ cnn_training_curves.png
    ‚îÇ   ‚îî‚îÄ‚îÄ cnn_classification_maps.png
    ‚îÇ
    ‚îî‚îÄ‚îÄ report/                      # Markdown reports
        ‚îú‚îÄ‚îÄ rf_report_YYYYMMDD_HHMMSS.md
        ‚îî‚îÄ‚îÄ cnn_report_YYYYMMDD_HHMMSS.md
```

---

## üìà Ph∆∞∆°ng ph√°p

### Random Forest Pipeline (Pixel-based Classification)

**Input unit:** Single pixel (27 features)

**Feature engineering (27 features):**
```
Sentinel-2 (21 features):
  - S2_before[0:7]:  B4, B8, B11, B12, NDVI, NBR, NDMI
  - S2_after[0:7]:   B4, B8, B11, B12, NDVI, NBR, NDMI
  - S2_delta[0:7]:   ŒîB4, ŒîB8, ŒîB11, ŒîB12, ŒîNDVI, ŒîNBR, ŒîNDMI

Sentinel-1 (6 features):
  - S1_before[0:2]:  VV, VH
  - S1_after[0:2]:   VV, VH
  - S1_delta[0:2]:   ŒîVV, ŒîVH
```

**Training configuration:**
- **Algorithm:** RandomForestClassifier (scikit-learn)
- **Number of trees:** 100
- **Max features per split:** sqrt(27) ‚âà 5
- **Class weight:** Balanced
- **Train/Val/Test split:** 70% / 15% / 15% (stratified)
- **Cross-validation:** 5-fold stratified

**Advantages:**
- Fast training (~5 minutes)
- High interpretability (feature importance)
- Robust to noise and missing data
- Low memory requirements

**Disadvantages:**
- No spatial context (treats each pixel independently)
- Cannot learn spatial patterns

---

### CNN Pipeline (Patch-based Classification)

**Input unit:** 3√ó3 patch (3√ó3√ó27 = 243 values)

**Architecture:**
```
Input: (batch, 3, 3, 27) patches
  ‚Üì
Permute ‚Üí (batch, 27, 3, 3)    # PyTorch format (N, C, H, W)
  ‚Üì
Conv Block 1: 27‚Üí64 channels (3√ó3, BatchNorm, ReLU, Dropout 0.3)
  ‚Üì
Conv Block 2: 64‚Üí32 channels (3√ó3, BatchNorm, ReLU, Dropout 0.3)
  ‚Üì
Global Average Pooling ‚Üí (batch, 32)
  ‚Üì
FC Block: 32‚Üí64 (BatchNorm, ReLU, Dropout 0.5)
  ‚Üì
Output: 64‚Üí4 (logits)
```

**Training configuration:**
- **Optimizer:** AdamW (lr=0.001, weight_decay=1e-4)
- **Loss function:** CrossEntropyLoss (balanced class weights)
- **LR Scheduler:** ReduceLROnPlateau (factor=0.5, patience=5)
- **Early stopping:** patience=10 epochs
- **Batch size:** 32
- **Epochs:** 50 (max)
- **Data split:** Spatial-aware split (prevent spatial leakage)

**Regularization techniques:**
- Batch Normalization (stabilize training)
- Dropout (0.3 conv, 0.5 fc)
- Weight Decay (L2 regularization)
- Data augmentation (optional)

**Advantages:**
- Learns spatial patterns automatically
- Better for detecting neighborhood changes
- More flexible architecture

**Disadvantages:**
- Slower training (~15-30 minutes)
- Requires more data
- Lower interpretability (black-box)
- Higher memory requirements

---

### So s√°nh 2 ph∆∞∆°ng ph√°p

| Aspect | Random Forest | CNN |
|--------|--------------|-----|
| **Input Unit** | Single pixel (27 features) | 3√ó3 patch (3√ó3√ó27) |
| **Spatial Context** | Kh√¥ng | C√≥ (3√ó3 neighborhood) |
| **Feature Learning** | Manual | Automatic |
| **Training Time** | ~5-10 ph√∫t | ~15-30 ph√∫t |
| **Model Size** | ~277 KB | ~448 KB |
| **Inference Speed** | Nhanh (~10k pixels/s) | Ch·∫≠m h∆°n (~1k patches/s) |
| **Interpretability** | Cao (feature importance) | Th·∫•p (black-box) |
| **Data Requirements** | √çt | Nhi·ªÅu h∆°n |
| **Overfitting Risk** | Th·∫•p (ensemble) | Cao h∆°n (c·∫ßn regularization) |
| **Edge Handling** | T·∫•t c·∫£ valid pixels | B·ªè edge pixels (1-pixel margin) |
| **Expected Accuracy** | >98% | >98% |

---

## üìä K·∫øt qu·∫£

### Metrics ƒë∆∞·ª£c ƒë√°nh gi√°

**Classification metrics:**
- Accuracy (Overall, Per-class)
- Precision, Recall, F1-Score
- Confusion Matrix (Train/Val/Test)
- ROC Curve & AUC Score

**Model-specific metrics:**
- **Random Forest:**
  - Feature importance (Gini)
  - Out-of-Bag (OOB) score
  - 5-fold Cross-validation scores

- **CNN:**
  - Training curves (loss, accuracy)
  - Learning rate schedule
  - Early stopping epoch
  - Probability calibration (ECE, Brier score)

### Output files

**GeoTIFF rasters:**
- Multi-class classification maps (0=Forest Stable, 1=Deforestation, 2=Non-forest, 3=Reforestation, -1=NoData)
- Probability maps (0.0-1.0 = probability for each class, -9999.0=NoData)
- CRS: EPSG:32648 (UTM Zone 48N)
- Resolution: 10m

**Visualizations:**
- Confusion matrices (train/val/test)
- ROC curves with AUC
- Feature importance plots (RF)
- Training curves (CNN)
- Classification maps (binary + probability)

**Reports:**
- Markdown format v·ªõi timestamp
- Comprehensive model evaluation
- Data configuration summary
- Key findings v√† statistics

---

## üî¨ T√≠nh nƒÉng n√¢ng cao

### 1. Spatial-Aware Data Splitting (CNN)
- **Problem:** Prevent spatial data leakage gi·ªØa train/val/test
- **Solution:** Hierarchical clustering v·ªõi 50m distance threshold
- **Result:** Train/val/test kh√¥ng c√≥ spatial overlap

### 2. Multi-Sensor Integration
- **Optical (Sentinel-2):** Spectral signatures, vegetation indices
- **SAR (Sentinel-1):** Penetrates clouds, structure information
- **Combined:** Robust trong m·ªçi ƒëi·ªÅu ki·ªán th·ªùi ti·∫øt

### 3. Temporal Change Detection
- **Before/After comparison:** Detect changes between two time periods
- **Delta features:** Explicitly model temporal change (Œî = After - Before)
- **Temporal consistency:** Reduce false positives

### 4. Probability Calibration (CNN)
- **Post-training calibration:** Isotonic regression
- **Improve reliability:** Predicted probabilities match true frequencies
- **Risk-aware decisions:** Better for threshold-based decision making

### 5. Batch Processing for Memory Efficiency
- **Random Forest:** 10,000 pixels/batch
- **CNN:** 1,000 patches/batch
- **Full raster prediction:** Kh√¥ng c·∫ßn load to√†n b·ªô dataset v√†o memory

---

## üõ†Ô∏è Configuration

T·∫•t c·∫£ c·∫•u h√¨nh ƒë∆∞·ª£c qu·∫£n l√Ω t·∫≠p trung trong [`src/config.py`](src/config.py):

**Paths:**
- Input data paths (S1, S2, ground truth, boundary)
- Output directories (models, rasters, plots, reports)

**Hyperparameters:**
- Random Forest: n_estimators, max_depth, class_weight, etc.
- CNN: epochs, batch_size, learning_rate, dropout, etc.

**Data split:**
- Train/Val/Test ratios
- Random seed (for reproducibility)

**Feature configuration:**
- Number of features (27)
- Feature names and indices

**Output format:**
- GeoTIFF compression, NoData values
- Plot settings (DPI, colormap, figsize)

ƒê·ªÉ thay ƒë·ªïi c·∫•u h√¨nh, ch·ªânh s·ª≠a [`src/config.py`](src/config.py) tr∆∞·ªõc khi ch·∫°y pipeline.

---

## üìö Dependencies ch√≠nh

**Core ML libraries:**
- `torch` 2.5.1+cu121 - Deep learning framework
- `scikit-learn` 1.7.2 - Machine learning (Random Forest)
- `numpy` 2.2.6 - Numerical computing
- `pandas` 2.3.3 - Data manipulation

**Geospatial libraries:**
- `rasterio` 1.4.3 - Read/write GeoTIFF
- `geopandas` 1.1.1 - Geospatial data analysis
- `shapely` 2.1.1 - Geometric operations
- `pyproj` 3.6.1 - Coordinate transformations

**Visualization:**
- `matplotlib` 3.10.7 - Plotting
- `seaborn` 0.13.2 - Statistical visualization
- `folium` 0.20.0 - Interactive maps

**Full dependencies:** Xem [`environment.yml`](environment.yml)

---

## üìù Git commit history

C√°c c·∫≠p nh·∫≠t g·∫ßn ƒë√¢y:
```
7e41fe8 BIG UPDATE!!!
2d53b21 over10ksamples
c39550e th·ª≠ l·∫°i tr∆∞·ªõc khi ƒë·ªïi samples
2c5954c Remove vectorization & add visualization plots
e7d7430 blabla
```

---

## üìß Li√™n h·ªá

- **Sinh vi√™n:** Ninh H·∫£i ƒêƒÉng
- **Email:** ninhhaidangg@gmail.com
- **GitHub:** [ninhhaidang](https://github.com/ninhhaidang)
- **Repository:** [25-26_HKI_DATN_21021411_DangNH](https://github.com/Geospatial-Technology-Lab/25-26_HKI_DATN_21021411_DangNH)
- **ƒê∆°n v·ªã:** Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng ngh·ªá - ƒêHQGHN

---

## üìö T√†i li·ªáu tham kh·∫£o

Lu·∫≠n vƒÉn n√†y tham kh·∫£o **24 t√†i li·ªáu** t·ª´ c√°c ngu·ªìn uy t√≠n v·ªÅ Machine Learning, Deep Learning, v√† Vi·ªÖn th√°m.

**Xem danh s√°ch ƒë·∫ßy ƒë·ªß:** [REFERENCES.md](THESIS/REFERENCES.md)

**Ph√¢n lo·∫°i theo ch·ªß ƒë·ªÅ:**
- T·ªï ch·ª©c qu·ªëc t·∫ø: 3 t√†i li·ªáu
- Machine Learning truy·ªÅn th·ªëng: 4 t√†i li·ªáu
- Deep Learning: 7 t√†i li·ªáu
- Gi√°m s√°t r·ª´ng: 3 t√†i li·ªáu
- SAR-Optical Fusion: 2 t√†i li·ªáu
- Nghi√™n c·ª©u Vi·ªát Nam: 3 t√†i li·ªáu
- So s√°nh ph∆∞∆°ng ph√°p: 2 t√†i li·ªáu

---

## üìÑ License

D·ª± √°n n√†y ƒë∆∞·ª£c ph√°t tri·ªÉn cho m·ª•c ƒë√≠ch nghi√™n c·ª©u v√† h·ªçc thu·∫≠t.

---

**Last updated:** November 2025
