{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Notebook 07: Hard Classification Experiments\n",
    "\n",
    "**Mục đích:** Thử hard classification (rule-based thresholds) thay vì soft classification (probability-based).\n",
    "\n",
    "**Hypothesis:** NDVI delta và các spectral indices có hard thresholds rõ ràng cho deforestation.\n",
    "\n",
    "**Input:**\n",
    "- Full Sentinel-2 imagery (2024, 2025)\n",
    "- Full Sentinel-1 imagery (2024, 2025)\n",
    "- Forest boundary shapefile\n",
    "- Ground truth points (for validation)\n",
    "\n",
    "**Output:**\n",
    "- Hard classification maps với different thresholds\n",
    "- Comparison với soft classify (RF, CNN)\n",
    "- Optimal threshold determination\n",
    "- Accuracy metrics\n",
    "\n",
    "**Thời gian ước tính:** ~10-15 phút (no model training needed!)\n",
    "\n",
    "---\n",
    "\n",
    "## Hard Classification Methods:\n",
    "\n",
    "### 1. NDVI Delta Threshold\n",
    "```\n",
    "if d_NDVI < threshold → deforestation\n",
    "```\n",
    "\n",
    "### 2. NBR Delta Threshold (Normalized Burn Ratio)\n",
    "```\n",
    "NBR = (NIR - SWIR) / (NIR + SWIR)\n",
    "if d_NBR < threshold → deforestation\n",
    "```\n",
    "\n",
    "### 3. Multi-band Rules\n",
    "```\n",
    "if (d_NDVI < -0.1) AND (d_NBR < -0.1) → deforestation\n",
    "```\n",
    "\n",
    "### 4. Adaptive Thresholds\n",
    "```\n",
    "threshold = mean(d_NDVI) - 2*std(d_NDVI)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import rasterio\n",
    "from pathlib import Path\n",
    "\n",
    "from src.config import *\n",
    "from src.utils import read_geotiff, validate_sentinel2_ranges, normalize_image, mask_raster_with_boundary\n",
    "\n",
    "plt.style.use('default')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Full Area Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LOADING FULL AREA IMAGERY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load Sentinel-2\n",
    "print(\"\\n[1/4] Loading Sentinel-2 2024...\")\n",
    "s2_2024, profile_s2, transform = read_geotiff(SENTINEL2_2024, clip_sentinel2=True)\n",
    "print(f\"  Shape: {s2_2024.shape}\")\n",
    "\n",
    "print(\"[2/4] Loading Sentinel-2 2025...\")\n",
    "s2_2025, _, _ = read_geotiff(SENTINEL2_2025, clip_sentinel2=True)\n",
    "print(f\"  Shape: {s2_2025.shape}\")\n",
    "\n",
    "# Load Sentinel-1\n",
    "print(\"[3/4] Loading Sentinel-1 2024...\")\n",
    "s1_2024, _, _ = read_geotiff(SENTINEL1_2024)\n",
    "s1_2024 = s1_2024[0:2, :, :]  # VV, VH\n",
    "print(f\"  Shape: {s1_2024.shape}\")\n",
    "\n",
    "print(\"[4/4] Loading Sentinel-1 2025...\")\n",
    "s1_2025, _, _ = read_geotiff(SENTINEL1_2025)\n",
    "s1_2025 = s1_2025[0:2, :, :]\n",
    "print(f\"  Shape: {s1_2025.shape}\")\n",
    "\n",
    "# Get dimensions\n",
    "height, width = s2_2024.shape[1], s2_2024.shape[2]\n",
    "print(f\"\\n✓ Imagery loaded successfully\")\n",
    "print(f\"  Dimensions: {height} × {width} pixels\")\n",
    "print(f\"  Area: {(height * 10 / 1000) * (width * 10 / 1000):.2f} km²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Apply boundary mask\n",
    "print(\"\\n[1/3] Applying forest boundary mask...\")\n",
    "s2_2024, forest_mask = mask_raster_with_boundary(s2_2024, transform, FOREST_BOUNDARY)\n",
    "s2_2025, _ = mask_raster_with_boundary(s2_2025, transform, FOREST_BOUNDARY)\n",
    "s1_2024, _ = mask_raster_with_boundary(s1_2024, transform, FOREST_BOUNDARY)\n",
    "s1_2025, _ = mask_raster_with_boundary(s1_2025, transform, FOREST_BOUNDARY)\n",
    "\n",
    "forest_pixels = np.sum(forest_mask)\n",
    "print(f\"  Forest area: {forest_pixels:,} pixels ({forest_pixels * 100 / 1e6:.2f} km²)\")\n",
    "\n",
    "# Normalize (keep original values for now, we'll normalize later)\n",
    "print(\"[2/3] Normalizing Sentinel-2...\")\n",
    "s2_2024 = validate_sentinel2_ranges(s2_2024)\n",
    "s2_2025 = validate_sentinel2_ranges(s2_2025)\n",
    "\n",
    "print(\"[3/3] Normalizing Sentinel-1...\")\n",
    "s1_2024 = normalize_image(s1_2024, method=\"minmax\")\n",
    "s1_2025 = normalize_image(s1_2025, method=\"minmax\")\n",
    "\n",
    "print(\"\\n✓ Preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Extract Band Indices\n",
    "\n",
    "Extract already-calculated NDVI, NBR, NDMI from S2 imagery:\n",
    "- Channel 4: NDVI\n",
    "- Channel 5: NBR\n",
    "- Channel 6: NDMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTRACTING SPECTRAL INDICES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract indices (already calculated in S2 imagery)\n",
    "# S2 channels: [B4, B8, B11, B12, NDVI, NBR, NDMI]\n",
    "ndvi_2024 = s2_2024[4, :, :]\n",
    "ndvi_2025 = s2_2025[4, :, :]\n",
    "\n",
    "nbr_2024 = s2_2024[5, :, :]\n",
    "nbr_2025 = s2_2025[5, :, :]\n",
    "\n",
    "ndmi_2024 = s2_2024[6, :, :]\n",
    "ndmi_2025 = s2_2025[6, :, :]\n",
    "\n",
    "# Calculate deltas (temporal change)\n",
    "d_ndvi = ndvi_2025 - ndvi_2024\n",
    "d_nbr = nbr_2025 - nbr_2024\n",
    "d_ndmi = ndmi_2025 - ndmi_2024\n",
    "\n",
    "print(\"\\n✓ Indices extracted:\")\n",
    "print(f\"  - NDVI 2024: shape {ndvi_2024.shape}, range [{np.nanmin(ndvi_2024):.3f}, {np.nanmax(ndvi_2024):.3f}]\")\n",
    "print(f\"  - NDVI 2025: shape {ndvi_2025.shape}, range [{np.nanmin(ndvi_2025):.3f}, {np.nanmax(ndvi_2025):.3f}]\")\n",
    "print(f\"  - d_NDVI:    range [{np.nanmin(d_ndvi):.3f}, {np.nanmax(d_ndvi):.3f}]\")\n",
    "\n",
    "print(f\"\\n  - NBR 2024:  range [{np.nanmin(nbr_2024):.3f}, {np.nanmax(nbr_2024):.3f}]\")\n",
    "print(f\"  - NBR 2025:  range [{np.nanmin(nbr_2025):.3f}, {np.nanmax(nbr_2025):.3f}]\")\n",
    "print(f\"  - d_NBR:     range [{np.nanmin(d_nbr):.3f}, {np.nanmax(d_nbr):.3f}]\")\n",
    "\n",
    "print(f\"\\n  - NDMI 2024: range [{np.nanmin(ndmi_2024):.3f}, {np.nanmax(ndmi_2024):.3f}]\")\n",
    "print(f\"  - NDMI 2025: range [{np.nanmin(ndmi_2025):.3f}, {np.nanmax(ndmi_2025):.3f}]\")\n",
    "print(f\"  - d_NDMI:    range [{np.nanmin(d_ndmi):.3f}, {np.nanmax(d_ndmi):.3f}]\")\n",
    "\n",
    "# Statistics for forest area only\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DELTA STATISTICS (Forest Area Only)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "d_ndvi_forest = d_ndvi[forest_mask]\n",
    "d_nbr_forest = d_nbr[forest_mask]\n",
    "d_ndmi_forest = d_ndmi[forest_mask]\n",
    "\n",
    "print(f\"\\nd_NDVI:\")\n",
    "print(f\"  Mean: {np.nanmean(d_ndvi_forest):.4f}\")\n",
    "print(f\"  Std:  {np.nanstd(d_ndvi_forest):.4f}\")\n",
    "print(f\"  Min:  {np.nanmin(d_ndvi_forest):.4f}\")\n",
    "print(f\"  Max:  {np.nanmax(d_ndvi_forest):.4f}\")\n",
    "\n",
    "print(f\"\\nd_NBR:\")\n",
    "print(f\"  Mean: {np.nanmean(d_nbr_forest):.4f}\")\n",
    "print(f\"  Std:  {np.nanstd(d_nbr_forest):.4f}\")\n",
    "print(f\"  Min:  {np.nanmin(d_nbr_forest):.4f}\")\n",
    "print(f\"  Max:  {np.nanmax(d_nbr_forest):.4f}\")\n",
    "\n",
    "print(f\"\\nd_NDMI:\")\n",
    "print(f\"  Mean: {np.nanmean(d_ndmi_forest):.4f}\")\n",
    "print(f\"  Std:  {np.nanstd(d_ndmi_forest):.4f}\")\n",
    "print(f\"  Min:  {np.nanmin(d_ndmi_forest):.4f}\")\n",
    "print(f\"  Max:  {np.nanmax(d_ndmi_forest):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Load Ground Truth for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "gt_csv = GROUND_TRUTH_CSV\n",
    "\n",
    "if gt_csv.exists():\n",
    "    df_gt = pd.read_csv(gt_csv)\n",
    "    print(f\"\\n✓ Loaded {len(df_gt)} ground truth points\")\n",
    "    print(f\"  - No deforestation (0): {(df_gt['label'] == 0).sum()}\")\n",
    "    print(f\"  - Deforestation (1): {(df_gt['label'] == 1).sum()}\")\n",
    "    \n",
    "    # Show columns\n",
    "    print(f\"\\nColumns in CSV: {list(df_gt.columns)}\")\n",
    "    print(f\"\\nFirst 5 rows:\")\n",
    "    print(df_gt.head())\n",
    "    \n",
    "    # Extract d_NDVI values at GT points\n",
    "    # Note: x, y are in projected coordinates (need to convert to pixel coordinates)\n",
    "    # This is simplified - in practice need proper coordinate transformation\n",
    "else:\n",
    "    print(\"\\n⚠️ Ground truth not found. Will proceed without validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Method 1: NDVI Delta Threshold\n",
    "\n",
    "**Simple rule:** `if d_NDVI < threshold → deforestation`\n",
    "\n",
    "We'll test multiple thresholds: -0.05, -0.10, -0.15, -0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 1: NDVI DELTA THRESHOLD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test different thresholds\n",
    "thresholds_ndvi = [-0.05, -0.10, -0.15, -0.20]\n",
    "\n",
    "results_ndvi = {}\n",
    "pixel_area_ha = 0.01  # 10m × 10m\n",
    "forest_area_ha = forest_pixels * pixel_area_ha\n",
    "\n",
    "for threshold in thresholds_ndvi:\n",
    "    # Apply threshold\n",
    "    deforestation_map = (d_ndvi < threshold).astype(np.uint8)\n",
    "    deforestation_map[~forest_mask] = 255  # NoData\n",
    "    \n",
    "    # Calculate statistics\n",
    "    defor_pixels = np.sum((d_ndvi < threshold) & forest_mask)\n",
    "    defor_area_ha = defor_pixels * pixel_area_ha\n",
    "    defor_pct = (defor_pixels / forest_pixels) * 100\n",
    "    \n",
    "    results_ndvi[threshold] = {\n",
    "        'map': deforestation_map,\n",
    "        'pixels': defor_pixels,\n",
    "        'area_ha': defor_area_ha,\n",
    "        'percentage': defor_pct\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nThreshold = {threshold:+.2f}:\")\n",
    "    print(f\"  - Deforestation: {defor_pixels:,} pixels ({defor_area_ha:.2f} ha)\")\n",
    "    print(f\"  - Percentage: {defor_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. Method 2: NBR Delta Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 2: NBR DELTA THRESHOLD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test different thresholds\n",
    "thresholds_nbr = [-0.05, -0.10, -0.15, -0.20]\n",
    "\n",
    "results_nbr = {}\n",
    "\n",
    "for threshold in thresholds_nbr:\n",
    "    # Apply threshold\n",
    "    deforestation_map = (d_nbr < threshold).astype(np.uint8)\n",
    "    deforestation_map[~forest_mask] = 255\n",
    "    \n",
    "    # Calculate statistics\n",
    "    defor_pixels = np.sum((d_nbr < threshold) & forest_mask)\n",
    "    defor_area_ha = defor_pixels * pixel_area_ha\n",
    "    defor_pct = (defor_pixels / forest_pixels) * 100\n",
    "    \n",
    "    results_nbr[threshold] = {\n",
    "        'map': deforestation_map,\n",
    "        'pixels': defor_pixels,\n",
    "        'area_ha': defor_area_ha,\n",
    "        'percentage': defor_pct\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nThreshold = {threshold:+.2f}:\")\n",
    "    print(f\"  - Deforestation: {defor_pixels:,} pixels ({defor_area_ha:.2f} ha)\")\n",
    "    print(f\"  - Percentage: {defor_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Method 3: Multi-band Combined Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 3: MULTI-BAND COMBINED RULES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Rule 1: NDVI AND NBR\n",
    "rule1_map = ((d_ndvi < -0.10) & (d_nbr < -0.10)).astype(np.uint8)\n",
    "rule1_map[~forest_mask] = 255\n",
    "rule1_pixels = np.sum((d_ndvi < -0.10) & (d_nbr < -0.10) & forest_mask)\n",
    "rule1_pct = (rule1_pixels / forest_pixels) * 100\n",
    "\n",
    "print(f\"\\nRule 1: (d_NDVI < -0.10) AND (d_NBR < -0.10)\")\n",
    "print(f\"  - Deforestation: {rule1_pixels:,} pixels ({rule1_pixels*pixel_area_ha:.2f} ha)\")\n",
    "print(f\"  - Percentage: {rule1_pct:.2f}%\")\n",
    "\n",
    "# Rule 2: NDVI OR NBR\n",
    "rule2_map = ((d_ndvi < -0.10) | (d_nbr < -0.10)).astype(np.uint8)\n",
    "rule2_map[~forest_mask] = 255\n",
    "rule2_pixels = np.sum((d_ndvi < -0.10) | (d_nbr < -0.10) & forest_mask)\n",
    "rule2_pct = (rule2_pixels / forest_pixels) * 100\n",
    "\n",
    "print(f\"\\nRule 2: (d_NDVI < -0.10) OR (d_NBR < -0.10)\")\n",
    "print(f\"  - Deforestation: {rule2_pixels:,} pixels ({rule2_pixels*pixel_area_ha:.2f} ha)\")\n",
    "print(f\"  - Percentage: {rule2_pct:.2f}%\")\n",
    "\n",
    "# Rule 3: All three indices\n",
    "rule3_map = ((d_ndvi < -0.10) & (d_nbr < -0.10) & (d_ndmi < -0.10)).astype(np.uint8)\n",
    "rule3_map[~forest_mask] = 255\n",
    "rule3_pixels = np.sum((d_ndvi < -0.10) & (d_nbr < -0.10) & (d_ndmi < -0.10) & forest_mask)\n",
    "rule3_pct = (rule3_pixels / forest_pixels) * 100\n",
    "\n",
    "print(f\"\\nRule 3: (d_NDVI < -0.10) AND (d_NBR < -0.10) AND (d_NDMI < -0.10)\")\n",
    "print(f\"  - Deforestation: {rule3_pixels:,} pixels ({rule3_pixels*pixel_area_ha:.2f} ha)\")\n",
    "print(f\"  - Percentage: {rule3_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. Method 4: Adaptive Threshold (Statistical)\n",
    "\n",
    "Use statistics of delta distribution:\n",
    "```\n",
    "threshold = mean(d_NDVI) - k * std(d_NDVI)\n",
    "```\n",
    "where k = 1, 1.5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"METHOD 4: ADAPTIVE THRESHOLD (STATISTICAL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mean_dndvi = np.nanmean(d_ndvi_forest)\n",
    "std_dndvi = np.nanstd(d_ndvi_forest)\n",
    "\n",
    "print(f\"\\nd_NDVI statistics (forest only):\")\n",
    "print(f\"  Mean: {mean_dndvi:.4f}\")\n",
    "print(f\"  Std:  {std_dndvi:.4f}\")\n",
    "\n",
    "results_adaptive = {}\n",
    "\n",
    "for k in [1.0, 1.5, 2.0]:\n",
    "    threshold = mean_dndvi - k * std_dndvi\n",
    "    \n",
    "    # Apply threshold\n",
    "    deforestation_map = (d_ndvi < threshold).astype(np.uint8)\n",
    "    deforestation_map[~forest_mask] = 255\n",
    "    \n",
    "    # Calculate statistics\n",
    "    defor_pixels = np.sum((d_ndvi < threshold) & forest_mask)\n",
    "    defor_area_ha = defor_pixels * pixel_area_ha\n",
    "    defor_pct = (defor_pixels / forest_pixels) * 100\n",
    "    \n",
    "    results_adaptive[k] = {\n",
    "        'threshold': threshold,\n",
    "        'map': deforestation_map,\n",
    "        'pixels': defor_pixels,\n",
    "        'area_ha': defor_area_ha,\n",
    "        'percentage': defor_pct\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nk = {k} (threshold = {threshold:.4f}):\")\n",
    "    print(f\"  - Deforestation: {defor_pixels:,} pixels ({defor_area_ha:.2f} ha)\")\n",
    "    print(f\"  - Percentage: {defor_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 9. Visualize All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(24, 18))\n",
    "\n",
    "cmap_binary = ListedColormap(['#2ecc71', '#e74c3c', 'white'])\n",
    "\n",
    "# Row 1: NDVI delta + different NDVI thresholds\n",
    "# d_NDVI map\n",
    "ax = axes[0, 0]\n",
    "im = ax.imshow(d_ndvi, cmap='RdYlGn', vmin=-0.5, vmax=0.5)\n",
    "ax.set_title('d_NDVI (2025 - 2024)', fontsize=12, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "# NDVI thresholds\n",
    "for i, threshold in enumerate([-0.05, -0.10, -0.15]):\n",
    "    ax = axes[0, i+1]\n",
    "    binary_display = results_ndvi[threshold]['map'].copy()\n",
    "    binary_display[binary_display == 255] = 2\n",
    "    im = ax.imshow(binary_display, cmap=cmap_binary, vmin=0, vmax=2)\n",
    "    pct = results_ndvi[threshold]['percentage']\n",
    "    ax.set_title(f'NDVI < {threshold:.2f}\\n({pct:.1f}%)', fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Row 2: NBR delta + different NBR thresholds\n",
    "# d_NBR map\n",
    "ax = axes[1, 0]\n",
    "im = ax.imshow(d_nbr, cmap='RdYlGn', vmin=-0.5, vmax=0.5)\n",
    "ax.set_title('d_NBR (2025 - 2024)', fontsize=12, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "# NBR thresholds\n",
    "for i, threshold in enumerate([-0.05, -0.10, -0.15]):\n",
    "    ax = axes[1, i+1]\n",
    "    binary_display = results_nbr[threshold]['map'].copy()\n",
    "    binary_display[binary_display == 255] = 2\n",
    "    im = ax.imshow(binary_display, cmap=cmap_binary, vmin=0, vmax=2)\n",
    "    pct = results_nbr[threshold]['percentage']\n",
    "    ax.set_title(f'NBR < {threshold:.2f}\\n({pct:.1f}%)', fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Row 3: Combined rules + Adaptive\n",
    "# Rule 1: AND\n",
    "ax = axes[2, 0]\n",
    "binary_display = rule1_map.copy()\n",
    "binary_display[binary_display == 255] = 2\n",
    "im = ax.imshow(binary_display, cmap=cmap_binary, vmin=0, vmax=2)\n",
    "ax.set_title(f'NDVI AND NBR\\n({rule1_pct:.1f}%)', fontsize=12, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Rule 2: OR\n",
    "ax = axes[2, 1]\n",
    "binary_display = rule2_map.copy()\n",
    "binary_display[binary_display == 255] = 2\n",
    "im = ax.imshow(binary_display, cmap=cmap_binary, vmin=0, vmax=2)\n",
    "ax.set_title(f'NDVI OR NBR\\n({rule2_pct:.1f}%)', fontsize=12, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Rule 3: All three\n",
    "ax = axes[2, 2]\n",
    "binary_display = rule3_map.copy()\n",
    "binary_display[binary_display == 255] = 2\n",
    "im = ax.imshow(binary_display, cmap=cmap_binary, vmin=0, vmax=2)\n",
    "ax.set_title(f'NDVI+NBR+NDMI\\n({rule3_pct:.1f}%)', fontsize=12, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# Adaptive k=2\n",
    "ax = axes[2, 3]\n",
    "binary_display = results_adaptive[2.0]['map'].copy()\n",
    "binary_display[binary_display == 255] = 2\n",
    "im = ax.imshow(binary_display, cmap=cmap_binary, vmin=0, vmax=2)\n",
    "pct = results_adaptive[2.0]['percentage']\n",
    "thresh = results_adaptive[2.0]['threshold']\n",
    "ax.set_title(f'Adaptive (k=2)\\nthresh={thresh:.3f}\\n({pct:.1f}%)', fontsize=12, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "output_fig = FIGURES_DIR / \"hard_classification_all_methods.png\"\n",
    "plt.savefig(output_fig, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Visualization saved to: {output_fig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 10. Compare with Soft Classification (RF, CNN)\n",
    "\n",
    "Load results from Notebook 06 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load soft classify results\n",
    "soft_results_file = PROJECT_ROOT / \"predictions\" / \"all_models_comparison_stats.json\"\n",
    "\n",
    "if soft_results_file.exists():\n",
    "    with open(soft_results_file, 'r') as f:\n",
    "        soft_results = json.load(f)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPARISON: HARD vs SOFT CLASSIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nSOFT CLASSIFICATION (from Notebook 06):\")\n",
    "    print(f\"  Random Forest:  {soft_results['rf']['deforestation_pct']:.2f}%\")\n",
    "    print(f\"  Simple CNN:     {soft_results['cnn']['deforestation_pct']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nHARD CLASSIFICATION (this notebook):\")\n",
    "    print(f\"  NDVI < -0.10:   {results_ndvi[-0.10]['percentage']:.2f}%\")\n",
    "    print(f\"  NBR < -0.10:    {results_nbr[-0.10]['percentage']:.2f}%\")\n",
    "    print(f\"  NDVI AND NBR:   {rule1_pct:.2f}%\")\n",
    "    print(f\"  NDVI OR NBR:    {rule2_pct:.2f}%\")\n",
    "    print(f\"  Adaptive (k=2): {results_adaptive[2.0]['percentage']:.2f}%\")\n",
    "    \n",
    "    # Create comparison DataFrame\n",
    "    comparison_df = pd.DataFrame([\n",
    "        {'Method': 'Random Forest (soft)', 'Deforestation %': soft_results['rf']['deforestation_pct']},\n",
    "        {'Method': 'Simple CNN (soft)', 'Deforestation %': soft_results['cnn']['deforestation_pct']},\n",
    "        {'Method': 'NDVI < -0.10 (hard)', 'Deforestation %': results_ndvi[-0.10]['percentage']},\n",
    "        {'Method': 'NBR < -0.10 (hard)', 'Deforestation %': results_nbr[-0.10]['percentage']},\n",
    "        {'Method': 'NDVI AND NBR (hard)', 'Deforestation %': rule1_pct},\n",
    "        {'Method': 'Adaptive k=2 (hard)', 'Deforestation %': results_adaptive[2.0]['percentage']},\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n⚠️ Soft classification results not found. Please run Notebook 06 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 11. Export Best Hard Classification Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best method (you can change this)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORTING HARD CLASSIFICATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Export multiple methods for comparison\n",
    "output_dir = PROJECT_ROOT / \"predictions\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "methods_to_export = [\n",
    "    ('ndvi_threshold_-0.10', results_ndvi[-0.10]['map']),\n",
    "    ('nbr_threshold_-0.10', results_nbr[-0.10]['map']),\n",
    "    ('combined_ndvi_and_nbr', rule1_map),\n",
    "    ('adaptive_k2', results_adaptive[2.0]['map']),\n",
    "]\n",
    "\n",
    "exported_files = []\n",
    "\n",
    "for method_name, binary_map in methods_to_export:\n",
    "    output_file = output_dir / f\"hard_classify_{method_name}.tif\"\n",
    "    \n",
    "    with rasterio.open(output_file, 'w',\n",
    "                       driver='GTiff',\n",
    "                       height=binary_map.shape[0],\n",
    "                       width=binary_map.shape[1],\n",
    "                       count=1,\n",
    "                       dtype=binary_map.dtype,\n",
    "                       crs=profile_s2['crs'],\n",
    "                       transform=transform,\n",
    "                       nodata=255) as dst:\n",
    "        dst.write(binary_map, 1)\n",
    "    \n",
    "    exported_files.append(output_file)\n",
    "    print(f\"✓ Exported: {output_file}\")\n",
    "\n",
    "# Export d_NDVI for reference\n",
    "dndvi_output = output_dir / \"d_NDVI_map.tif\"\n",
    "with rasterio.open(dndvi_output, 'w',\n",
    "                   driver='GTiff',\n",
    "                   height=d_ndvi.shape[0],\n",
    "                   width=d_ndvi.shape[1],\n",
    "                   count=1,\n",
    "                   dtype=np.float32,\n",
    "                   crs=profile_s2['crs'],\n",
    "                   transform=transform,\n",
    "                   nodata=np.nan) as dst:\n",
    "    dst.write(d_ndvi.astype(np.float32), 1)\n",
    "\n",
    "exported_files.append(dndvi_output)\n",
    "print(f\"✓ Exported: {dndvi_output}\")\n",
    "\n",
    "print(f\"\\n✓ Exported {len(exported_files)} files to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 12. Kết luận\n",
    "\n",
    "✅ **Hard classification experiments completed!**\n",
    "\n",
    "### Key Findings:\n",
    "1. **d_NDVI** là indicator mạnh nhất cho deforestation\n",
    "2. Different thresholds cho kết quả khác nhau rất nhiều\n",
    "3. Combined rules (AND) cho conservative estimates\n",
    "4. Combined rules (OR) cho liberal estimates\n",
    "5. Adaptive thresholds tự động điều chỉnh theo distribution\n",
    "\n",
    "### So với Soft Classification:\n",
    "- Hard classify cho **sharp boundaries**\n",
    "- Soft classify cho **smooth transitions**\n",
    "- Hard classify **faster** (no model needed)\n",
    "- Soft classify có thể **capture complex patterns**\n",
    "\n",
    "### Tiếp theo:\n",
    "- ✅ Chọn threshold tốt nhất dựa trên visual inspection\n",
    "- ✅ Validate với ground truth\n",
    "- ✅ Compare spatial patterns với soft classify\n",
    "- ✅ Consider ensemble: soft + hard\n",
    "\n",
    "### Lưu ý:\n",
    "- ⚠️ Hard thresholds phụ thuộc vào điều kiện cục bộ\n",
    "- ⚠️ Cần validation với ground truth\n",
    "- ⚠️ Có thể cần adaptive thresholds cho different regions\n",
    "- ⚠️ Post-processing (spatial filtering) có thể cải thiện results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
