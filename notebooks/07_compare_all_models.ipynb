{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Compare All Models (3 CNNs + Random Forest)\n",
    "\n",
    "This notebook compares deforestation detection results from all 4 models:\n",
    "\n",
    "**CNN Models:**\n",
    "1. Spatial Context CNN\n",
    "2. Multi-Scale CNN\n",
    "3. Shallow U-Net\n",
    "\n",
    "**Traditional ML:**\n",
    "4. Random Forest\n",
    "\n",
    "**Workflow:**\n",
    "1. Run inference for all 3 CNN models separately\n",
    "2. Load results from Random Forest (from notebook 06)\n",
    "3. Compare probability maps side-by-side\n",
    "4. Compare binary classification maps\n",
    "5. Analyze statistics and model agreement\n",
    "\n",
    "**Expected outputs:**\n",
    "- Side-by-side probability maps (2×2 grid)\n",
    "- Side-by-side binary maps (2×2 grid)\n",
    "- Statistics comparison (bar charts)\n",
    "- CNN models agreement analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root and src to Python path\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source dir: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Inference for All CNN Models\n",
    "\n",
    "This will generate separate probability and binary maps for each of the 3 CNN models.\n",
    "\n",
    "**Expected time:** ~4-6 minutes total on GPU (1.5-2 min per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RUNNING INFERENCE FOR ALL 3 CNN MODELS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Run inference script\n",
    "inference_script = project_root / 'inference_all_models.py'\n",
    "\n",
    "if not inference_script.exists():\n",
    "    print(f\"Error: {inference_script} not found!\")\n",
    "else:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, str(inference_script)],\n",
    "        capture_output=False,\n",
    "        text=True,\n",
    "        cwd=project_root\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"INFERENCE COMPLETED SUCCESSFULLY\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ERROR: Inference failed\")\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check Available Models\n",
    "\n",
    "Verify which model outputs are available for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_dir = project_root / 'outputs'\n",
    "\n",
    "# Model configurations\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Spatial CNN',\n",
    "        'prob_file': 'spatial_cnn_probability_map.tif',\n",
    "        'binary_file': 'spatial_cnn_binary_map.tif',\n",
    "        'color': 'steelblue'\n",
    "    },\n",
    "    {\n",
    "        'name': 'MultiScale CNN',\n",
    "        'prob_file': 'multiscale_cnn_probability_map.tif',\n",
    "        'binary_file': 'multiscale_cnn_binary_map.tif',\n",
    "        'color': 'coral'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Shallow U-Net',\n",
    "        'prob_file': 'shallow_unet_probability_map.tif',\n",
    "        'binary_file': 'shallow_unet_binary_map.tif',\n",
    "        'color': 'mediumseagreen'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'prob_file': 'random_forest_probability_map.tif',\n",
    "        'binary_file': 'random_forest_binary_map.tif',\n",
    "        'color': 'mediumpurple'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Checking available models...\\n\")\n",
    "available_models = []\n",
    "\n",
    "for model in models:\n",
    "    prob_path = outputs_dir / model['prob_file']\n",
    "    binary_path = outputs_dir / model['binary_file']\n",
    "    \n",
    "    if prob_path.exists() and binary_path.exists():\n",
    "        available_models.append(model)\n",
    "        print(f\"✓ {model['name']}: Available\")\n",
    "    else:\n",
    "        print(f\"✗ {model['name']}: Missing\")\n",
    "\n",
    "print(f\"\\nTotal available: {len(available_models)}/{len(models)} models\")\n",
    "\n",
    "if len(available_models) == 0:\n",
    "    print(\"\\nError: No model outputs found!\")\n",
    "    print(\"Please run inference first:\")\n",
    "    print(\"  - For CNN models: Run cell above or python inference_all_models.py\")\n",
    "    print(\"  - For Random Forest: Run notebook 06_train_random_forest.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load All Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_map(filepath):\n",
    "    \"\"\"Load GeoTIFF map\"\"\"\n",
    "    with rasterio.open(filepath) as src:\n",
    "        return src.read(1)\n",
    "\n",
    "# Load all maps\n",
    "print(\"Loading maps...\\n\")\n",
    "prob_maps = {}\n",
    "binary_maps = {}\n",
    "\n",
    "for model in available_models:\n",
    "    prob_path = outputs_dir / model['prob_file']\n",
    "    binary_path = outputs_dir / model['binary_file']\n",
    "    \n",
    "    prob_maps[model['name']] = load_map(prob_path)\n",
    "    binary_maps[model['name']] = load_map(binary_path)\n",
    "    print(f\"  Loaded: {model['name']}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(prob_maps)} models successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Side-by-Side Probability Maps Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 grid for probability maps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if model['name'] in prob_maps:\n",
    "        im = axes[i].imshow(prob_maps[model['name']], cmap='RdYlGn_r', vmin=0, vmax=1)\n",
    "        axes[i].set_title(f\"{model['name']}\\nProbability Map\", \n",
    "                         fontsize=14, fontweight='bold')\n",
    "        axes[i].set_xlabel('X (pixels)', fontsize=11)\n",
    "        axes[i].set_ylabel('Y (pixels)', fontsize=11)\n",
    "        plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "        axes[i].text(0.5, 0.5, f\"{model['name']}\\nNot Available\",\n",
    "                    ha='center', va='center', fontsize=14, \n",
    "                    transform=axes[i].transAxes)\n",
    "\n",
    "plt.suptitle('Deforestation Probability Maps - All Models Comparison',\n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "figures_dir = project_root / 'figures'\n",
    "figures_dir.mkdir(exist_ok=True)\n",
    "plt.savefig(figures_dir / 'all_models_probability_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {figures_dir / 'all_models_probability_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Side-by-Side Binary Maps Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2x2 grid for binary maps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Custom colormap\n",
    "colors = ['#2ecc71', '#e74c3c']  # Green, Red\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    if model['name'] in binary_maps:\n",
    "        im = axes[i].imshow(binary_maps[model['name']], cmap=cmap, vmin=0, vmax=1)\n",
    "        axes[i].set_title(f\"{model['name']}\\nBinary Classification\", \n",
    "                         fontsize=14, fontweight='bold')\n",
    "        axes[i].set_xlabel('X (pixels)', fontsize=11)\n",
    "        axes[i].set_ylabel('Y (pixels)', fontsize=11)\n",
    "        cbar = plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04, \n",
    "                           ticks=[0.25, 0.75])\n",
    "        cbar.ax.set_yticklabels(['No Deforestation', 'Deforestation'], fontsize=10)\n",
    "    else:\n",
    "        axes[i].axis('off')\n",
    "        axes[i].text(0.5, 0.5, f\"{model['name']}\\nNot Available\",\n",
    "                    ha='center', va='center', fontsize=14, \n",
    "                    transform=axes[i].transAxes)\n",
    "\n",
    "plt.suptitle('Binary Deforestation Maps - All Models Comparison',\n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'all_models_binary_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {figures_dir / 'all_models_binary_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each model\n",
    "pixel_area_m2 = 10.0 * 10.0\n",
    "\n",
    "stats_data = []\n",
    "for model in models:\n",
    "    if model['name'] in binary_maps:\n",
    "        binary_map = binary_maps[model['name']]\n",
    "        prob_map = prob_maps[model['name']]\n",
    "        \n",
    "        total_pixels = binary_map.size\n",
    "        defor_pixels = binary_map.sum()\n",
    "        defor_percentage = (defor_pixels / total_pixels) * 100\n",
    "        defor_area_km2 = defor_pixels * pixel_area_m2 / 1e6\n",
    "        \n",
    "        stats_data.append({\n",
    "            'Model': model['name'],\n",
    "            'Deforestation (%)': defor_percentage,\n",
    "            'Area (km²)': defor_area_km2,\n",
    "            'Mean Probability': prob_map.mean(),\n",
    "            'Color': model['color']\n",
    "        })\n",
    "\n",
    "# Display statistics table\n",
    "print(\"=\"*80)\n",
    "print(\"DEFORESTATION STATISTICS - ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "for data in stats_data:\n",
    "    print(f\"{data['Model']}:\")\n",
    "    print(f\"  Deforestation: {data['Deforestation (%)']:.2f}%\")\n",
    "    print(f\"  Area: {data['Area (km²)']:.2f} km²\")\n",
    "    print(f\"  Mean Probability: {data['Mean Probability']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "model_names = [s['Model'] for s in stats_data]\n",
    "colors_list = [s['Color'] for s in stats_data]\n",
    "\n",
    "# 1. Deforestation percentage\n",
    "defor_pcts = [s['Deforestation (%)'] for s in stats_data]\n",
    "axes[0].bar(range(len(model_names)), defor_pcts, color=colors_list, \n",
    "           edgecolor='black', alpha=0.8)\n",
    "axes[0].set_xticks(range(len(model_names)))\n",
    "axes[0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Deforestation (%)', fontsize=12)\n",
    "axes[0].set_title('Deforestation Percentage', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(defor_pcts):\n",
    "    axes[0].text(i, v + 0.5, f'{v:.2f}%', ha='center', \n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Deforestation area\n",
    "defor_areas = [s['Area (km²)'] for s in stats_data]\n",
    "axes[1].bar(range(len(model_names)), defor_areas, color=colors_list, \n",
    "           edgecolor='black', alpha=0.8)\n",
    "axes[1].set_xticks(range(len(model_names)))\n",
    "axes[1].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Area (km²)', fontsize=12)\n",
    "axes[1].set_title('Deforestation Area', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(defor_areas):\n",
    "    axes[1].text(i, v + 20, f'{v:.1f}', ha='center', \n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "# 3. Mean probability\n",
    "mean_probs = [s['Mean Probability'] for s in stats_data]\n",
    "axes[2].bar(range(len(model_names)), mean_probs, color=colors_list, \n",
    "           edgecolor='black', alpha=0.8)\n",
    "axes[2].set_xticks(range(len(model_names)))\n",
    "axes[2].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "axes[2].set_ylabel('Mean Probability', fontsize=12)\n",
    "axes[2].set_title('Average Deforestation Probability', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(mean_probs):\n",
    "    axes[2].text(i, v + 0.01, f'{v:.3f}', ha='center', \n",
    "                fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Deforestation Statistics - All Models Comparison',\n",
    "             fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir / 'all_models_statistics_comparison.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: {figures_dir / 'all_models_statistics_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CNN Models Agreement Analysis\n",
    "\n",
    "This section analyzes where the 3 CNN models agree on deforestation detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get CNN models only\n",
    "cnn_models = ['Spatial CNN', 'MultiScale CNN', 'Shallow U-Net']\n",
    "cnn_binary_maps = [binary_maps[name] for name in cnn_models if name in binary_maps]\n",
    "\n",
    "if len(cnn_binary_maps) >= 2:\n",
    "    # Stack binary maps\n",
    "    stacked = np.stack(cnn_binary_maps, axis=0)\n",
    "    agreement = stacked.sum(axis=0)  # 0 to N models agree\n",
    "    \n",
    "    # Create agreement visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, 12))\n",
    "    cmap_agreement = plt.cm.get_cmap('RdYlGn_r', len(cnn_binary_maps) + 1)\n",
    "    im = ax.imshow(agreement, cmap=cmap_agreement, vmin=0, vmax=len(cnn_binary_maps))\n",
    "    ax.set_title('CNN Models Agreement on Deforestation Detection',\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('X (pixels)', fontsize=12)\n",
    "    ax.set_ylabel('Y (pixels)', fontsize=12)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04,\n",
    "                       ticks=range(len(cnn_binary_maps) + 1))\n",
    "    cbar.set_label('Number of Models Predicting Deforestation',\n",
    "                  fontsize=12, rotation=270, labelpad=25)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'cnn_models_agreement.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {figures_dir / 'cnn_models_agreement.png'}\")\n",
    "    \n",
    "    # Agreement statistics\n",
    "    agreement_counts = np.bincount(agreement.flatten(), \n",
    "                                   minlength=len(cnn_binary_maps) + 1)\n",
    "    agreement_pcts = agreement_counts / agreement.size * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CNN MODELS AGREEMENT:\")\n",
    "    print(\"=\"*80)\n",
    "    for i, (count, pct) in enumerate(zip(agreement_counts, agreement_pcts)):\n",
    "        print(f\"  {i} models agree: {count:,} pixels ({pct:.2f}%)\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Not enough CNN models for agreement analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Differences Heatmap\n",
    "\n",
    "Visualize the differences between model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise differences between models\n",
    "if len(prob_maps) >= 2:\n",
    "    model_names_list = list(prob_maps.keys())\n",
    "    n_models = len(model_names_list)\n",
    "    \n",
    "    # Calculate mean absolute differences\n",
    "    diff_matrix = np.zeros((n_models, n_models))\n",
    "    \n",
    "    for i, name1 in enumerate(model_names_list):\n",
    "        for j, name2 in enumerate(model_names_list):\n",
    "            if i != j:\n",
    "                diff = np.abs(prob_maps[name1] - prob_maps[name2]).mean()\n",
    "                diff_matrix[i, j] = diff\n",
    "    \n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(diff_matrix, cmap='YlOrRd', vmin=0)\n",
    "    \n",
    "    # Set ticks\n",
    "    ax.set_xticks(range(n_models))\n",
    "    ax.set_yticks(range(n_models))\n",
    "    ax.set_xticklabels(model_names_list, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(model_names_list)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(n_models):\n",
    "        for j in range(n_models):\n",
    "            text = ax.text(j, i, f'{diff_matrix[i, j]:.4f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", \n",
    "                          fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_title('Mean Absolute Difference Between Model Predictions',\n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Mean Absolute Difference', fontsize=11, rotation=270, labelpad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / 'models_difference_heatmap.png', \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {figures_dir / 'models_difference_heatmap.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary report\n",
    "summary_path = outputs_dir / 'all_models_comparison_summary.txt'\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"ALL MODELS COMPARISON SUMMARY\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"DEFORESTATION STATISTICS:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    for data in stats_data:\n",
    "        f.write(f\"\\n{data['Model']}:\\n\")\n",
    "        f.write(f\"  Deforestation: {data['Deforestation (%)']:.2f}%\\n\")\n",
    "        f.write(f\"  Area: {data['Area (km²)']:.2f} km²\\n\")\n",
    "        f.write(f\"  Mean Probability: {data['Mean Probability']:.4f}\\n\")\n",
    "    \n",
    "    if len(cnn_binary_maps) >= 2:\n",
    "        f.write(\"\\n\\nCNN MODELS AGREEMENT:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        for i, (count, pct) in enumerate(zip(agreement_counts, agreement_pcts)):\n",
    "            f.write(f\"  {i} models agree: {count:,} pixels ({pct:.2f}%)\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\nGENERATED FIGURES:\\n\")\n",
    "    f.write(\"-\"*80 + \"\\n\")\n",
    "    f.write(\"  - all_models_probability_comparison.png\\n\")\n",
    "    f.write(\"  - all_models_binary_comparison.png\\n\")\n",
    "    f.write(\"  - all_models_statistics_comparison.png\\n\")\n",
    "    f.write(\"  - cnn_models_agreement.png\\n\")\n",
    "    f.write(\"  - models_difference_heatmap.png\\n\")\n",
    "\n",
    "print(f\"Summary saved to: {summary_path}\")\n",
    "\n",
    "# Display summary\n",
    "with open(summary_path, 'r', encoding='utf-8') as f:\n",
    "    print(\"\\n\" + f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "This notebook has generated comprehensive comparisons between all 4 deforestation detection models:\n",
    "\n",
    "**Visualizations created:**\n",
    "1. Side-by-side probability maps (2×2 grid)\n",
    "2. Side-by-side binary classification maps (2×2 grid)\n",
    "3. Statistics comparison (bar charts)\n",
    "4. CNN models agreement analysis\n",
    "5. Model differences heatmap\n",
    "\n",
    "**Key insights:**\n",
    "- Compare deforestation estimates across different model architectures\n",
    "- Identify areas of high agreement (high confidence predictions)\n",
    "- Identify areas of disagreement (uncertain predictions)\n",
    "- Evaluate trade-offs between CNN models and traditional ML (Random Forest)\n",
    "\n",
    "All figures have been saved to `figures/` directory for inclusion in your thesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
