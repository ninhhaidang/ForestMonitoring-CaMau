{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Visualize Full Deforestation Maps - All 3 CNN Models\n",
    "\n",
    "This notebook runs inference for **all 3 CNN models** and visualizes comparison:\n",
    "\n",
    "**Models:**\n",
    "1. Spatial Context CNN\n",
    "2. Multi-Scale CNN\n",
    "3. Shallow U-Net\n",
    "\n",
    "**Outputs:**\n",
    "- Probability maps for each model\n",
    "- Binary classification maps for each model\n",
    "- Side-by-side comparison (3 models)\n",
    "- Statistics comparison\n",
    "- Regional analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: d:\\HaiDang\\25-26_HKI_DATN_21021411_DangNH\n",
      "Source dir: d:\\HaiDang\\25-26_HKI_DATN_21021411_DangNH\\src\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root and src to Python path\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source dir: {src_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Full-Image Inference for All 3 CNN Models\n",
    "\n",
    "This section runs inference on the full study area for **all 3 CNN models**:\n",
    "- Spatial Context CNN\n",
    "- Multi-Scale CNN\n",
    "- Shallow U-Net\n",
    "\n",
    "**Expected time:** ~4-6 minutes total on GPU (~1.5-2 min per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from models import get_model\n",
    "from preprocessing import normalize_band, handle_nan\n",
    "\n",
    "print(\"Inference libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA RTX A4000\n",
      "GPU Memory: 17.17 GB\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load Full Image Stack (14 channels - S2 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TIFF files (S2 only - 14 channels)...\n",
      "Loaded: (10917, 12547, 14) (float32)\n",
      "Channels: 14 (S2 only)\n",
      "Transform: | 10.00, 0.00, 465450.00|\n",
      "| 0.00,-10.00, 1055820.00|\n",
      "| 0.00, 0.00, 1.00|\n",
      "CRS: EPSG:32648\n"
     ]
    }
   ],
   "source": [
    "# Paths to TIFF files\n",
    "s2_2024_path = project_root / 'data' / 'raw' / 'sentinel2' / 'S2_2024_01_30.tif'\n",
    "s2_2025_path = project_root / 'data' / 'raw' / 'sentinel2' / 'S2_2025_02_28.tif'\n",
    "\n",
    "print(\"Loading TIFF files (S2 only - 14 channels)...\")\n",
    "\n",
    "# Load S2 2024\n",
    "with rasterio.open(s2_2024_path) as src:\n",
    "    s2_2024 = src.read()  # (7, H, W)\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "    height, width = src.height, src.width\n",
    "\n",
    "# Load S2 2025\n",
    "with rasterio.open(s2_2025_path) as src:\n",
    "    s2_2025 = src.read()  # (7, H, W)\n",
    "\n",
    "# Stack only Sentinel-2: (14, H, W) = 7 S2 (2024) + 7 S2 (2025)\n",
    "all_bands = np.concatenate([s2_2024, s2_2025], axis=0)\n",
    "\n",
    "# Transpose to (H, W, 14)\n",
    "all_bands = np.transpose(all_bands, (1, 2, 0))\n",
    "\n",
    "print(f\"Loaded: {all_bands.shape} ({all_bands.dtype})\")\n",
    "print(f\"Channels: 14 (S2 only)\")\n",
    "print(f\"Transform: {transform}\")\n",
    "print(f\"CRS: {crs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Normalize Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing bands...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745990d8ffa44f6caac31e7aca218222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalize:   0%|          | 0/14 [00:00<?, ?band/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalizing bands...\")\n",
    "for c in tqdm(range(14), desc=\"Normalize\", unit=\"band\"):\n",
    "    # Handle NaN\n",
    "    if np.isnan(all_bands[:, :, c]).any():\n",
    "        all_bands[:, :, c] = handle_nan(all_bands[:, :, c], method='fill')\n",
    "\n",
    "    # Normalize (same as training)\n",
    "    # 14 channels: 0-6=S2_2024, 7-13=S2_2025\n",
    "    # 0-3,7-10: reflectance (B,G,R,NIR)\n",
    "    # 4-6,11-13: indices (NDVI,NBR,NDMI)\n",
    "    if c in [0, 1, 2, 3, 7, 8, 9, 10]:  # S2 reflectance\n",
    "        all_bands[:, :, c] = normalize_band(all_bands[:, :, c], method='clip', clip_range=(0, 1))\n",
    "    else:  # S2 indices (4,5,6,11,12,13)\n",
    "        # Scale from [-1, 1] to [0, 1]\n",
    "        all_bands[:, :, c] = (all_bands[:, :, c] + 1) / 2\n",
    "\n",
    "print(\"Normalization complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Load All 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "models_config = [\n",
    "    {\n",
    "        'name': 'spatial_cnn',\n",
    "        'display_name': 'Spatial Context CNN',\n",
    "        'checkpoint': 'spatial_context_cnn_best.pth',\n",
    "        'model_type': 'spatial_context_cnn',\n",
    "        'color': 'steelblue'\n",
    "    },\n",
    "    {\n",
    "        'name': 'multiscale_cnn',\n",
    "        'display_name': 'Multi-Scale CNN',\n",
    "        'checkpoint': 'multiscale_cnn_best.pth',\n",
    "        'model_type': 'multiscale_cnn',\n",
    "        'color': 'coral'\n",
    "    },\n",
    "    {\n",
    "        'name': 'shallow_unet',\n",
    "        'display_name': 'Shallow U-Net',\n",
    "        'checkpoint': 'shallow_unet_best.pth',\n",
    "        'model_type': 'shallow_unet',\n",
    "        'color': 'mediumseagreen'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load all models\n",
    "models = {}\n",
    "print(\"Loading models...\\n\")\n",
    "\n",
    "for config in models_config:\n",
    "    model_path = project_root / 'checkpoints' / config['checkpoint']\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"⚠️  {config['display_name']}: Checkpoint not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Loading {config['display_name']}...\")\n",
    "    model = get_model(config['model_type'], in_channels=14)\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"  Epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
    "        print(f\"  Val Accuracy: {checkpoint.get('val_acc', 0)*100:.2f}%\")\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    models[config['name']] = model\n",
    "    print(f\"✓ {config['display_name']} loaded\\n\")\n",
    "\n",
    "print(f\"\\nTotal models loaded: {len(models)}/3\")\n",
    "\n",
    "if len(models) == 0:\n",
    "    raise RuntimeError(\n",
    "        'No model checkpoints found!\\n'\n",
    "        'Please train the models first by running notebook 03_train_models.ipynb'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Run Sliding Window Inference for All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference parameters\n",
    "window_size = 128\n",
    "stride = 64  # 50% overlap\n",
    "batch_size = 32 if device.type == 'cuda' else 8\n",
    "\n",
    "h, w, c = all_bands.shape\n",
    "\n",
    "# Calculate windows\n",
    "n_rows = (h - window_size) // stride + 1\n",
    "n_cols = (w - window_size) // stride + 1\n",
    "total_windows = n_rows * n_cols\n",
    "\n",
    "print(f\"Image size: {h} x {w}\")\n",
    "print(f\"Total windows: {total_windows:,}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print()\n",
    "\n",
    "# Extract all windows once\n",
    "print(\"Extracting windows...\")\n",
    "windows = []\n",
    "positions = []\n",
    "\n",
    "for i in tqdm(range(n_rows), desc=\"Extracting\", unit=\"row\"):\n",
    "    for j in range(n_cols):\n",
    "        y = i * stride\n",
    "        x = j * stride\n",
    "        \n",
    "        # Extract patch\n",
    "        patch = all_bands[y:y+window_size, x:x+window_size, :]  # (128, 128, 14)\n",
    "        \n",
    "        # Convert to torch tensor: (C, H, W)\n",
    "        patch_tensor = torch.from_numpy(patch).permute(2, 0, 1).float()\n",
    "        \n",
    "        windows.append(patch_tensor)\n",
    "        positions.append((y, x))\n",
    "\n",
    "print(f\"Extracted {len(windows):,} windows\\n\")\n",
    "\n",
    "# Run inference for each model\n",
    "prob_maps = {}\n",
    "binary_maps = {}\n",
    "\n",
    "n_batches = (len(windows) + batch_size - 1) // batch_size\n",
    "\n",
    "for config in models_config:\n",
    "    model_name = config['name']\n",
    "    \n",
    "    if model_name not in models:\n",
    "        print(f\"⚠️  Skipping {config['display_name']} (not loaded)\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Running inference: {config['display_name']}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    model = models[model_name]\n",
    "    \n",
    "    # Initialize output arrays\n",
    "    prob_map = np.zeros((h, w), dtype=np.float32)\n",
    "    count_map = np.zeros((h, w), dtype=np.int32)\n",
    "    \n",
    "    # Process in batches\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in tqdm(range(n_batches), desc=\"Inference\", unit=\"batch\"):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(start_idx + batch_size, len(windows))\n",
    "            \n",
    "            # Create batch\n",
    "            batch_patches = torch.stack(windows[start_idx:end_idx]).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_patches)  # (B, 1, 128, 128) logits\n",
    "            probs = torch.sigmoid(outputs).squeeze(1).cpu().numpy()  # (B, 128, 128)\n",
    "            \n",
    "            # Add to probability map\n",
    "            for i, (y, x) in enumerate(positions[start_idx:end_idx]):\n",
    "                prob_map[y:y+window_size, x:x+window_size] += probs[i]\n",
    "                count_map[y:y+window_size, x:x+window_size] += 1\n",
    "    \n",
    "    # Average overlapping predictions\n",
    "    prob_map = np.divide(prob_map, count_map, where=count_map > 0)\n",
    "    \n",
    "    # Create binary map\n",
    "    binary_map = (prob_map > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Store results\n",
    "    prob_maps[model_name] = prob_map\n",
    "    binary_maps[model_name] = binary_map\n",
    "    \n",
    "    print(f\"\\n✓ {config['display_name']} complete\")\n",
    "    print(f\"  Probability range: [{prob_map.min():.4f}, {prob_map.max():.4f}]\")\n",
    "    print(f\"  Deforestation: {binary_map.sum() / binary_map.size * 100:.2f}%\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"ALL INFERENCE COMPLETED - {len(prob_maps)} models\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Statistics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each model\n",
    "pixel_size_m = 10.0\n",
    "pixel_area_m2 = pixel_size_m * pixel_size_m\n",
    "\n",
    "stats_data = []\n",
    "\n",
    "for config in models_config:\n",
    "    model_name = config['name']\n",
    "    \n",
    "    if model_name not in prob_maps:\n",
    "        continue\n",
    "    \n",
    "    prob_map = prob_maps[model_name]\n",
    "    binary_map = binary_maps[model_name]\n",
    "    \n",
    "    total_pixels = prob_map.size\n",
    "    defor_pixels = binary_map.sum()\n",
    "    defor_percentage = (defor_pixels / total_pixels) * 100\n",
    "    defor_area_km2 = defor_pixels * pixel_area_m2 / 1e6\n",
    "    total_area_km2 = total_pixels * pixel_area_m2 / 1e6\n",
    "    \n",
    "    stats_data.append({\n",
    "        'Model': config['display_name'],\n",
    "        'Deforestation (%)': defor_percentage,\n",
    "        'Area (km²)': defor_area_km2,\n",
    "        'Total Area (km²)': total_area_km2,\n",
    "        'Mean Probability': prob_map.mean(),\n",
    "        'Color': config['color']\n",
    "    })\n",
    "\n",
    "# Display statistics\n",
    "print(\"=\" * 80)\n",
    "print(\"DEFORESTATION STATISTICS - ALL MODELS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "for data in stats_data:\n",
    "    print(f\"{data['Model']}:\")\n",
    "    print(f\"  Total area: {data['Total Area (km²)']:.2f} km²\")\n",
    "    print(f\"  Deforestation area: {data['Area (km²)']:.2f} km²\")\n",
    "    print(f\"  Deforestation: {data['Deforestation (%)']:.2f}%\")\n",
    "    print(f\"  Mean probability: {data['Mean Probability']:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Save All Results as GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = project_root / 'outputs'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Saving results...\\n\")\n",
    "\n",
    "for config in models_config:\n",
    "    model_name = config['name']\n",
    "    \n",
    "    if model_name not in prob_maps:\n",
    "        continue\n",
    "    \n",
    "    prob_map = prob_maps[model_name]\n",
    "    binary_map = binary_maps[model_name]\n",
    "    \n",
    "    # Save probability map\n",
    "    prob_path = output_dir / f'{model_name}_probability_map.tif'\n",
    "    with rasterio.open(\n",
    "        prob_path, 'w',\n",
    "        driver='GTiff',\n",
    "        height=h, width=w,\n",
    "        count=1,\n",
    "        dtype=rasterio.float32,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress='lzw'\n",
    "    ) as dst:\n",
    "        dst.write(prob_map.astype(np.float32), 1)\n",
    "    \n",
    "    # Save binary map\n",
    "    binary_path = output_dir / f'{model_name}_binary_map.tif'\n",
    "    with rasterio.open(\n",
    "        binary_path, 'w',\n",
    "        driver='GTiff',\n",
    "        height=h, width=w,\n",
    "        count=1,\n",
    "        dtype=rasterio.uint8,\n",
    "        crs=crs,\n",
    "        transform=transform,\n",
    "        compress='lzw'\n",
    "    ) as dst:\n",
    "        dst.write(binary_map, 1)\n",
    "    \n",
    "    print(f\"{config['display_name']}:\")\n",
    "    print(f\"  ✓ {prob_path.name}\")\n",
    "    print(f\"  ✓ {binary_path.name}\")\n",
    "\n",
    "# Save comparison summary\n",
    "summary_path = output_dir / '3_models_comparison_summary.txt'\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"3 CNN MODELS COMPARISON SUMMARY\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    for data in stats_data:\n",
    "        f.write(f\"{data['Model']}:\\n\")\n",
    "        f.write(f\"  Total area: {data['Total Area (km²)']:.2f} km²\\n\")\n",
    "        f.write(f\"  Deforestation area: {data['Area (km²)']:.2f} km²\\n\")\n",
    "        f.write(f\"  Deforestation percentage: {data['Deforestation (%)']:.2f}%\\n\")\n",
    "        f.write(f\"  Mean probability: {data['Mean Probability']:.4f}\\n\\n\")\n",
    "\n",
    "print(f\"\\n✓ Summary: {summary_path.name}\")\n",
    "print(\"\\nAll inference outputs saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Compare Probability Maps (Side-by-Side)\n",
    "\n",
    "Visualize probability maps from all 3 models side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side comparison of probability maps\n",
    "n_models = len(prob_maps)\n",
    "\n",
    "if n_models > 0:\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(20, 7))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, config in enumerate(models_config):\n",
    "        model_name = config['name']\n",
    "        \n",
    "        if model_name not in prob_maps:\n",
    "            continue\n",
    "        \n",
    "        prob_map = prob_maps[model_name]\n",
    "        \n",
    "        im = axes[i].imshow(prob_map, cmap='RdYlGn_r', vmin=0, vmax=1)\n",
    "        axes[i].set_title(f\"{config['display_name']}\\nProbability Map\",\n",
    "                         fontsize=13, fontweight='bold')\n",
    "        axes[i].set_xlabel('X (pixels)', fontsize=10)\n",
    "        axes[i].set_ylabel('Y (pixels)', fontsize=10)\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Probability', fontsize=10, rotation=270, labelpad=15)\n",
    "    \n",
    "    plt.suptitle('Deforestation Probability Maps - 3 CNN Models Comparison',\n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    figures_dir = project_root / 'figures'\n",
    "    figures_dir.mkdir(exist_ok=True)\n",
    "    plt.savefig(figures_dir / '3_models_probability_comparison.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {figures_dir / '3_models_probability_comparison.png'}\")\n",
    "else:\n",
    "    print(\"No models available for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Binary Maps (Side-by-Side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side comparison of binary maps\n",
    "if n_models > 0:\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(20, 7))\n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors = ['#2ecc71', '#e74c3c']  # Green, Red\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    for i, config in enumerate(models_config):\n",
    "        model_name = config['name']\n",
    "        \n",
    "        if model_name not in binary_maps:\n",
    "            continue\n",
    "        \n",
    "        binary_map = binary_maps[model_name]\n",
    "        \n",
    "        im = axes[i].imshow(binary_map, cmap=cmap, vmin=0, vmax=1)\n",
    "        axes[i].set_title(f\"{config['display_name']}\\nBinary Classification\",\n",
    "                         fontsize=13, fontweight='bold')\n",
    "        axes[i].set_xlabel('X (pixels)', fontsize=10)\n",
    "        axes[i].set_ylabel('Y (pixels)', fontsize=10)\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=axes[i], fraction=0.046, pad=0.04,\n",
    "                           ticks=[0.25, 0.75])\n",
    "        cbar.ax.set_yticklabels(['No Deforestation', 'Deforestation'], fontsize=9)\n",
    "    \n",
    "    plt.suptitle('Binary Deforestation Maps - 3 CNN Models Comparison',\n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / '3_models_binary_comparison.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {figures_dir / '3_models_binary_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistics Comparison Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar charts comparing statistics\n",
    "if len(stats_data) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    model_names = [s['Model'] for s in stats_data]\n",
    "    colors_list = [s['Color'] for s in stats_data]\n",
    "    \n",
    "    # Deforestation percentage\n",
    "    defor_pcts = [s['Deforestation (%)'] for s in stats_data]\n",
    "    axes[0].bar(range(len(model_names)), defor_pcts, color=colors_list,\n",
    "               edgecolor='black', alpha=0.8)\n",
    "    axes[0].set_xticks(range(len(model_names)))\n",
    "    axes[0].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "    axes[0].set_ylabel('Deforestation (%)', fontsize=11)\n",
    "    axes[0].set_title('Deforestation Percentage', fontsize=13, fontweight='bold')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(defor_pcts):\n",
    "        axes[0].text(i, v + 0.3, f'{v:.2f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Deforestation area\n",
    "    defor_areas = [s['Area (km²)'] for s in stats_data]\n",
    "    axes[1].bar(range(len(model_names)), defor_areas, color=colors_list,\n",
    "               edgecolor='black', alpha=0.8)\n",
    "    axes[1].set_xticks(range(len(model_names)))\n",
    "    axes[1].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "    axes[1].set_ylabel('Area (km²)', fontsize=11)\n",
    "    axes[1].set_title('Deforestation Area', fontsize=13, fontweight='bold')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(defor_areas):\n",
    "        axes[1].text(i, v + 20, f'{v:.1f}', ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Mean probability\n",
    "    mean_probs = [s['Mean Probability'] for s in stats_data]\n",
    "    axes[2].bar(range(len(model_names)), mean_probs, color=colors_list,\n",
    "               edgecolor='black', alpha=0.8)\n",
    "    axes[2].set_xticks(range(len(model_names)))\n",
    "    axes[2].set_xticklabels(model_names, rotation=15, ha='right')\n",
    "    axes[2].set_ylabel('Mean Probability', fontsize=11)\n",
    "    axes[2].set_title('Average Probability', fontsize=13, fontweight='bold')\n",
    "    axes[2].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(mean_probs):\n",
    "        axes[2].text(i, v + 0.01, f'{v:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Statistics Comparison - 3 CNN Models',\n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figures_dir / '3_models_statistics_comparison.png',\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Saved: {figures_dir / '3_models_statistics_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "This notebook has run full-image inference for **all 3 CNN models** and generated:\n",
    "\n",
    "**Outputs:**\n",
    "- Individual probability and binary maps for each model (GeoTIFF format)\n",
    "- Side-by-side probability maps comparison\n",
    "- Side-by-side binary maps comparison\n",
    "- Statistics comparison bar charts\n",
    "- Comprehensive summary report\n",
    "\n",
    "**Models compared:**\n",
    "1. Spatial Context CNN\n",
    "2. Multi-Scale CNN\n",
    "3. Shallow U-Net\n",
    "\n",
    "**Next steps:**\n",
    "- Run notebook `07_compare_all_models.ipynb` to compare with Random Forest\n",
    "- Analyze model agreement and differences\n",
    "- Use the generated maps for further analysis\n",
    "\n",
    "All figures have been saved to `figures/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}