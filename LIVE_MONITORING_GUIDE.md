# ğŸ“Š Live Monitoring Guide - Enhanced Training Visualization

## ğŸ¯ New Features

TÃ´i Ä‘Ã£ thÃªm **live monitoring vá»›i tqdm** vÃ  **real-time visualization** vÃ o notebooks!

### âœ¨ Features má»›i:

1. **ğŸ“Š Real-time Progress Bars** (tqdm)
   - Progress bar cho má»—i training epoch
   - Progress bar cho validation
   - Overall progress bar cho toÃ n bá»™ training
   - Hiá»ƒn thá»‹ metrics real-time (loss, accuracy)

2. **ğŸ“ˆ Live Plotting**
   - Plots tá»± Ä‘á»™ng update sau má»—i epoch
   - 4 plots: Loss, Accuracy, F1 Score, Learning Rate
   - ÄÃ¡nh dáº¥u best epoch trÃªn chart
   - Auto-save plot cuá»‘i training

3. **â±ï¸ Time Estimation**
   - Æ¯á»›c tÃ­nh thá»i gian training
   - Dá»±a trÃªn GPU type (RTX 3090, 4090, A100, etc.)
   - Hiá»ƒn thá»‹ trÆ°á»›c khi báº¯t Ä‘áº§u train

4. **ğŸ¨ Better Visualization**
   - Visualize samples vá»›i progress bar
   - Formatted epoch summaries
   - Color-coded status messages

---

## ğŸš€ Usage

### 1. Training vá»›i Live Monitoring:

```python
from src.notebook_utils import NotebookTrainer

# Create trainer (thay vÃ¬ Trainer thÃ´ng thÆ°á»ng)
trainer = NotebookTrainer(
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
    criterion=criterion,
    optimizer=optimizer,
    scheduler=scheduler,
    device=device,
    save_dir='models',
    model_name='unet_efficientnet'
)

# Train vá»›i live plots
history = trainer.train(
    epochs=50,
    early_stopping_patience=10,
    plot_every=1  # Update plot every 1 epoch
)
```

### 2. Visualize Samples:

```python
from src.notebook_utils import visualize_batch_with_progress

# Visualize 8 random samples vá»›i progress bar
visualize_batch_with_progress(train_loader.dataset, num_samples=8)
```

### 3. Training Schedule Estimate:

```python
from src.notebook_utils import print_training_schedule

print_training_schedule(
    epochs=50,
    batch_size=16,
    total_samples=1028,
    gpu_name='NVIDIA RTX A4000'
)
```

---

## ğŸ“Š What You'll See During Training

### Progress Bars:

```
Overall Progress: 20%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/50 epochs
Epoch 10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:45<00:00]
  â””â”€ loss: 0.3214  acc: 87.32%

Epoch 10 [Val]  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00]

================================================================================
ğŸ“Š Epoch 10 Summary
================================================================================
  Train â†’ Loss: 0.3214  |  Acc: 87.32%
  Val   â†’ Loss: 0.2891  |  Acc: 89.15%  |  F1: 0.8876
  LR: 0.000095
================================================================================
âœ… New best model! Val Acc: 89.15% (saved)
```

### Live Plots:

Báº¡n sáº½ tháº¥y 4 plots tá»± Ä‘á»™ng update:

1. **Loss Curve** - Train vs Val loss
2. **Accuracy Curve** - Train vs Val accuracy (vá»›i dáº¥u sao â­ táº¡i best epoch)
3. **F1 Score Curve** - Validation F1 score
4. **Learning Rate Schedule** - LR changes over time

---

## ğŸ¨ Visual Examples

### Training Progress:

```
ğŸš€ TRAINING STARTED - UNET_EFFICIENTNET
================================================================================
Device: cuda
Total Epochs: 50
Early Stopping Patience: 10
Save Directory: models/unet_efficientnet
================================================================================

Overall Progress:   0%|          | 0/50 epochs [00:00<?, ?it/s]
Epoch 1 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:47<00:00, 1.38it/s, loss=0.6234, acc=65.43%]
Epoch 1 [Val]  : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00, 2.15it/s]

================================================================================
ğŸ“Š Epoch 1 Summary
================================================================================
  Train â†’ Loss: 0.6234  |  Acc: 65.43%
  Val   â†’ Loss: 0.5891  |  Acc: 68.21%  |  F1: 0.6543
  LR: 0.000100
================================================================================
âœ… New best model! Val Acc: 68.21% (saved)
```

### Time Estimation:

```
================================================================================
ğŸ“… TRAINING SCHEDULE ESTIMATE
================================================================================
Total epochs: 50
Batches per epoch: 65
Total batches: 3,250

Estimated time:
  Per epoch: ~13.0 minutes
  Total: ~10.8 hours (650 minutes)

GPU: NVIDIA RTX A4000
================================================================================
```

---

## ğŸ”§ Customization

### Adjust Plot Update Frequency:

```python
# Update plot every 2 epochs (faster for long training)
history = trainer.train(
    epochs=100,
    early_stopping_patience=15,
    plot_every=2
)
```

### Change Visualization Settings:

```python
# Visualize more samples
visualize_batch_with_progress(dataset, num_samples=16)

# Or fewer samples
visualize_batch_with_progress(dataset, num_samples=4)
```

---

## ğŸ“‹ Comparison: Old vs New

### Old Trainer (src/utils.py):
```python
from src.utils import Trainer

trainer = Trainer(...)
history = trainer.train(epochs=50)
# â†’ Chá»‰ cÃ³ text output
# â†’ KhÃ´ng cÃ³ live plots
# â†’ Pháº£i plot manually sau khi train xong
```

### New NotebookTrainer (src/notebook_utils.py):
```python
from src.notebook_utils import NotebookTrainer

trainer = NotebookTrainer(...)
history = trainer.train(epochs=50)
# âœ… Progress bars cho má»i operations
# âœ… Live plots update má»—i epoch
# âœ… Auto-save plots
# âœ… Better formatted output
# âœ… Time estimates
```

---

## ğŸ’¡ Tips

### 1. For Long Training Sessions:

```python
# Update plots less frequently to save time
trainer.train(epochs=100, plot_every=5)
```

### 2. Monitor GPU Usage:

```python
# Check GPU before training
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

### 3. Adjust for Slower GPUs:

```python
# Reduce batch size if OOM
BATCH_SIZE = 8  # Instead of 16

# Or train for fewer epochs first
EPOCHS = 20  # Quick test run
```

---

## ğŸ¯ Benefits

### Real-time Monitoring:
- âœ… Xem ngay khi model Ä‘ang há»c tá»‘t hay khÃ´ng
- âœ… PhÃ¡t hiá»‡n overfitting sá»›m
- âœ… Dá»«ng training náº¿u khÃ´ng improve

### Better UX:
- âœ… Progress bars cho má»i operations
- âœ… KhÃ´ng pháº£i Ä‘á»£i Ä‘áº¿n cuá»‘i má»›i biáº¿t káº¿t quáº£
- âœ… Dá»… debug vÃ  adjust hyperparameters

### Time Saving:
- âœ… Biáº¿t trÆ°á»›c training máº¥t bao lÃ¢u
- âœ… Auto-save best model
- âœ… Early stopping tá»± Ä‘á»™ng

---

## ğŸ“š Files Changed

### New Files:
- `src/notebook_utils.py` - NotebookTrainer + visualization utilities

### Updated Files:
- `notebooks/1_train_models.ipynb` - Sá»­ dá»¥ng NotebookTrainer
  - Cell 3: Import NotebookTrainer
  - Cell 9: Add training schedule
  - Cell 11: Enhanced sample visualization
  - Cell 15: Use NotebookTrainer with live plots

---

## ğŸ” Example Output

Khi báº¡n cháº¡y notebook, báº¡n sáº½ tháº¥y:

```
ğŸ”„ Creating dataloaders...

ğŸ“Š Data splits:
  Train: 1028 samples (80.0%)
  Val:   128 samples (10.0%)
  Test:  129 samples (10.0%)

âœ… DataLoaders created!
  Train: 1028 samples (65 batches)
  Val:   128 samples (8 batches)
  Test:  129 samples (9 batches)

================================================================================
ğŸ“… TRAINING SCHEDULE ESTIMATE
================================================================================
Total epochs: 50
Batches per epoch: 65
Total batches: 3,250

Estimated time:
  Per epoch: ~13.0 minutes
  Total: ~10.8 hours (650 minutes)

GPU: NVIDIA RTX A4000
================================================================================

Loading 8 random samples...
Loading samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00, 3.21it/s]
âœ… Displayed 8 samples

[... 8 images displayed ...]

ğŸ¬ Training will start with LIVE visualization!
   - Progress bars for each epoch
   - Real-time plots (updated every epoch)
   - Automatic best model saving
   - Early stopping monitoring

[... Live training with progress bars and plots ...]
```

---

## ğŸ‰ Summary

BÃ¢y giá» báº¡n cÃ³ **real-time monitoring** hoÃ n chá»‰nh cho training process:

- ğŸ“Š **tqdm progress bars** - Track tá»«ng batch, epoch
- ğŸ“ˆ **Live plots** - Xem metrics update real-time
- â±ï¸ **Time estimates** - Biáº¿t trÆ°á»›c training máº¥t bao lÃ¢u
- ğŸ¨ **Better visualization** - Äáº¹p vÃ  dá»… hiá»ƒu hÆ¡n

Cháº¡y notebook vÃ  xem magic xáº£y ra! âœ¨
